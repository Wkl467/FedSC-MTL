{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "443f5729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Fashion-MNIST data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khalil\\AppData\\Local\\Temp\\ipykernel_27376\\1574330812.py:25: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  targets = np.array(full_dataset.targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Federated Training...\n",
      "Round 1/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 2.2720, Acc: 26.38%\n",
      "Client Avg - Loss: 1.3361, Acc: 60.76%\n",
      "Round 2/100, μ=0.0980, Clients: 10\n",
      "Global Test - Loss: 1.6217, Acc: 36.03%\n",
      "Client Avg - Loss: 0.5601, Acc: 84.28%\n",
      "Round 3/100, μ=0.0960, Clients: 10\n",
      "Global Test - Loss: 1.4859, Acc: 40.40%\n",
      "Client Avg - Loss: 0.8008, Acc: 70.51%\n",
      "Round 4/100, μ=0.0941, Clients: 10\n",
      "Global Test - Loss: 1.5093, Acc: 50.60%\n",
      "Client Avg - Loss: 0.3976, Acc: 86.36%\n",
      "Round 5/100, μ=0.0922, Clients: 10\n",
      "Global Test - Loss: 1.3219, Acc: 47.60%\n",
      "Client Avg - Loss: 0.4871, Acc: 83.54%\n",
      "Round 6/100, μ=0.0904, Clients: 10\n",
      "Global Test - Loss: 0.9488, Acc: 60.52%\n",
      "Client Avg - Loss: 0.3315, Acc: 89.21%\n",
      "Round 7/100, μ=0.0886, Clients: 10\n",
      "Global Test - Loss: 1.6126, Acc: 46.29%\n",
      "Client Avg - Loss: 0.3537, Acc: 89.07%\n",
      "Round 8/100, μ=0.0868, Clients: 10\n",
      "Global Test - Loss: 1.1102, Acc: 52.74%\n",
      "Client Avg - Loss: 0.3858, Acc: 87.94%\n",
      "Round 9/100, μ=0.0851, Clients: 10\n",
      "Global Test - Loss: 1.2204, Acc: 52.22%\n",
      "Client Avg - Loss: 0.3322, Acc: 87.08%\n",
      "Round 10/100, μ=0.0834, Clients: 10\n",
      "Global Test - Loss: 1.0454, Acc: 56.54%\n",
      "Client Avg - Loss: 0.3372, Acc: 87.99%\n",
      "Round 11/100, μ=0.0817, Clients: 10\n",
      "Global Test - Loss: 1.1594, Acc: 56.94%\n",
      "Client Avg - Loss: 0.3425, Acc: 87.57%\n",
      "Round 12/100, μ=0.0801, Clients: 10\n",
      "Global Test - Loss: 0.8774, Acc: 66.56%\n",
      "Client Avg - Loss: 0.3761, Acc: 86.96%\n",
      "Round 13/100, μ=0.0785, Clients: 10\n",
      "Global Test - Loss: 0.9802, Acc: 62.28%\n",
      "Client Avg - Loss: 0.3226, Acc: 87.38%\n",
      "Round 14/100, μ=0.0769, Clients: 10\n",
      "Global Test - Loss: 1.1506, Acc: 57.85%\n",
      "Client Avg - Loss: 0.3999, Acc: 85.47%\n",
      "Round 15/100, μ=0.0754, Clients: 10\n",
      "Global Test - Loss: 0.9854, Acc: 65.85%\n",
      "Client Avg - Loss: 0.3858, Acc: 85.40%\n",
      "Round 16/100, μ=0.0739, Clients: 10\n",
      "Global Test - Loss: 0.7295, Acc: 73.83%\n",
      "Client Avg - Loss: 0.2582, Acc: 91.75%\n",
      "Round 17/100, μ=0.0724, Clients: 10\n",
      "Global Test - Loss: 1.0390, Acc: 59.17%\n",
      "Client Avg - Loss: 0.2524, Acc: 91.86%\n",
      "Round 18/100, μ=0.0709, Clients: 10\n",
      "Global Test - Loss: 0.8053, Acc: 70.02%\n",
      "Client Avg - Loss: 0.1524, Acc: 95.17%\n",
      "Round 19/100, μ=0.0695, Clients: 10\n",
      "Global Test - Loss: 1.3331, Acc: 54.59%\n",
      "Client Avg - Loss: 0.3196, Acc: 88.28%\n",
      "Round 20/100, μ=0.0681, Clients: 10\n",
      "Global Test - Loss: 1.1118, Acc: 62.38%\n",
      "Client Avg - Loss: 0.3019, Acc: 89.69%\n",
      "Round 21/100, μ=0.0668, Clients: 10\n",
      "Global Test - Loss: 0.8058, Acc: 69.07%\n",
      "Client Avg - Loss: 0.3340, Acc: 87.69%\n",
      "Round 22/100, μ=0.0654, Clients: 10\n",
      "Global Test - Loss: 0.8125, Acc: 67.89%\n",
      "Client Avg - Loss: 0.2618, Acc: 90.25%\n",
      "Round 23/100, μ=0.0641, Clients: 10\n",
      "Global Test - Loss: 0.7920, Acc: 69.64%\n",
      "Client Avg - Loss: 0.2799, Acc: 90.21%\n",
      "Round 24/100, μ=0.0628, Clients: 10\n",
      "Global Test - Loss: 0.8047, Acc: 69.17%\n",
      "Client Avg - Loss: 0.2582, Acc: 90.76%\n",
      "Round 25/100, μ=0.0616, Clients: 10\n",
      "Global Test - Loss: 0.9722, Acc: 65.05%\n",
      "Client Avg - Loss: 0.2962, Acc: 91.15%\n",
      "Round 26/100, μ=0.0603, Clients: 10\n",
      "Global Test - Loss: 0.6661, Acc: 74.53%\n",
      "Client Avg - Loss: 0.2176, Acc: 92.62%\n",
      "Round 27/100, μ=0.0591, Clients: 10\n",
      "Global Test - Loss: 0.7386, Acc: 71.51%\n",
      "Client Avg - Loss: 0.1674, Acc: 93.98%\n",
      "Round 28/100, μ=0.0580, Clients: 10\n",
      "Global Test - Loss: 0.7476, Acc: 69.89%\n",
      "Client Avg - Loss: 0.2360, Acc: 91.79%\n",
      "Round 29/100, μ=0.0568, Clients: 10\n",
      "Global Test - Loss: 0.6812, Acc: 74.74%\n",
      "Client Avg - Loss: 0.2266, Acc: 92.65%\n",
      "Round 30/100, μ=0.0557, Clients: 10\n",
      "Global Test - Loss: 0.7995, Acc: 69.10%\n",
      "Client Avg - Loss: 0.2336, Acc: 92.21%\n",
      "Round 31/100, μ=0.0545, Clients: 10\n",
      "Global Test - Loss: 1.0055, Acc: 67.34%\n",
      "Client Avg - Loss: 0.3310, Acc: 87.60%\n",
      "Round 32/100, μ=0.0535, Clients: 10\n",
      "Global Test - Loss: 0.8802, Acc: 67.97%\n",
      "Client Avg - Loss: 0.2425, Acc: 92.48%\n",
      "Round 33/100, μ=0.0524, Clients: 10\n",
      "Global Test - Loss: 0.8406, Acc: 69.37%\n",
      "Client Avg - Loss: 0.2707, Acc: 89.77%\n",
      "Round 34/100, μ=0.0513, Clients: 10\n",
      "Global Test - Loss: 0.6520, Acc: 75.43%\n",
      "Client Avg - Loss: 0.2205, Acc: 92.36%\n",
      "Round 35/100, μ=0.0503, Clients: 10\n",
      "Global Test - Loss: 0.7772, Acc: 67.21%\n",
      "Client Avg - Loss: 0.1519, Acc: 94.93%\n",
      "Round 36/100, μ=0.0493, Clients: 10\n",
      "Global Test - Loss: 0.6533, Acc: 76.24%\n",
      "Client Avg - Loss: 0.2098, Acc: 92.73%\n",
      "Round 37/100, μ=0.0483, Clients: 10\n",
      "Global Test - Loss: 1.0810, Acc: 56.84%\n",
      "Client Avg - Loss: 0.1674, Acc: 94.82%\n",
      "Round 38/100, μ=0.0474, Clients: 10\n",
      "Global Test - Loss: 0.6688, Acc: 73.24%\n",
      "Client Avg - Loss: 0.2736, Acc: 89.92%\n",
      "Round 39/100, μ=0.0464, Clients: 10\n",
      "Global Test - Loss: 0.7321, Acc: 70.95%\n",
      "Client Avg - Loss: 0.3012, Acc: 88.87%\n",
      "Round 40/100, μ=0.0455, Clients: 10\n",
      "Global Test - Loss: 0.6124, Acc: 77.00%\n",
      "Client Avg - Loss: 0.2359, Acc: 91.63%\n",
      "Round 41/100, μ=0.0446, Clients: 10\n",
      "Global Test - Loss: 0.6652, Acc: 75.01%\n",
      "Client Avg - Loss: 0.2191, Acc: 92.37%\n",
      "Round 42/100, μ=0.0437, Clients: 10\n",
      "Global Test - Loss: 0.7544, Acc: 72.62%\n",
      "Client Avg - Loss: 0.3248, Acc: 87.83%\n",
      "Round 43/100, μ=0.0428, Clients: 10\n",
      "Global Test - Loss: 0.8358, Acc: 64.90%\n",
      "Client Avg - Loss: 0.2114, Acc: 92.60%\n",
      "Round 44/100, μ=0.0419, Clients: 10\n",
      "Global Test - Loss: 1.1375, Acc: 57.01%\n",
      "Client Avg - Loss: 0.2249, Acc: 91.98%\n",
      "Round 45/100, μ=0.0411, Clients: 10\n",
      "Global Test - Loss: 0.8440, Acc: 68.13%\n",
      "Client Avg - Loss: 0.2416, Acc: 90.93%\n",
      "Round 46/100, μ=0.0403, Clients: 10\n",
      "Global Test - Loss: 1.0426, Acc: 65.32%\n",
      "Client Avg - Loss: 0.1731, Acc: 93.71%\n",
      "Round 47/100, μ=0.0395, Clients: 10\n",
      "Global Test - Loss: 0.7285, Acc: 74.91%\n",
      "Client Avg - Loss: 0.3239, Acc: 88.84%\n",
      "Round 48/100, μ=0.0387, Clients: 10\n",
      "Global Test - Loss: 0.7563, Acc: 70.43%\n",
      "Client Avg - Loss: 0.2326, Acc: 91.76%\n",
      "Round 49/100, μ=0.0379, Clients: 10\n",
      "Global Test - Loss: 0.7837, Acc: 67.24%\n",
      "Client Avg - Loss: 0.1604, Acc: 93.88%\n",
      "Round 50/100, μ=0.0372, Clients: 10\n",
      "Global Test - Loss: 0.7920, Acc: 70.43%\n",
      "Client Avg - Loss: 0.1554, Acc: 94.56%\n",
      "Round 51/100, μ=0.0364, Clients: 10\n",
      "Global Test - Loss: 0.7247, Acc: 74.47%\n",
      "Client Avg - Loss: 0.2138, Acc: 92.35%\n",
      "Round 52/100, μ=0.0357, Clients: 10\n",
      "Global Test - Loss: 0.7415, Acc: 68.21%\n",
      "Client Avg - Loss: 0.3156, Acc: 87.74%\n",
      "Round 53/100, μ=0.0350, Clients: 10\n",
      "Global Test - Loss: 1.0299, Acc: 59.30%\n",
      "Client Avg - Loss: 0.2498, Acc: 90.42%\n",
      "Round 54/100, μ=0.0343, Clients: 10\n",
      "Global Test - Loss: 0.6103, Acc: 77.30%\n",
      "Client Avg - Loss: 0.1666, Acc: 94.55%\n",
      "Round 55/100, μ=0.0336, Clients: 10\n",
      "Global Test - Loss: 0.8276, Acc: 67.38%\n",
      "Client Avg - Loss: 0.1692, Acc: 93.47%\n",
      "Round 56/100, μ=0.0329, Clients: 10\n",
      "Global Test - Loss: 0.7663, Acc: 66.58%\n",
      "Client Avg - Loss: 0.2140, Acc: 91.90%\n",
      "Round 57/100, μ=0.0323, Clients: 10\n",
      "Global Test - Loss: 0.7525, Acc: 68.63%\n",
      "Client Avg - Loss: 0.2305, Acc: 90.44%\n",
      "Round 58/100, μ=0.0316, Clients: 10\n",
      "Global Test - Loss: 0.7051, Acc: 72.21%\n",
      "Client Avg - Loss: 0.2705, Acc: 89.58%\n",
      "Round 59/100, μ=0.0310, Clients: 10\n",
      "Global Test - Loss: 0.6800, Acc: 72.48%\n",
      "Client Avg - Loss: 0.1976, Acc: 92.30%\n",
      "Round 60/100, μ=0.0304, Clients: 10\n",
      "Global Test - Loss: 0.7265, Acc: 72.21%\n",
      "Client Avg - Loss: 0.2001, Acc: 92.51%\n",
      "Round 61/100, μ=0.0298, Clients: 10\n",
      "Global Test - Loss: 0.8402, Acc: 69.05%\n",
      "Client Avg - Loss: 0.2679, Acc: 90.20%\n",
      "Round 62/100, μ=0.0292, Clients: 10\n",
      "Global Test - Loss: 0.9252, Acc: 65.33%\n",
      "Client Avg - Loss: 0.1588, Acc: 94.91%\n",
      "Round 63/100, μ=0.0286, Clients: 10\n",
      "Global Test - Loss: 0.7301, Acc: 72.19%\n",
      "Client Avg - Loss: 0.1388, Acc: 94.79%\n",
      "Round 64/100, μ=0.0280, Clients: 10\n",
      "Global Test - Loss: 0.7087, Acc: 72.53%\n",
      "Client Avg - Loss: 0.2726, Acc: 89.57%\n",
      "Round 65/100, μ=0.0274, Clients: 10\n",
      "Global Test - Loss: 0.6273, Acc: 76.36%\n",
      "Client Avg - Loss: 0.2645, Acc: 89.66%\n",
      "Round 66/100, μ=0.0269, Clients: 10\n",
      "Global Test - Loss: 1.0863, Acc: 56.35%\n",
      "Client Avg - Loss: 0.2224, Acc: 91.25%\n",
      "Round 67/100, μ=0.0264, Clients: 10\n",
      "Global Test - Loss: 1.1747, Acc: 56.38%\n",
      "Client Avg - Loss: 0.1706, Acc: 92.58%\n",
      "Round 68/100, μ=0.0258, Clients: 10\n",
      "Global Test - Loss: 0.5260, Acc: 80.23%\n",
      "Client Avg - Loss: 0.1912, Acc: 93.41%\n",
      "Round 69/100, μ=0.0253, Clients: 10\n",
      "Global Test - Loss: 0.6853, Acc: 72.09%\n",
      "Client Avg - Loss: 0.1738, Acc: 93.67%\n",
      "Round 70/100, μ=0.0248, Clients: 10\n",
      "Global Test - Loss: 0.7477, Acc: 72.75%\n",
      "Client Avg - Loss: 0.2867, Acc: 89.56%\n",
      "Round 71/100, μ=0.0243, Clients: 10\n",
      "Global Test - Loss: 0.5982, Acc: 77.81%\n",
      "Client Avg - Loss: 0.2691, Acc: 90.13%\n",
      "Round 72/100, μ=0.0238, Clients: 10\n",
      "Global Test - Loss: 0.6597, Acc: 74.63%\n",
      "Client Avg - Loss: 0.2432, Acc: 91.37%\n",
      "Round 73/100, μ=0.0233, Clients: 10\n",
      "Global Test - Loss: 0.6224, Acc: 76.24%\n",
      "Client Avg - Loss: 0.2668, Acc: 89.73%\n",
      "Round 74/100, μ=0.0229, Clients: 10\n",
      "Global Test - Loss: 0.7439, Acc: 70.81%\n",
      "Client Avg - Loss: 0.1511, Acc: 94.69%\n",
      "Round 75/100, μ=0.0224, Clients: 10\n",
      "Global Test - Loss: 0.8546, Acc: 74.09%\n",
      "Client Avg - Loss: 0.2388, Acc: 90.92%\n",
      "Round 76/100, μ=0.0220, Clients: 10\n",
      "Global Test - Loss: 0.7269, Acc: 68.89%\n",
      "Client Avg - Loss: 0.1900, Acc: 93.26%\n",
      "Round 77/100, μ=0.0215, Clients: 10\n",
      "Global Test - Loss: 0.7133, Acc: 73.06%\n",
      "Client Avg - Loss: 0.1473, Acc: 94.74%\n",
      "Round 78/100, μ=0.0211, Clients: 10\n",
      "Global Test - Loss: 0.5614, Acc: 78.79%\n",
      "Client Avg - Loss: 0.1976, Acc: 92.66%\n",
      "Round 79/100, μ=0.0207, Clients: 10\n",
      "Global Test - Loss: 0.5213, Acc: 80.43%\n",
      "Client Avg - Loss: 0.1863, Acc: 92.94%\n",
      "Round 80/100, μ=0.0203, Clients: 10\n",
      "Global Test - Loss: 0.7127, Acc: 73.24%\n",
      "Client Avg - Loss: 0.1901, Acc: 93.16%\n",
      "Round 81/100, μ=0.0199, Clients: 10\n",
      "Global Test - Loss: 0.6629, Acc: 74.69%\n",
      "Client Avg - Loss: 0.2145, Acc: 91.46%\n",
      "Round 82/100, μ=0.0195, Clients: 10\n",
      "Global Test - Loss: 0.6749, Acc: 75.28%\n",
      "Client Avg - Loss: 0.1762, Acc: 93.77%\n",
      "Round 83/100, μ=0.0191, Clients: 10\n",
      "Global Test - Loss: 0.6190, Acc: 75.72%\n",
      "Client Avg - Loss: 0.1671, Acc: 93.81%\n",
      "Round 84/100, μ=0.0187, Clients: 10\n",
      "Global Test - Loss: 0.5972, Acc: 76.60%\n",
      "Client Avg - Loss: 0.1714, Acc: 93.30%\n",
      "Round 85/100, μ=0.0183, Clients: 10\n",
      "Global Test - Loss: 0.6165, Acc: 77.50%\n",
      "Client Avg - Loss: 0.1271, Acc: 95.77%\n",
      "Round 86/100, μ=0.0180, Clients: 10\n",
      "Global Test - Loss: 0.6872, Acc: 75.12%\n",
      "Client Avg - Loss: 0.2248, Acc: 91.53%\n",
      "Round 87/100, μ=0.0176, Clients: 10\n",
      "Global Test - Loss: 0.6319, Acc: 77.04%\n",
      "Client Avg - Loss: 0.1395, Acc: 95.15%\n",
      "Round 88/100, μ=0.0172, Clients: 10\n",
      "Global Test - Loss: 0.6813, Acc: 76.08%\n",
      "Client Avg - Loss: 0.1715, Acc: 93.96%\n",
      "Round 89/100, μ=0.0169, Clients: 10\n",
      "Global Test - Loss: 0.6597, Acc: 75.49%\n",
      "Client Avg - Loss: 0.1791, Acc: 93.21%\n",
      "Round 90/100, μ=0.0166, Clients: 10\n",
      "Global Test - Loss: 0.5460, Acc: 80.20%\n",
      "Client Avg - Loss: 0.1573, Acc: 94.02%\n",
      "Round 91/100, μ=0.0162, Clients: 10\n",
      "Global Test - Loss: 0.6615, Acc: 73.44%\n",
      "Client Avg - Loss: 0.0956, Acc: 96.78%\n",
      "Round 92/100, μ=0.0159, Clients: 10\n",
      "Global Test - Loss: 0.7125, Acc: 72.04%\n",
      "Client Avg - Loss: 0.1861, Acc: 93.29%\n",
      "Round 93/100, μ=0.0156, Clients: 10\n",
      "Global Test - Loss: 0.8258, Acc: 69.89%\n",
      "Client Avg - Loss: 0.1302, Acc: 95.46%\n",
      "Round 94/100, μ=0.0153, Clients: 10\n",
      "Global Test - Loss: 0.6263, Acc: 76.14%\n",
      "Client Avg - Loss: 0.1240, Acc: 95.62%\n",
      "Round 95/100, μ=0.0150, Clients: 10\n",
      "Global Test - Loss: 0.6422, Acc: 78.25%\n",
      "Client Avg - Loss: 0.2018, Acc: 92.79%\n",
      "Round 96/100, μ=0.0147, Clients: 10\n",
      "Global Test - Loss: 0.7888, Acc: 72.04%\n",
      "Client Avg - Loss: 0.1919, Acc: 93.37%\n",
      "Round 97/100, μ=0.0144, Clients: 10\n",
      "Global Test - Loss: 0.5442, Acc: 78.80%\n",
      "Client Avg - Loss: 0.1215, Acc: 95.89%\n",
      "Round 98/100, μ=0.0141, Clients: 10\n",
      "Global Test - Loss: 1.0096, Acc: 63.68%\n",
      "Client Avg - Loss: 0.1846, Acc: 92.76%\n",
      "Round 99/100, μ=0.0138, Clients: 10\n",
      "Global Test - Loss: 0.5644, Acc: 79.76%\n",
      "Client Avg - Loss: 0.1135, Acc: 96.20%\n",
      "Round 100/100, μ=0.0135, Clients: 10\n",
      "Global Test - Loss: 0.5999, Acc: 79.95%\n",
      "Client Avg - Loss: 0.0879, Acc: 97.47%\n",
      "Training complete! Results saved.\n"
     ]
    }
   ],
   "source": [
    "# FedProx on Fashion-MNIST\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ======================\n",
    "# Load Fashion-MNIST data\n",
    "# ======================\n",
    "def load_fashionmnist_data(num_clients=100, iid_degree=0.1):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    full_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    targets = np.array(full_dataset.targets)\n",
    "\n",
    "    client_data = {i: {'x': [], 'y': []} for i in range(num_clients)}\n",
    "\n",
    "    for class_idx in range(10):\n",
    "        class_indices = np.where(targets == class_idx)[0]\n",
    "        np.random.shuffle(class_indices)\n",
    "\n",
    "        proportions = np.random.dirichlet(np.repeat(iid_degree, num_clients))\n",
    "        allocations = (proportions * len(class_indices)).astype(int)\n",
    "        allocations[-1] = len(class_indices) - np.sum(allocations[:-1])\n",
    "\n",
    "        start_idx = 0\n",
    "        for client_id in range(num_clients):\n",
    "            end_idx = start_idx + allocations[client_id]\n",
    "            client_indices = class_indices[start_idx:end_idx]\n",
    "\n",
    "            for idx in client_indices:\n",
    "                img, label = full_dataset[idx]\n",
    "                client_data[client_id]['x'].append(img)\n",
    "                client_data[client_id]['y'].append(label)\n",
    "\n",
    "            start_idx = end_idx\n",
    "\n",
    "    client_loaders = {}\n",
    "    for client_id, data in client_data.items():\n",
    "        if len(data['x']) == 0:\n",
    "            continue\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(\n",
    "            data['x'], data['y'], test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        train_dataset = CustomDataset(x_train, y_train)\n",
    "        test_dataset = CustomDataset(x_test, y_test)\n",
    "\n",
    "        client_loaders[client_id] = {\n",
    "            'train': DataLoader(train_dataset, batch_size=32, shuffle=True),\n",
    "            'test': DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "        }\n",
    "\n",
    "    return client_loaders\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "# ======================\n",
    "# CNN Model for Fashion-MNIST\n",
    "# ======================\n",
    "class FashionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(7*7*64, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 7*7*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# ======================\n",
    "# FedProx Client\n",
    "# ======================\n",
    "class FedProxClient:\n",
    "    def __init__(self, client_id, train_loader, test_loader, device):\n",
    "        self.client_id = client_id\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        self.model = FashionCNN().to(device)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def train(self, global_model, mu, local_epochs, lr=0.01):\n",
    "        self.model.load_state_dict(global_model.state_dict())\n",
    "        self.model.train()\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=lr)\n",
    "\n",
    "        train_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for epoch in range(local_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for data, targets in self.train_loader:\n",
    "                data, targets = data.to(self.device), targets.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(data)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                prox_term = 0.0\n",
    "                for w, w_t in zip(self.model.parameters(), global_model.parameters()):\n",
    "                    prox_term += (w - w_t).norm(2)\n",
    "\n",
    "                loss += (mu / 2) * prox_term\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            epoch_loss /= len(self.train_loader)\n",
    "            train_loss += epoch_loss\n",
    "\n",
    "        train_loss /= local_epochs\n",
    "        train_acc = 100. * correct / total\n",
    "\n",
    "        return copy.deepcopy(self.model.state_dict()), train_loss, train_acc\n",
    "\n",
    "    def test(self, model=None):\n",
    "        if model:\n",
    "            self.model.load_state_dict(model)\n",
    "        self.model.eval()\n",
    "\n",
    "        test_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, targets in self.test_loader:\n",
    "                data, targets = data.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(data)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        test_loss /= len(self.test_loader)\n",
    "        test_acc = 100. * correct / total\n",
    "        return test_loss, test_acc\n",
    "\n",
    "# ======================\n",
    "# FedProx Server\n",
    "# ======================\n",
    "class FedProxServer:\n",
    "    def __init__(self, num_clients, device, mu=0.1, dynamic_mu=True):\n",
    "        self.global_model = FashionCNN().to(device)\n",
    "        self.device = device\n",
    "        self.clients = []\n",
    "        self.mu = mu\n",
    "        self.dynamic_mu = dynamic_mu\n",
    "        self.num_clients = num_clients\n",
    "\n",
    "    def add_clients(self, client_loaders):\n",
    "        for client_id, loaders in client_loaders.items():\n",
    "            self.clients.append(FedProxClient(client_id, loaders['train'], loaders['test'], self.device))\n",
    "\n",
    "    def aggregate(self, client_updates):\n",
    "        global_dict = self.global_model.state_dict()\n",
    "        total_samples = sum([samples for _, samples, _ in client_updates])\n",
    "        averaged_params = {key: torch.zeros_like(global_dict[key]) for key in global_dict.keys()}\n",
    "\n",
    "        for model_state, samples, _ in client_updates:\n",
    "            for key in model_state.keys():\n",
    "                averaged_params[key] += model_state[key] * (samples / total_samples)\n",
    "\n",
    "        self.global_model.load_state_dict(averaged_params)\n",
    "\n",
    "    def select_clients(self, fraction=0.1):\n",
    "        num_selected = max(int(self.num_clients * fraction), 1)\n",
    "        return np.random.choice(self.clients, num_selected, replace=False)\n",
    "\n",
    "    def adaptive_mu(self, round_idx, base_mu=0.1, decay_rate=0.98):\n",
    "        if self.dynamic_mu:\n",
    "            return base_mu * (decay_rate ** round_idx)\n",
    "        return self.mu\n",
    "\n",
    "    def evaluate_global_model(self, test_loader=None):\n",
    "        self.global_model.eval()\n",
    "        if test_loader:\n",
    "            return self._centralized_eval(test_loader)\n",
    "        else:\n",
    "            return self._federated_eval()\n",
    "\n",
    "    def _centralized_eval(self, test_loader):\n",
    "        correct, total, test_loss = 0, 0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for data, targets in test_loader:\n",
    "                data, targets = data.to(self.device), targets.to(self.device)\n",
    "                outputs = self.global_model(data)\n",
    "                loss = F.cross_entropy(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_acc = 100. * correct / total\n",
    "        return test_loss, test_acc\n",
    "\n",
    "    def _federated_eval(self):\n",
    "        total_loss, total_acc, total_samples = 0.0, 0.0, 0\n",
    "        for client in self.clients:\n",
    "            samples = len(client.test_loader.dataset)\n",
    "            loss, acc = client.test(self.global_model.state_dict())\n",
    "            total_loss += loss * samples\n",
    "            total_acc += acc * samples\n",
    "            total_samples += samples\n",
    "\n",
    "        avg_loss = total_loss / total_samples\n",
    "        avg_acc = total_acc / total_samples\n",
    "        return avg_loss, avg_acc\n",
    "\n",
    "# ======================\n",
    "# main function\n",
    "# ======================\n",
    "def main():\n",
    "    num_rounds = 100\n",
    "    num_clients = 100\n",
    "    client_fraction = 0.1\n",
    "    local_epochs = 5\n",
    "    base_mu = 0.1\n",
    "    dynamic_mu = True\n",
    "\n",
    "    print(\"Loading Fashion-MNIST data...\")\n",
    "    client_loaders = load_fashionmnist_data(num_clients=num_clients, iid_degree=0.1)\n",
    "\n",
    "    server = FedProxServer(num_clients=num_clients, device=device, mu=base_mu, dynamic_mu=dynamic_mu)\n",
    "    server.add_clients(client_loaders)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    history = {'round': [], 'mu': [], 'global_loss': [], 'global_acc': [], 'client_losses': [], 'client_accs': []}\n",
    "\n",
    "    print(\"Starting Federated Training...\")\n",
    "    for round_idx in range(num_rounds):\n",
    "        mu = server.adaptive_mu(round_idx, base_mu=base_mu)\n",
    "        selected_clients = server.select_clients(fraction=client_fraction)\n",
    "        print(f\"Round {round_idx+1}/{num_rounds}, μ={mu:.4f}, Clients: {len(selected_clients)}\")\n",
    "\n",
    "        client_updates = []\n",
    "        client_stats = {'loss': [], 'acc': []}\n",
    "\n",
    "        for client in selected_clients:\n",
    "            model_state, loss, acc = client.train(global_model=server.global_model, mu=mu, local_epochs=local_epochs, lr=0.01)\n",
    "            samples = len(client.train_loader.dataset)\n",
    "            client_updates.append((model_state, samples, client.client_id))\n",
    "            client_stats['loss'].append(loss)\n",
    "            client_stats['acc'].append(acc)\n",
    "\n",
    "        server.aggregate(client_updates)\n",
    "        global_loss, global_acc = server.evaluate_global_model(test_loader=test_loader)\n",
    "\n",
    "        history['round'].append(round_idx)\n",
    "        history['mu'].append(mu)\n",
    "        history['global_loss'].append(global_loss)\n",
    "        history['global_acc'].append(global_acc)\n",
    "        history['client_losses'].append(client_stats['loss'])\n",
    "        history['client_accs'].append(client_stats['acc'])\n",
    "\n",
    "        print(f\"Global Test - Loss: {global_loss:.4f}, Acc: {global_acc:.2f}%\")\n",
    "        print(f\"Client Avg - Loss: {np.mean(client_stats['loss']):.4f}, Acc: {np.mean(client_stats['acc']):.2f}%\")\n",
    "\n",
    "    torch.save({'model': server.global_model.state_dict(), 'history': history}, 'fedprox_fashionmnist_results.pth')\n",
    "    print(\"Training complete! Results saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "667f51a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[0] Loading Fashion-MNIST...\n",
      "[1] Dataset loaded. Total samples: 60000\n",
      "[2] Partitioning data...\n",
      "[3] Partition done in 0.00s\n",
      "[4] Initializing models...\n",
      "[5] Starting federated training...\n",
      "Round 1/100, Clients: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khalil\\AppData\\Local\\Temp\\ipykernel_27376\\2881047894.py:43: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  labels = np.array(dataset.targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Test - Loss: 2.2142, Acc: 42.94%\n",
      "Round 2/100, Clients: 10\n",
      "Global Test - Loss: 1.1207, Acc: 59.91%\n",
      "Round 3/100, Clients: 10\n",
      "Global Test - Loss: 0.8407, Acc: 68.52%\n",
      "Round 4/100, Clients: 10\n",
      "Global Test - Loss: 0.7467, Acc: 72.29%\n",
      "Round 5/100, Clients: 10\n",
      "Global Test - Loss: 0.6881, Acc: 74.37%\n",
      "Round 6/100, Clients: 10\n",
      "Global Test - Loss: 0.6376, Acc: 75.62%\n",
      "Round 7/100, Clients: 10\n",
      "Global Test - Loss: 0.6210, Acc: 76.48%\n",
      "Round 8/100, Clients: 10\n",
      "Global Test - Loss: 0.5813, Acc: 77.77%\n",
      "Round 9/100, Clients: 10\n",
      "Global Test - Loss: 0.5563, Acc: 79.35%\n",
      "Round 10/100, Clients: 10\n",
      "Global Test - Loss: 0.5546, Acc: 79.03%\n",
      "Round 11/100, Clients: 10\n",
      "Global Test - Loss: 0.5345, Acc: 79.15%\n",
      "Round 12/100, Clients: 10\n",
      "Global Test - Loss: 0.5149, Acc: 80.50%\n",
      "Round 13/100, Clients: 10\n",
      "Global Test - Loss: 0.4930, Acc: 81.78%\n",
      "Round 14/100, Clients: 10\n",
      "Global Test - Loss: 0.4777, Acc: 82.20%\n",
      "Round 15/100, Clients: 10\n",
      "Global Test - Loss: 0.4667, Acc: 82.80%\n",
      "Round 16/100, Clients: 10\n",
      "Global Test - Loss: 0.4591, Acc: 83.07%\n",
      "Round 17/100, Clients: 10\n",
      "Global Test - Loss: 0.4404, Acc: 83.75%\n",
      "Round 18/100, Clients: 10\n",
      "Global Test - Loss: 0.4309, Acc: 84.14%\n",
      "Round 19/100, Clients: 10\n",
      "Global Test - Loss: 0.4195, Acc: 84.51%\n",
      "Round 20/100, Clients: 10\n",
      "Global Test - Loss: 0.4111, Acc: 84.95%\n",
      "Round 21/100, Clients: 10\n",
      "Global Test - Loss: 0.4020, Acc: 85.23%\n",
      "Round 22/100, Clients: 10\n",
      "Global Test - Loss: 0.3969, Acc: 85.40%\n",
      "Round 23/100, Clients: 10\n",
      "Global Test - Loss: 0.3847, Acc: 85.75%\n",
      "Round 24/100, Clients: 10\n",
      "Global Test - Loss: 0.3818, Acc: 86.08%\n",
      "Round 25/100, Clients: 10\n",
      "Global Test - Loss: 0.3727, Acc: 86.37%\n",
      "Round 26/100, Clients: 10\n",
      "Global Test - Loss: 0.3665, Acc: 86.50%\n",
      "Round 27/100, Clients: 10\n",
      "Global Test - Loss: 0.3586, Acc: 86.73%\n",
      "Round 28/100, Clients: 10\n",
      "Global Test - Loss: 0.3532, Acc: 87.02%\n",
      "Round 29/100, Clients: 10\n",
      "Global Test - Loss: 0.3480, Acc: 87.11%\n",
      "Round 30/100, Clients: 10\n",
      "Global Test - Loss: 0.3450, Acc: 87.29%\n",
      "Round 31/100, Clients: 10\n",
      "Global Test - Loss: 0.3491, Acc: 87.01%\n",
      "Round 32/100, Clients: 10\n",
      "Global Test - Loss: 0.3389, Acc: 87.49%\n",
      "Round 33/100, Clients: 10\n",
      "Global Test - Loss: 0.3362, Acc: 87.55%\n",
      "Round 34/100, Clients: 10\n",
      "Global Test - Loss: 0.3327, Acc: 87.77%\n",
      "Round 35/100, Clients: 10\n",
      "Global Test - Loss: 0.3288, Acc: 87.89%\n",
      "Round 36/100, Clients: 10\n",
      "Global Test - Loss: 0.3211, Acc: 88.04%\n",
      "Round 37/100, Clients: 10\n",
      "Global Test - Loss: 0.3235, Acc: 88.06%\n",
      "Round 38/100, Clients: 10\n",
      "Global Test - Loss: 0.3208, Acc: 88.17%\n",
      "Round 39/100, Clients: 10\n",
      "Global Test - Loss: 0.3120, Acc: 88.45%\n",
      "Round 40/100, Clients: 10\n",
      "Global Test - Loss: 0.3170, Acc: 88.26%\n",
      "Round 41/100, Clients: 10\n",
      "Global Test - Loss: 0.3094, Acc: 88.59%\n",
      "Round 42/100, Clients: 10\n",
      "Global Test - Loss: 0.3073, Acc: 88.68%\n",
      "Round 43/100, Clients: 10\n",
      "Global Test - Loss: 0.3143, Acc: 88.47%\n",
      "Round 44/100, Clients: 10\n",
      "Global Test - Loss: 0.2971, Acc: 88.99%\n",
      "Round 45/100, Clients: 10\n",
      "Global Test - Loss: 0.3002, Acc: 88.95%\n",
      "Round 46/100, Clients: 10\n",
      "Global Test - Loss: 0.2948, Acc: 89.16%\n",
      "Round 47/100, Clients: 10\n",
      "Global Test - Loss: 0.2881, Acc: 89.34%\n",
      "Round 48/100, Clients: 10\n",
      "Global Test - Loss: 0.2897, Acc: 89.35%\n",
      "Round 49/100, Clients: 10\n",
      "Global Test - Loss: 0.2907, Acc: 89.24%\n",
      "Round 50/100, Clients: 10\n",
      "Global Test - Loss: 0.2890, Acc: 89.50%\n",
      "Round 51/100, Clients: 10\n",
      "Global Test - Loss: 0.2882, Acc: 89.49%\n",
      "Round 52/100, Clients: 10\n",
      "Global Test - Loss: 0.2798, Acc: 89.81%\n",
      "Round 53/100, Clients: 10\n",
      "Global Test - Loss: 0.2796, Acc: 89.78%\n",
      "Round 54/100, Clients: 10\n",
      "Global Test - Loss: 0.2770, Acc: 89.95%\n",
      "Round 55/100, Clients: 10\n",
      "Global Test - Loss: 0.2810, Acc: 89.70%\n",
      "Round 56/100, Clients: 10\n",
      "Global Test - Loss: 0.2713, Acc: 90.07%\n",
      "Round 57/100, Clients: 10\n",
      "Global Test - Loss: 0.2714, Acc: 90.03%\n",
      "Round 58/100, Clients: 10\n",
      "Global Test - Loss: 0.2728, Acc: 90.06%\n",
      "Round 59/100, Clients: 10\n",
      "Global Test - Loss: 0.2701, Acc: 89.99%\n",
      "Round 60/100, Clients: 10\n",
      "Global Test - Loss: 0.2754, Acc: 89.92%\n",
      "Round 61/100, Clients: 10\n",
      "Global Test - Loss: 0.2658, Acc: 90.21%\n",
      "Round 62/100, Clients: 10\n",
      "Global Test - Loss: 0.2679, Acc: 90.19%\n",
      "Round 63/100, Clients: 10\n",
      "Global Test - Loss: 0.2634, Acc: 90.25%\n",
      "Round 64/100, Clients: 10\n",
      "Global Test - Loss: 0.2658, Acc: 90.32%\n",
      "Round 65/100, Clients: 10\n",
      "Global Test - Loss: 0.2611, Acc: 90.41%\n",
      "Round 66/100, Clients: 10\n",
      "Global Test - Loss: 0.2610, Acc: 90.50%\n",
      "Round 67/100, Clients: 10\n",
      "Global Test - Loss: 0.2592, Acc: 90.55%\n",
      "Round 68/100, Clients: 10\n",
      "Global Test - Loss: 0.2588, Acc: 90.50%\n",
      "Round 69/100, Clients: 10\n",
      "Global Test - Loss: 0.2564, Acc: 90.70%\n",
      "Round 70/100, Clients: 10\n",
      "Global Test - Loss: 0.2580, Acc: 90.57%\n",
      "Round 71/100, Clients: 10\n",
      "Global Test - Loss: 0.2537, Acc: 90.79%\n",
      "Round 72/100, Clients: 10\n",
      "Global Test - Loss: 0.2512, Acc: 90.73%\n",
      "Round 73/100, Clients: 10\n",
      "Global Test - Loss: 0.2468, Acc: 90.95%\n",
      "Round 74/100, Clients: 10\n",
      "Global Test - Loss: 0.2440, Acc: 91.00%\n",
      "Round 75/100, Clients: 10\n",
      "Global Test - Loss: 0.2476, Acc: 90.87%\n",
      "Round 76/100, Clients: 10\n",
      "Global Test - Loss: 0.2475, Acc: 90.99%\n",
      "Round 77/100, Clients: 10\n",
      "Global Test - Loss: 0.2459, Acc: 91.02%\n",
      "Round 78/100, Clients: 10\n",
      "Global Test - Loss: 0.2412, Acc: 91.19%\n",
      "Round 79/100, Clients: 10\n",
      "Global Test - Loss: 0.2420, Acc: 91.19%\n",
      "Round 80/100, Clients: 10\n",
      "Global Test - Loss: 0.2379, Acc: 91.33%\n",
      "Round 81/100, Clients: 10\n",
      "Global Test - Loss: 0.2412, Acc: 91.17%\n",
      "Round 82/100, Clients: 10\n",
      "Global Test - Loss: 0.2355, Acc: 91.43%\n",
      "Round 83/100, Clients: 10\n",
      "Global Test - Loss: 0.2345, Acc: 91.50%\n",
      "Round 84/100, Clients: 10\n",
      "Global Test - Loss: 0.2357, Acc: 91.39%\n",
      "Round 85/100, Clients: 10\n",
      "Global Test - Loss: 0.2330, Acc: 91.54%\n",
      "Round 86/100, Clients: 10\n",
      "Global Test - Loss: 0.2338, Acc: 91.49%\n",
      "Round 87/100, Clients: 10\n",
      "Global Test - Loss: 0.2335, Acc: 91.57%\n",
      "Round 88/100, Clients: 10\n",
      "Global Test - Loss: 0.2309, Acc: 91.64%\n",
      "Round 89/100, Clients: 10\n",
      "Global Test - Loss: 0.2261, Acc: 91.83%\n",
      "Round 90/100, Clients: 10\n",
      "Global Test - Loss: 0.2299, Acc: 91.67%\n",
      "Round 91/100, Clients: 10\n",
      "Global Test - Loss: 0.2277, Acc: 91.67%\n",
      "Round 92/100, Clients: 10\n",
      "Global Test - Loss: 0.2258, Acc: 91.71%\n",
      "Round 93/100, Clients: 10\n",
      "Global Test - Loss: 0.2235, Acc: 91.73%\n",
      "Round 94/100, Clients: 10\n",
      "Global Test - Loss: 0.2278, Acc: 91.70%\n",
      "Round 95/100, Clients: 10\n",
      "Global Test - Loss: 0.2228, Acc: 91.92%\n",
      "Round 96/100, Clients: 10\n",
      "Global Test - Loss: 0.2208, Acc: 91.90%\n",
      "Round 97/100, Clients: 10\n",
      "Global Test - Loss: 0.2212, Acc: 92.00%\n",
      "Round 98/100, Clients: 10\n",
      "Global Test - Loss: 0.2179, Acc: 91.98%\n",
      "Round 99/100, Clients: 10\n",
      "Global Test - Loss: 0.2167, Acc: 92.06%\n",
      "Round 100/100, Clients: 10\n",
      "Global Test - Loss: 0.2184, Acc: 92.07%\n",
      "[6] Done. Total time: 1056.88s\n"
     ]
    }
   ],
   "source": [
    "# FedAvg on Fashion-MNIST\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Model Definition (Fashion-MNIST CNN)\n",
    "# -----------------------------\n",
    "class Fashion_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),  # 修改为输入1通道\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3*3*128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)  # Fashion-MNIST 有10个类别\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.conv(x))\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Fashion-MNIST Partitioning (Non-IID)\n",
    "# -----------------------------\n",
    "def partition_data(dataset, num_clients=100):\n",
    "    labels = np.array(dataset.targets)\n",
    "    idx_by_class = [np.where(labels == i)[0] for i in range(10)]\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "    for c in range(10):\n",
    "        np.random.shuffle(idx_by_class[c])\n",
    "        parts = np.array_split(idx_by_class[c], num_clients)\n",
    "        for i in range(num_clients):\n",
    "            client_indices[i].extend(parts[i])\n",
    "    return [Subset(dataset, inds) for inds in client_indices]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Client Class (FedAvg)\n",
    "# -----------------------------\n",
    "class Client:\n",
    "    def __init__(self, model, data, lr, local_epochs, device):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.data = data\n",
    "        self.lr = lr\n",
    "        self.local_epochs = local_epochs\n",
    "        self.device = device\n",
    "\n",
    "    def train(self, global_model):\n",
    "        self.model.load_state_dict(global_model.state_dict())\n",
    "        self.model.train()\n",
    "\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=self.lr, momentum=0.9)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loader = DataLoader(self.data, batch_size=32, shuffle=True)\n",
    "\n",
    "        for epoch in range(self.local_epochs):\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        return copy.deepcopy(self.model.state_dict())\n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        loader = DataLoader(self.data, batch_size=64, shuffle=False)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "                total_loss += loss.item() * x.size(0)\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += x.size(0)\n",
    "        return total_loss / total, correct / total\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Server Class (FedAvg)\n",
    "# -----------------------------\n",
    "class Server:\n",
    "    def __init__(self, model, num_clients):\n",
    "        self.global_model = model\n",
    "        self.clients = []\n",
    "        self.num_clients = num_clients\n",
    "\n",
    "    def add_clients(self, client_list):\n",
    "        self.clients = client_list\n",
    "\n",
    "    def aggregate(self, client_states):\n",
    "        avg_state = copy.deepcopy(self.global_model.state_dict())\n",
    "        for k in avg_state:\n",
    "            avg_state[k] = sum(client[k] for client in client_states) / len(client_states)\n",
    "        self.global_model.load_state_dict(avg_state)\n",
    "\n",
    "    def federated_train(self, rounds):\n",
    "        for r in range(rounds):\n",
    "            selected = random.sample(self.clients, k=10)\n",
    "            client_states = []\n",
    "\n",
    "            print(f\"Round {r+1}/{rounds}, Clients: {len(selected)}\")\n",
    "\n",
    "            for client in selected:\n",
    "                state_dict = client.train(self.global_model)\n",
    "                client_states.append(state_dict)\n",
    "\n",
    "            self.aggregate(client_states)\n",
    "\n",
    "            # Evaluate on all clients\n",
    "            global_losses, global_accs = [], []\n",
    "            for client in self.clients:\n",
    "                client.model.load_state_dict(self.global_model.state_dict())\n",
    "                loss, acc = client.evaluate()\n",
    "                global_losses.append(loss)\n",
    "                global_accs.append(acc)\n",
    "\n",
    "            avg_loss = np.mean(global_losses)\n",
    "            avg_acc = np.mean(global_accs) * 100\n",
    "\n",
    "            print(f\"Global Test - Loss: {avg_loss:.4f}, Acc: {avg_acc:.2f}%\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Main Execution\n",
    "# -----------------------------\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    print(\"[0] Loading Fashion-MNIST...\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    fashion_train = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    print(f\"[1] Dataset loaded. Total samples: {len(fashion_train)}\")\n",
    "\n",
    "    print(\"[2] Partitioning data...\")\n",
    "    partition_start = time.time()\n",
    "    client_data = partition_data(fashion_train, num_clients=100)\n",
    "    print(f\"[3] Partition done in {time.time() - partition_start:.2f}s\")\n",
    "\n",
    "    print(\"[4] Initializing models...\")\n",
    "    global_model = Fashion_CNN().to(device)\n",
    "    server = Server(global_model, num_clients=100)\n",
    "    clients = [Client(global_model, data, lr=0.01, local_epochs=2, device=device) for data in client_data]\n",
    "    server.add_clients(clients)\n",
    "\n",
    "    print(\"[5] Starting federated training...\")\n",
    "    server.federated_train(rounds=100)\n",
    "\n",
    "    print(f\"[6] Done. Total time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce625b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[0] Loading Fashion-MNIST...\n",
      "[1] Dataset loaded. Total samples: 60000\n",
      "[2] Partitioning data...\n",
      "[3] Partition done in 0.00s\n",
      "[4] Initializing models...\n",
      "[5] Starting federated training...\n",
      "Round 1/100, Clients: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khalil\\AppData\\Local\\Temp\\ipykernel_27376\\2058025593.py:44: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  labels = np.array(dataset.targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Test - Loss: 2.2076, Acc: 38.61%\n",
      "Round 2/100, Clients: 10\n",
      "Global Test - Loss: 1.0993, Acc: 56.73%\n",
      "Round 3/100, Clients: 10\n",
      "Global Test - Loss: 0.8633, Acc: 69.06%\n",
      "Round 4/100, Clients: 10\n",
      "Global Test - Loss: 0.7728, Acc: 72.54%\n",
      "Round 5/100, Clients: 10\n",
      "Global Test - Loss: 0.7304, Acc: 73.38%\n",
      "Round 6/100, Clients: 10\n",
      "Global Test - Loss: 0.6563, Acc: 75.63%\n",
      "Round 7/100, Clients: 10\n",
      "Global Test - Loss: 0.6307, Acc: 76.30%\n",
      "Round 8/100, Clients: 10\n",
      "Global Test - Loss: 0.6087, Acc: 77.31%\n",
      "Round 9/100, Clients: 10\n",
      "Global Test - Loss: 0.5812, Acc: 77.95%\n",
      "Round 10/100, Clients: 10\n",
      "Global Test - Loss: 0.5636, Acc: 78.76%\n",
      "Round 11/100, Clients: 10\n",
      "Global Test - Loss: 0.5376, Acc: 79.44%\n",
      "Round 12/100, Clients: 10\n",
      "Global Test - Loss: 0.5222, Acc: 80.34%\n",
      "Round 13/100, Clients: 10\n",
      "Global Test - Loss: 0.5100, Acc: 81.01%\n",
      "Round 14/100, Clients: 10\n",
      "Global Test - Loss: 0.4854, Acc: 81.95%\n",
      "Round 15/100, Clients: 10\n",
      "Global Test - Loss: 0.4785, Acc: 82.12%\n",
      "Round 16/100, Clients: 10\n",
      "Global Test - Loss: 0.4723, Acc: 82.47%\n",
      "Round 17/100, Clients: 10\n",
      "Global Test - Loss: 0.4507, Acc: 83.34%\n",
      "Round 18/100, Clients: 10\n",
      "Global Test - Loss: 0.4417, Acc: 83.70%\n",
      "Round 19/100, Clients: 10\n",
      "Global Test - Loss: 0.4326, Acc: 84.24%\n",
      "Round 20/100, Clients: 10\n",
      "Global Test - Loss: 0.4270, Acc: 84.31%\n",
      "Round 21/100, Clients: 10\n",
      "Global Test - Loss: 0.4217, Acc: 84.48%\n",
      "Round 22/100, Clients: 10\n",
      "Global Test - Loss: 0.4139, Acc: 84.63%\n",
      "Round 23/100, Clients: 10\n",
      "Global Test - Loss: 0.3932, Acc: 85.67%\n",
      "Round 24/100, Clients: 10\n",
      "Global Test - Loss: 0.3898, Acc: 85.67%\n",
      "Round 25/100, Clients: 10\n",
      "Global Test - Loss: 0.3854, Acc: 85.88%\n",
      "Round 26/100, Clients: 10\n",
      "Global Test - Loss: 0.3726, Acc: 86.39%\n",
      "Round 27/100, Clients: 10\n",
      "Global Test - Loss: 0.3678, Acc: 86.47%\n",
      "Round 28/100, Clients: 10\n",
      "Global Test - Loss: 0.3618, Acc: 86.75%\n",
      "Round 29/100, Clients: 10\n",
      "Global Test - Loss: 0.3624, Acc: 86.61%\n",
      "Round 30/100, Clients: 10\n",
      "Global Test - Loss: 0.3528, Acc: 87.04%\n",
      "Round 31/100, Clients: 10\n",
      "Global Test - Loss: 0.3483, Acc: 87.18%\n",
      "Round 32/100, Clients: 10\n",
      "Global Test - Loss: 0.3416, Acc: 87.53%\n",
      "Round 33/100, Clients: 10\n",
      "Global Test - Loss: 0.3396, Acc: 87.57%\n",
      "Round 34/100, Clients: 10\n",
      "Global Test - Loss: 0.3297, Acc: 87.92%\n",
      "Round 35/100, Clients: 10\n",
      "Global Test - Loss: 0.3296, Acc: 87.84%\n",
      "Round 36/100, Clients: 10\n",
      "Global Test - Loss: 0.3276, Acc: 87.95%\n",
      "Round 37/100, Clients: 10\n",
      "Global Test - Loss: 0.3224, Acc: 88.15%\n",
      "Round 38/100, Clients: 10\n",
      "Global Test - Loss: 0.3192, Acc: 88.23%\n",
      "Round 39/100, Clients: 10\n",
      "Global Test - Loss: 0.3139, Acc: 88.43%\n",
      "Round 40/100, Clients: 10\n",
      "Global Test - Loss: 0.3188, Acc: 88.21%\n",
      "Round 41/100, Clients: 10\n",
      "Global Test - Loss: 0.3122, Acc: 88.50%\n",
      "Round 42/100, Clients: 10\n",
      "Global Test - Loss: 0.3041, Acc: 88.84%\n",
      "Round 43/100, Clients: 10\n",
      "Global Test - Loss: 0.3064, Acc: 88.69%\n",
      "Round 44/100, Clients: 10\n",
      "Global Test - Loss: 0.3015, Acc: 88.91%\n",
      "Round 45/100, Clients: 10\n",
      "Global Test - Loss: 0.3022, Acc: 88.98%\n",
      "Round 46/100, Clients: 10\n",
      "Global Test - Loss: 0.2952, Acc: 89.13%\n",
      "Round 47/100, Clients: 10\n",
      "Global Test - Loss: 0.2952, Acc: 89.25%\n",
      "Round 48/100, Clients: 10\n",
      "Global Test - Loss: 0.2905, Acc: 89.20%\n",
      "Round 49/100, Clients: 10\n",
      "Global Test - Loss: 0.2868, Acc: 89.46%\n",
      "Round 50/100, Clients: 10\n",
      "Global Test - Loss: 0.2866, Acc: 89.48%\n",
      "Round 51/100, Clients: 10\n",
      "Global Test - Loss: 0.2820, Acc: 89.59%\n",
      "Round 52/100, Clients: 10\n",
      "Global Test - Loss: 0.2818, Acc: 89.58%\n",
      "Round 53/100, Clients: 10\n",
      "Global Test - Loss: 0.2781, Acc: 89.81%\n",
      "Round 54/100, Clients: 10\n",
      "Global Test - Loss: 0.2767, Acc: 89.86%\n",
      "Round 55/100, Clients: 10\n",
      "Global Test - Loss: 0.2777, Acc: 89.90%\n",
      "Round 56/100, Clients: 10\n",
      "Global Test - Loss: 0.2751, Acc: 90.03%\n",
      "Round 57/100, Clients: 10\n",
      "Global Test - Loss: 0.2717, Acc: 90.07%\n",
      "Round 58/100, Clients: 10\n",
      "Global Test - Loss: 0.2777, Acc: 89.89%\n",
      "Round 59/100, Clients: 10\n",
      "Global Test - Loss: 0.2677, Acc: 90.25%\n",
      "Round 60/100, Clients: 10\n",
      "Global Test - Loss: 0.2694, Acc: 90.11%\n",
      "Round 61/100, Clients: 10\n",
      "Global Test - Loss: 0.2669, Acc: 90.26%\n",
      "Round 62/100, Clients: 10\n",
      "Global Test - Loss: 0.2651, Acc: 90.25%\n",
      "Round 63/100, Clients: 10\n",
      "Global Test - Loss: 0.2591, Acc: 90.38%\n",
      "Round 64/100, Clients: 10\n",
      "Global Test - Loss: 0.2586, Acc: 90.50%\n",
      "Round 65/100, Clients: 10\n",
      "Global Test - Loss: 0.2592, Acc: 90.47%\n",
      "Round 66/100, Clients: 10\n",
      "Global Test - Loss: 0.2596, Acc: 90.49%\n",
      "Round 67/100, Clients: 10\n",
      "Global Test - Loss: 0.2545, Acc: 90.76%\n",
      "Round 68/100, Clients: 10\n",
      "Global Test - Loss: 0.2535, Acc: 90.77%\n",
      "Round 69/100, Clients: 10\n",
      "Global Test - Loss: 0.2560, Acc: 90.64%\n",
      "Round 70/100, Clients: 10\n",
      "Global Test - Loss: 0.2535, Acc: 90.72%\n",
      "Round 71/100, Clients: 10\n",
      "Global Test - Loss: 0.2536, Acc: 90.74%\n",
      "Round 72/100, Clients: 10\n",
      "Global Test - Loss: 0.2501, Acc: 90.78%\n",
      "Round 73/100, Clients: 10\n",
      "Global Test - Loss: 0.2481, Acc: 90.98%\n",
      "Round 74/100, Clients: 10\n",
      "Global Test - Loss: 0.2452, Acc: 91.05%\n",
      "Round 75/100, Clients: 10\n",
      "Global Test - Loss: 0.2471, Acc: 91.04%\n",
      "Round 76/100, Clients: 10\n",
      "Global Test - Loss: 0.2427, Acc: 90.98%\n",
      "Round 77/100, Clients: 10\n",
      "Global Test - Loss: 0.2414, Acc: 91.23%\n",
      "Round 78/100, Clients: 10\n",
      "Global Test - Loss: 0.2462, Acc: 91.14%\n",
      "Round 79/100, Clients: 10\n",
      "Global Test - Loss: 0.2388, Acc: 91.26%\n",
      "Round 80/100, Clients: 10\n",
      "Global Test - Loss: 0.2397, Acc: 91.24%\n",
      "Round 81/100, Clients: 10\n",
      "Global Test - Loss: 0.2389, Acc: 91.19%\n",
      "Round 82/100, Clients: 10\n",
      "Global Test - Loss: 0.2352, Acc: 91.31%\n",
      "Round 83/100, Clients: 10\n",
      "Global Test - Loss: 0.2383, Acc: 91.17%\n",
      "Round 84/100, Clients: 10\n",
      "Global Test - Loss: 0.2326, Acc: 91.49%\n",
      "Round 85/100, Clients: 10\n",
      "Global Test - Loss: 0.2303, Acc: 91.54%\n",
      "Round 86/100, Clients: 10\n",
      "Global Test - Loss: 0.2295, Acc: 91.65%\n",
      "Round 87/100, Clients: 10\n",
      "Global Test - Loss: 0.2307, Acc: 91.52%\n",
      "Round 88/100, Clients: 10\n",
      "Global Test - Loss: 0.2313, Acc: 91.49%\n",
      "Round 89/100, Clients: 10\n",
      "Global Test - Loss: 0.2281, Acc: 91.54%\n",
      "Round 90/100, Clients: 10\n",
      "Global Test - Loss: 0.2323, Acc: 91.61%\n",
      "Round 91/100, Clients: 10\n",
      "Global Test - Loss: 0.2256, Acc: 91.73%\n",
      "Round 92/100, Clients: 10\n",
      "Global Test - Loss: 0.2239, Acc: 91.79%\n",
      "Round 93/100, Clients: 10\n",
      "Global Test - Loss: 0.2211, Acc: 91.87%\n",
      "Round 94/100, Clients: 10\n",
      "Global Test - Loss: 0.2222, Acc: 91.78%\n",
      "Round 95/100, Clients: 10\n",
      "Global Test - Loss: 0.2213, Acc: 91.85%\n",
      "Round 96/100, Clients: 10\n",
      "Global Test - Loss: 0.2244, Acc: 91.76%\n",
      "Round 97/100, Clients: 10\n",
      "Global Test - Loss: 0.2240, Acc: 91.78%\n",
      "Round 98/100, Clients: 10\n",
      "Global Test - Loss: 0.2227, Acc: 91.93%\n",
      "Round 99/100, Clients: 10\n",
      "Global Test - Loss: 0.2214, Acc: 92.07%\n",
      "Round 100/100, Clients: 10\n",
      "Global Test - Loss: 0.2189, Acc: 91.99%\n",
      "[6] Done. Total time: 1097.76s\n"
     ]
    }
   ],
   "source": [
    "# SCAFFOLD on Fashion-MNIST\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Model Definition (Fashion-MNIST CNN)\n",
    "# -----------------------------\n",
    "class Fashion_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),  # 修改为1通道\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3*3*128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)  # Fashion-MNIST 有10类\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.conv(x))\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Partitioning (Non-IID)\n",
    "# -----------------------------\n",
    "def partition_data(dataset, num_clients=100):\n",
    "    labels = np.array(dataset.targets)\n",
    "    idx_by_class = [np.where(labels == i)[0] for i in range(10)]\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "    for c in range(10):\n",
    "        np.random.shuffle(idx_by_class[c])\n",
    "        parts = np.array_split(idx_by_class[c], num_clients)\n",
    "        for i in range(num_clients):\n",
    "            client_indices[i].extend(parts[i])\n",
    "    return [Subset(dataset, inds) for inds in client_indices]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Client Class (SCAFFOLD)\n",
    "# -----------------------------\n",
    "class Client:\n",
    "    def __init__(self, model, data, lr, local_epochs, device):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.data = data\n",
    "        self.lr = lr\n",
    "        self.local_epochs = local_epochs\n",
    "        self.device = device\n",
    "        self.ci = {k: torch.zeros_like(v) for k, v in self.model.state_dict().items()}\n",
    "\n",
    "    def train(self, global_model, global_control):\n",
    "        self.model.load_state_dict(global_model.state_dict())\n",
    "        self.model.train()\n",
    "\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=self.lr, momentum=0.9)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loader = DataLoader(self.data, batch_size=32, shuffle=True)\n",
    "\n",
    "        for epoch in range(self.local_epochs):\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "\n",
    "                # SCAFFOLD correction term\n",
    "                control = torch.tensor(0.0, device=self.device)\n",
    "\n",
    "                model_state = self.model.state_dict()\n",
    "                global_state = global_model.state_dict()\n",
    "\n",
    "                for name in model_state:\n",
    "                    p = model_state[name]\n",
    "                    w_t = global_state[name]\n",
    "                    c = global_control[name]\n",
    "                    ci = self.ci[name]\n",
    "                    control += ((p - w_t) * (c - ci)).sum()\n",
    "\n",
    "                loss += 0.5 * control\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Update local control variates\n",
    "        delta_ci = {}\n",
    "        with torch.no_grad():\n",
    "            for k in self.model.state_dict().keys():\n",
    "                delta = global_control[k] - self.ci[k] + \\\n",
    "                        (self.model.state_dict()[k] - global_model.state_dict()[k]) / (self.local_epochs * self.lr)\n",
    "                delta_ci[k] = delta\n",
    "                self.ci[k] += delta\n",
    "\n",
    "        return copy.deepcopy(self.model.state_dict()), delta_ci\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        loader = DataLoader(self.data, batch_size=64, shuffle=False)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "                total_loss += loss.item() * x.size(0)\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += x.size(0)\n",
    "        return total_loss / total, correct / total\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Server Class (SCAFFOLD)\n",
    "# -----------------------------\n",
    "class Server:\n",
    "    def __init__(self, model, num_clients):\n",
    "        self.global_model = model\n",
    "        self.clients = []\n",
    "        self.num_clients = num_clients\n",
    "        self.global_control = {k: torch.zeros_like(v) for k, v in self.global_model.state_dict().items()}\n",
    "\n",
    "    def add_clients(self, client_list):\n",
    "        self.clients = client_list\n",
    "\n",
    "    def aggregate(self, client_states):\n",
    "        avg_state = copy.deepcopy(self.global_model.state_dict())\n",
    "        for k in avg_state:\n",
    "            avg_state[k] = sum(client[k] for client in client_states) / len(client_states)\n",
    "        self.global_model.load_state_dict(avg_state)\n",
    "\n",
    "    def update_control(self, delta_controls):\n",
    "        for k in self.global_control:\n",
    "            self.global_control[k] += sum(delta[k] for delta in delta_controls) / len(delta_controls)\n",
    "\n",
    "    def federated_train(self, rounds):\n",
    "        for r in range(rounds):\n",
    "            selected = random.sample(self.clients, k=10)\n",
    "            client_states, delta_controls = [], []\n",
    "\n",
    "            print(f\"Round {r+1}/{rounds}, Clients: {len(selected)}\")\n",
    "\n",
    "            for client in selected:\n",
    "                state_dict, delta_ci = client.train(self.global_model, self.global_control)\n",
    "                client_states.append(state_dict)\n",
    "                delta_controls.append(delta_ci)\n",
    "\n",
    "            self.aggregate(client_states)\n",
    "            self.update_control(delta_controls)\n",
    "\n",
    "            # Evaluate\n",
    "            global_losses, global_accs = [], []\n",
    "            for client in self.clients:\n",
    "                client.model.load_state_dict(self.global_model.state_dict())\n",
    "                loss, acc = client.evaluate()\n",
    "                global_losses.append(loss)\n",
    "                global_accs.append(acc)\n",
    "\n",
    "            avg_loss = np.mean(global_losses)\n",
    "            avg_acc = np.mean(global_accs) * 100\n",
    "\n",
    "            print(f\"Global Test - Loss: {avg_loss:.4f}, Acc: {avg_acc:.2f}%\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Main Execution\n",
    "# -----------------------------\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    print(\"[0] Loading Fashion-MNIST...\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    fashion_train = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    print(f\"[1] Dataset loaded. Total samples: {len(fashion_train)}\")\n",
    "\n",
    "    print(\"[2] Partitioning data...\")\n",
    "    partition_start = time.time()\n",
    "    client_data = partition_data(fashion_train, num_clients=100)\n",
    "    print(f\"[3] Partition done in {time.time() - partition_start:.2f}s\")\n",
    "\n",
    "    print(\"[4] Initializing models...\")\n",
    "    global_model = Fashion_CNN().to(device)\n",
    "    server = Server(global_model, num_clients=100)\n",
    "    clients = [Client(global_model, data, lr=0.01, local_epochs=2, device=device) for data in client_data]\n",
    "    server.add_clients(clients)\n",
    "\n",
    "    print(\"[5] Starting federated training...\")\n",
    "    server.federated_train(rounds=100)\n",
    "\n",
    "    print(f\"[6] Done. Total time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d07450d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[0] Loading Fashion-MNIST...\n",
      "[1] Dataset loaded. Total samples: 60000\n",
      "[2] Partitioning data...\n",
      "[3] Partition done in 0.01s\n",
      "[4] Initializing models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khalil\\AppData\\Local\\Temp\\ipykernel_40796\\3865977535.py:44: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  labels = np.array(dataset.targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] Starting federated training...\n",
      "Round 1/100, Clients: 10\n",
      "Global Test - Loss: 2.3047, Acc: 3.92%\n",
      "Round 2/100, Clients: 10\n",
      "Global Test - Loss: 2.3039, Acc: 5.54%\n",
      "Round 3/100, Clients: 10\n",
      "Global Test - Loss: 2.3032, Acc: 7.92%\n",
      "Round 4/100, Clients: 10\n",
      "Global Test - Loss: 2.3025, Acc: 8.83%\n",
      "Round 5/100, Clients: 10\n",
      "Global Test - Loss: 2.3018, Acc: 9.68%\n",
      "Round 6/100, Clients: 10\n",
      "Global Test - Loss: 2.3011, Acc: 9.75%\n",
      "Round 7/100, Clients: 10\n",
      "Global Test - Loss: 2.3004, Acc: 9.98%\n",
      "Round 8/100, Clients: 10\n",
      "Global Test - Loss: 2.2996, Acc: 10.00%\n",
      "Round 9/100, Clients: 10\n",
      "Global Test - Loss: 2.2988, Acc: 10.00%\n",
      "Round 10/100, Clients: 10\n",
      "Global Test - Loss: 2.2979, Acc: 10.00%\n",
      "Round 11/100, Clients: 10\n",
      "Global Test - Loss: 2.2969, Acc: 10.00%\n",
      "Round 12/100, Clients: 10\n",
      "Global Test - Loss: 2.2953, Acc: 10.00%\n",
      "Round 13/100, Clients: 10\n",
      "Global Test - Loss: 2.2924, Acc: 10.01%\n",
      "Round 14/100, Clients: 10\n",
      "Global Test - Loss: 2.2864, Acc: 10.01%\n",
      "Round 15/100, Clients: 10\n",
      "Global Test - Loss: 2.2723, Acc: 15.72%\n",
      "Round 16/100, Clients: 10\n",
      "Global Test - Loss: 2.2286, Acc: 15.39%\n",
      "Round 17/100, Clients: 10\n",
      "Global Test - Loss: 2.0518, Acc: 24.35%\n",
      "Round 18/100, Clients: 10\n",
      "Global Test - Loss: 1.5697, Acc: 51.00%\n",
      "Round 19/100, Clients: 10\n",
      "Global Test - Loss: 1.2088, Acc: 50.15%\n",
      "Round 20/100, Clients: 10\n",
      "Global Test - Loss: 1.0619, Acc: 57.35%\n",
      "Round 21/100, Clients: 10\n",
      "Global Test - Loss: 0.9913, Acc: 61.94%\n",
      "Round 22/100, Clients: 10\n",
      "Global Test - Loss: 0.9466, Acc: 66.53%\n",
      "Round 23/100, Clients: 10\n",
      "Global Test - Loss: 0.9346, Acc: 63.69%\n",
      "Round 24/100, Clients: 10\n",
      "Global Test - Loss: 0.9540, Acc: 60.78%\n",
      "Round 25/100, Clients: 10\n",
      "Global Test - Loss: 0.8990, Acc: 66.74%\n",
      "Round 26/100, Clients: 10\n",
      "Global Test - Loss: 0.9240, Acc: 68.40%\n",
      "Round 27/100, Clients: 10\n",
      "Global Test - Loss: 0.8893, Acc: 69.67%\n",
      "Round 28/100, Clients: 10\n",
      "Global Test - Loss: 0.8558, Acc: 69.97%\n",
      "Round 29/100, Clients: 10\n",
      "Global Test - Loss: 0.8637, Acc: 70.95%\n",
      "Round 30/100, Clients: 10\n",
      "Global Test - Loss: 0.8457, Acc: 70.84%\n",
      "Round 31/100, Clients: 10\n",
      "Global Test - Loss: 0.8367, Acc: 69.48%\n",
      "Round 32/100, Clients: 10\n",
      "Global Test - Loss: 0.8200, Acc: 70.04%\n",
      "Round 33/100, Clients: 10\n",
      "Global Test - Loss: 0.8279, Acc: 70.44%\n",
      "Round 34/100, Clients: 10\n",
      "Global Test - Loss: 0.8353, Acc: 69.60%\n",
      "Round 35/100, Clients: 10\n",
      "Global Test - Loss: 0.8603, Acc: 69.84%\n",
      "Round 36/100, Clients: 10\n",
      "Global Test - Loss: 0.8166, Acc: 70.31%\n",
      "Round 37/100, Clients: 10\n",
      "Global Test - Loss: 0.8327, Acc: 71.29%\n",
      "Round 38/100, Clients: 10\n",
      "Global Test - Loss: 0.8335, Acc: 70.85%\n",
      "Round 39/100, Clients: 10\n",
      "Global Test - Loss: 0.8335, Acc: 70.83%\n",
      "Round 40/100, Clients: 10\n",
      "Global Test - Loss: 0.8018, Acc: 71.45%\n",
      "Round 41/100, Clients: 10\n",
      "Global Test - Loss: 0.8063, Acc: 70.95%\n",
      "Round 42/100, Clients: 10\n",
      "Global Test - Loss: 0.7946, Acc: 71.39%\n",
      "Round 43/100, Clients: 10\n",
      "Global Test - Loss: 0.8040, Acc: 71.03%\n",
      "Round 44/100, Clients: 10\n",
      "Global Test - Loss: 0.8086, Acc: 70.71%\n",
      "Round 45/100, Clients: 10\n",
      "Global Test - Loss: 0.7922, Acc: 72.29%\n",
      "Round 46/100, Clients: 10\n",
      "Global Test - Loss: 0.7886, Acc: 71.89%\n",
      "Round 47/100, Clients: 10\n",
      "Global Test - Loss: 0.7938, Acc: 72.17%\n",
      "Round 48/100, Clients: 10\n",
      "Global Test - Loss: 0.7867, Acc: 72.43%\n",
      "Round 49/100, Clients: 10\n",
      "Global Test - Loss: 0.7692, Acc: 72.54%\n",
      "Round 50/100, Clients: 10\n",
      "Global Test - Loss: 0.7967, Acc: 70.62%\n",
      "Round 51/100, Clients: 10\n",
      "Global Test - Loss: 0.7814, Acc: 72.61%\n",
      "Round 52/100, Clients: 10\n",
      "Global Test - Loss: 0.7665, Acc: 72.81%\n",
      "Round 53/100, Clients: 10\n",
      "Global Test - Loss: 0.7876, Acc: 72.18%\n",
      "Round 54/100, Clients: 10\n",
      "Global Test - Loss: 0.7693, Acc: 72.42%\n",
      "Round 55/100, Clients: 10\n",
      "Global Test - Loss: 0.7558, Acc: 73.21%\n",
      "Round 56/100, Clients: 10\n",
      "Global Test - Loss: 0.7571, Acc: 72.51%\n",
      "Round 57/100, Clients: 10\n",
      "Global Test - Loss: 0.7791, Acc: 72.62%\n",
      "Round 58/100, Clients: 10\n",
      "Global Test - Loss: 0.7857, Acc: 71.52%\n",
      "Round 59/100, Clients: 10\n",
      "Global Test - Loss: 0.7750, Acc: 72.62%\n",
      "Round 60/100, Clients: 10\n",
      "Global Test - Loss: 0.7747, Acc: 73.11%\n",
      "Round 61/100, Clients: 10\n",
      "Global Test - Loss: 0.7785, Acc: 72.94%\n",
      "Round 62/100, Clients: 10\n",
      "Global Test - Loss: 0.7702, Acc: 72.73%\n",
      "Round 63/100, Clients: 10\n",
      "Global Test - Loss: 0.7828, Acc: 73.08%\n",
      "Round 64/100, Clients: 10\n",
      "Global Test - Loss: 0.7706, Acc: 71.99%\n",
      "Round 65/100, Clients: 10\n",
      "Global Test - Loss: 0.7588, Acc: 73.34%\n",
      "Round 66/100, Clients: 10\n",
      "Global Test - Loss: 0.7590, Acc: 73.11%\n",
      "Round 67/100, Clients: 10\n",
      "Global Test - Loss: 0.7787, Acc: 72.57%\n",
      "Round 68/100, Clients: 10\n",
      "Global Test - Loss: 0.7604, Acc: 73.40%\n",
      "Round 69/100, Clients: 10\n",
      "Global Test - Loss: 0.7579, Acc: 72.00%\n",
      "Round 70/100, Clients: 10\n",
      "Global Test - Loss: 0.7361, Acc: 73.84%\n",
      "Round 71/100, Clients: 10\n",
      "Global Test - Loss: 0.7521, Acc: 73.10%\n",
      "Round 72/100, Clients: 10\n",
      "Global Test - Loss: 0.7701, Acc: 72.28%\n",
      "Round 73/100, Clients: 10\n",
      "Global Test - Loss: 0.7573, Acc: 72.70%\n",
      "Round 74/100, Clients: 10\n",
      "Global Test - Loss: 0.7444, Acc: 73.26%\n",
      "Round 75/100, Clients: 10\n",
      "Global Test - Loss: 0.7654, Acc: 71.96%\n",
      "Round 76/100, Clients: 10\n",
      "Global Test - Loss: 0.7604, Acc: 73.06%\n",
      "Round 77/100, Clients: 10\n",
      "Global Test - Loss: 0.7399, Acc: 72.89%\n",
      "Round 78/100, Clients: 10\n",
      "Global Test - Loss: 0.7583, Acc: 73.25%\n",
      "Round 79/100, Clients: 10\n",
      "Global Test - Loss: 0.7558, Acc: 72.63%\n",
      "Round 80/100, Clients: 10\n",
      "Global Test - Loss: 0.7700, Acc: 73.20%\n",
      "Round 81/100, Clients: 10\n",
      "Global Test - Loss: 0.7319, Acc: 73.19%\n",
      "Round 82/100, Clients: 10\n",
      "Global Test - Loss: 0.7837, Acc: 70.97%\n",
      "Round 83/100, Clients: 10\n",
      "Global Test - Loss: 0.7333, Acc: 73.39%\n",
      "Round 84/100, Clients: 10\n",
      "Global Test - Loss: 0.7317, Acc: 73.57%\n",
      "Round 85/100, Clients: 10\n",
      "Global Test - Loss: 0.7406, Acc: 73.06%\n",
      "Round 86/100, Clients: 10\n",
      "Global Test - Loss: 0.7282, Acc: 73.12%\n",
      "Round 87/100, Clients: 10\n",
      "Global Test - Loss: 0.7501, Acc: 71.78%\n",
      "Round 88/100, Clients: 10\n",
      "Global Test - Loss: 0.7526, Acc: 73.33%\n",
      "Round 89/100, Clients: 10\n",
      "Global Test - Loss: 0.7510, Acc: 73.52%\n",
      "Round 90/100, Clients: 10\n",
      "Global Test - Loss: 0.7358, Acc: 73.51%\n",
      "Round 91/100, Clients: 10\n",
      "Global Test - Loss: 0.7302, Acc: 73.95%\n",
      "Round 92/100, Clients: 10\n",
      "Global Test - Loss: 0.7416, Acc: 73.61%\n",
      "Round 93/100, Clients: 10\n",
      "Global Test - Loss: 0.7434, Acc: 72.95%\n",
      "Round 94/100, Clients: 10\n",
      "Global Test - Loss: 0.7385, Acc: 73.47%\n",
      "Round 95/100, Clients: 10\n",
      "Global Test - Loss: 0.7319, Acc: 73.80%\n",
      "Round 96/100, Clients: 10\n",
      "Global Test - Loss: 0.7548, Acc: 71.90%\n",
      "Round 97/100, Clients: 10\n",
      "Global Test - Loss: 0.7256, Acc: 73.97%\n",
      "Round 98/100, Clients: 10\n",
      "Global Test - Loss: 0.7427, Acc: 73.48%\n",
      "Round 99/100, Clients: 10\n",
      "Global Test - Loss: 0.7207, Acc: 73.77%\n",
      "Round 100/100, Clients: 10\n",
      "Global Test - Loss: 0.7536, Acc: 73.29%\n",
      "[6] Done. Total time: 1212.24s\n"
     ]
    }
   ],
   "source": [
    "# FedICT on Fashion-MNIST (fixed and full version)\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Model Definition (Fashion-MNIST CNN)\n",
    "# -----------------------------\n",
    "class Fashion_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3*3*128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.conv(x))\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Partitioning (Non-IID)\n",
    "# -----------------------------\n",
    "def partition_data(dataset, num_clients=100):\n",
    "    labels = np.array(dataset.targets)\n",
    "    idx_by_class = [np.where(labels == i)[0] for i in range(10)]\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "    for c in range(10):\n",
    "        np.random.shuffle(idx_by_class[c])\n",
    "        parts = np.array_split(idx_by_class[c], num_clients)\n",
    "        for i in range(num_clients):\n",
    "            client_indices[i].extend(parts[i])\n",
    "    return [Subset(dataset, inds) for inds in client_indices]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Client Class (FedICT)\n",
    "# -----------------------------\n",
    "class Client:\n",
    "    def __init__(self, model, data, lr, local_epochs, device):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.data = data\n",
    "        self.lr = lr\n",
    "        self.local_epochs = local_epochs\n",
    "        self.device = device\n",
    "\n",
    "    def local_train(self):\n",
    "        self.model.train()\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=self.lr, momentum=0.9)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loader = DataLoader(self.data, batch_size=32, shuffle=True)\n",
    "\n",
    "        for epoch in range(self.local_epochs):\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        return copy.deepcopy(self.model.state_dict())\n",
    "\n",
    "    def get_data_and_logits(self):\n",
    "        self.model.eval()\n",
    "        loader = DataLoader(self.data, batch_size=64, shuffle=False)\n",
    "        x_all, logits_all, targets_all = [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x_device = x.to(self.device)\n",
    "                logits = self.model(x_device)\n",
    "                x_all.append(x.cpu())\n",
    "                logits_all.append(logits.cpu())\n",
    "                targets_all.append(y)\n",
    "\n",
    "        x_all = torch.cat(x_all, dim=0)\n",
    "        logits_all = torch.cat(logits_all, dim=0)\n",
    "        targets_all = torch.cat(targets_all, dim=0)\n",
    "        return x_all, logits_all, targets_all\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        loader = DataLoader(self.data, batch_size=64, shuffle=False)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "                total_loss += loss.item() * x.size(0)\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += x.size(0)\n",
    "        return total_loss / total, correct / total\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Server Class (FedICT)\n",
    "# -----------------------------\n",
    "class Server:\n",
    "    def __init__(self, model, num_clients):\n",
    "        self.global_model = model\n",
    "        self.clients = []\n",
    "        self.num_clients = num_clients\n",
    "\n",
    "    def add_clients(self, client_list):\n",
    "        self.clients = client_list\n",
    "\n",
    "    def federated_train(self, rounds):\n",
    "        for r in range(rounds):\n",
    "            selected = random.sample(self.clients, k=10)\n",
    "            client_states = []\n",
    "            all_x, all_logits, all_targets = [], [], []\n",
    "\n",
    "            print(f\"Round {r+1}/{rounds}, Clients: {len(selected)}\")\n",
    "\n",
    "            for client in selected:\n",
    "                state_dict = client.local_train()\n",
    "                client_states.append(state_dict)\n",
    "\n",
    "                client.model.load_state_dict(state_dict)\n",
    "                x, logits, targets = client.get_data_and_logits()\n",
    "                all_x.append(x)\n",
    "                all_logits.append(logits)\n",
    "                all_targets.append(targets)\n",
    "\n",
    "            concat_x = torch.cat(all_x, dim=0)\n",
    "            concat_logits = torch.cat(all_logits, dim=0)\n",
    "            pseudo_labels = concat_logits.softmax(dim=1)\n",
    "\n",
    "            # Update global model using distillation\n",
    "            self.global_model.train()\n",
    "            optimizer = optim.SGD(self.global_model.parameters(), lr=0.001, momentum=0.9)\n",
    "            loader = DataLoader(TensorDataset(concat_x, pseudo_labels), batch_size=64, shuffle=True)\n",
    "\n",
    "            for x_batch, pseudo_y in loader:\n",
    "                x_batch = x_batch.to(self.global_model.fc[-1].weight.device)\n",
    "                pseudo_y = pseudo_y.to(self.global_model.fc[-1].weight.device)\n",
    "                optimizer.zero_grad()\n",
    "                output = self.global_model(x_batch)\n",
    "                loss = nn.KLDivLoss(reduction=\"batchmean\")(output.log_softmax(dim=1), pseudo_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Evaluate\n",
    "            global_losses, global_accs = [], []\n",
    "            for client in self.clients:\n",
    "                client.model.load_state_dict(self.global_model.state_dict())\n",
    "                loss, acc = client.evaluate()\n",
    "                global_losses.append(loss)\n",
    "                global_accs.append(acc)\n",
    "\n",
    "            avg_loss = np.mean(global_losses)\n",
    "            avg_acc = np.mean(global_accs) * 100\n",
    "\n",
    "            print(f\"Global Test - Loss: {avg_loss:.4f}, Acc: {avg_acc:.2f}%\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Main Execution\n",
    "# -----------------------------\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    print(\"[0] Loading Fashion-MNIST...\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    fashion_train = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    print(f\"[1] Dataset loaded. Total samples: {len(fashion_train)}\")\n",
    "\n",
    "    print(\"[2] Partitioning data...\")\n",
    "    partition_start = time.time()\n",
    "    client_data = partition_data(fashion_train, num_clients=100)\n",
    "    print(f\"[3] Partition done in {time.time() - partition_start:.2f}s\")\n",
    "\n",
    "    print(\"[4] Initializing models...\")\n",
    "    global_model = Fashion_CNN().to(device)\n",
    "    server = Server(global_model, num_clients=100)\n",
    "    clients = [Client(global_model, data, lr=0.01, local_epochs=2, device=device) for data in client_data]\n",
    "    server.add_clients(clients)\n",
    "\n",
    "    print(\"[5] Starting federated training...\")\n",
    "    server.federated_train(rounds=100)\n",
    "\n",
    "    print(f\"[6] Done. Total time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c36ef3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[0] Loading Fashion-MNIST...\n",
      "[1] Dataset loaded. Total samples: 60000\n",
      "[2] Partitioning data...\n",
      "[3] Partition done in 0.01s\n",
      "[4] Initializing models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khalil\\AppData\\Local\\Temp\\ipykernel_27376\\3171890922.py:44: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  labels = np.array(dataset.targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] Starting federated training...\n",
      "Round 1/100, Clients: 10\n",
      "Global Test - Loss: 2.1617, Acc: 44.21%\n",
      "Round 2/100, Clients: 10\n",
      "Global Test - Loss: 1.0101, Acc: 62.47%\n",
      "Round 3/100, Clients: 10\n",
      "Global Test - Loss: 0.7903, Acc: 69.46%\n",
      "Round 4/100, Clients: 10\n",
      "Global Test - Loss: 0.6855, Acc: 73.90%\n",
      "Round 5/100, Clients: 10\n",
      "Global Test - Loss: 0.6475, Acc: 75.84%\n",
      "Round 6/100, Clients: 10\n",
      "Global Test - Loss: 0.6031, Acc: 76.86%\n",
      "Round 7/100, Clients: 10\n",
      "Global Test - Loss: 0.5769, Acc: 78.48%\n",
      "Round 8/100, Clients: 10\n",
      "Global Test - Loss: 0.5674, Acc: 78.92%\n",
      "Round 9/100, Clients: 10\n",
      "Global Test - Loss: 0.5458, Acc: 79.38%\n",
      "Round 10/100, Clients: 10\n",
      "Global Test - Loss: 0.5155, Acc: 80.80%\n",
      "Round 11/100, Clients: 10\n",
      "Global Test - Loss: 0.5025, Acc: 81.58%\n",
      "Round 12/100, Clients: 10\n",
      "Global Test - Loss: 0.4842, Acc: 81.97%\n",
      "Round 13/100, Clients: 10\n",
      "Global Test - Loss: 0.4682, Acc: 82.75%\n",
      "Round 14/100, Clients: 10\n",
      "Global Test - Loss: 0.4637, Acc: 82.74%\n",
      "Round 15/100, Clients: 10\n",
      "Global Test - Loss: 0.4436, Acc: 83.75%\n",
      "Round 16/100, Clients: 10\n",
      "Global Test - Loss: 0.4304, Acc: 84.28%\n",
      "Round 17/100, Clients: 10\n",
      "Global Test - Loss: 0.4294, Acc: 84.28%\n",
      "Round 18/100, Clients: 10\n",
      "Global Test - Loss: 0.4177, Acc: 84.60%\n",
      "Round 19/100, Clients: 10\n",
      "Global Test - Loss: 0.4095, Acc: 84.98%\n",
      "Round 20/100, Clients: 10\n",
      "Global Test - Loss: 0.3993, Acc: 85.29%\n",
      "Round 21/100, Clients: 10\n",
      "Global Test - Loss: 0.3930, Acc: 85.70%\n",
      "Round 22/100, Clients: 10\n",
      "Global Test - Loss: 0.3923, Acc: 85.68%\n",
      "Round 23/100, Clients: 10\n",
      "Global Test - Loss: 0.3791, Acc: 86.02%\n",
      "Round 24/100, Clients: 10\n",
      "Global Test - Loss: 0.3797, Acc: 86.06%\n",
      "Round 25/100, Clients: 10\n",
      "Global Test - Loss: 0.3709, Acc: 86.45%\n",
      "Round 26/100, Clients: 10\n",
      "Global Test - Loss: 0.3594, Acc: 86.76%\n",
      "Round 27/100, Clients: 10\n",
      "Global Test - Loss: 0.3576, Acc: 86.83%\n",
      "Round 28/100, Clients: 10\n",
      "Global Test - Loss: 0.3547, Acc: 87.03%\n",
      "Round 29/100, Clients: 10\n",
      "Global Test - Loss: 0.3528, Acc: 87.00%\n",
      "Round 30/100, Clients: 10\n",
      "Global Test - Loss: 0.3507, Acc: 87.13%\n",
      "Round 31/100, Clients: 10\n",
      "Global Test - Loss: 0.3449, Acc: 87.33%\n",
      "Round 32/100, Clients: 10\n",
      "Global Test - Loss: 0.3340, Acc: 87.76%\n",
      "Round 33/100, Clients: 10\n",
      "Global Test - Loss: 0.3293, Acc: 87.77%\n",
      "Round 34/100, Clients: 10\n",
      "Global Test - Loss: 0.3353, Acc: 87.75%\n",
      "Round 35/100, Clients: 10\n",
      "Global Test - Loss: 0.3307, Acc: 87.73%\n",
      "Round 36/100, Clients: 10\n",
      "Global Test - Loss: 0.3244, Acc: 88.07%\n",
      "Round 37/100, Clients: 10\n",
      "Global Test - Loss: 0.3208, Acc: 88.27%\n",
      "Round 38/100, Clients: 10\n",
      "Global Test - Loss: 0.3234, Acc: 88.28%\n",
      "Round 39/100, Clients: 10\n",
      "Global Test - Loss: 0.3167, Acc: 88.33%\n",
      "Round 40/100, Clients: 10\n",
      "Global Test - Loss: 0.3147, Acc: 88.38%\n",
      "Round 41/100, Clients: 10\n",
      "Global Test - Loss: 0.3077, Acc: 88.65%\n",
      "Round 42/100, Clients: 10\n",
      "Global Test - Loss: 0.3040, Acc: 88.83%\n",
      "Round 43/100, Clients: 10\n",
      "Global Test - Loss: 0.3053, Acc: 88.76%\n",
      "Round 44/100, Clients: 10\n",
      "Global Test - Loss: 0.3008, Acc: 88.95%\n",
      "Round 45/100, Clients: 10\n",
      "Global Test - Loss: 0.3004, Acc: 89.01%\n",
      "Round 46/100, Clients: 10\n",
      "Global Test - Loss: 0.2995, Acc: 89.00%\n",
      "Round 47/100, Clients: 10\n",
      "Global Test - Loss: 0.3007, Acc: 89.09%\n",
      "Round 48/100, Clients: 10\n",
      "Global Test - Loss: 0.2942, Acc: 89.15%\n",
      "Round 49/100, Clients: 10\n",
      "Global Test - Loss: 0.2904, Acc: 89.40%\n",
      "Round 50/100, Clients: 10\n",
      "Global Test - Loss: 0.2896, Acc: 89.31%\n",
      "Round 51/100, Clients: 10\n",
      "Global Test - Loss: 0.2845, Acc: 89.53%\n",
      "Round 52/100, Clients: 10\n",
      "Global Test - Loss: 0.2887, Acc: 89.42%\n",
      "Round 53/100, Clients: 10\n",
      "Global Test - Loss: 0.2903, Acc: 89.49%\n",
      "Round 54/100, Clients: 10\n",
      "Global Test - Loss: 0.2864, Acc: 89.60%\n",
      "Round 55/100, Clients: 10\n",
      "Global Test - Loss: 0.2839, Acc: 89.61%\n",
      "Round 56/100, Clients: 10\n",
      "Global Test - Loss: 0.2798, Acc: 89.80%\n",
      "Round 57/100, Clients: 10\n",
      "Global Test - Loss: 0.2787, Acc: 89.67%\n",
      "Round 58/100, Clients: 10\n",
      "Global Test - Loss: 0.2757, Acc: 89.91%\n",
      "Round 59/100, Clients: 10\n",
      "Global Test - Loss: 0.2780, Acc: 89.78%\n",
      "Round 60/100, Clients: 10\n",
      "Global Test - Loss: 0.2746, Acc: 89.92%\n",
      "Round 61/100, Clients: 10\n",
      "Global Test - Loss: 0.2711, Acc: 90.05%\n",
      "Round 62/100, Clients: 10\n",
      "Global Test - Loss: 0.2663, Acc: 90.22%\n",
      "Round 63/100, Clients: 10\n",
      "Global Test - Loss: 0.2713, Acc: 89.95%\n",
      "Round 64/100, Clients: 10\n",
      "Global Test - Loss: 0.2657, Acc: 90.31%\n",
      "Round 65/100, Clients: 10\n",
      "Global Test - Loss: 0.2638, Acc: 90.38%\n",
      "Round 66/100, Clients: 10\n",
      "Global Test - Loss: 0.2622, Acc: 90.39%\n",
      "Round 67/100, Clients: 10\n",
      "Global Test - Loss: 0.2584, Acc: 90.57%\n",
      "Round 68/100, Clients: 10\n",
      "Global Test - Loss: 0.2572, Acc: 90.54%\n",
      "Round 69/100, Clients: 10\n",
      "Global Test - Loss: 0.2593, Acc: 90.45%\n",
      "Round 70/100, Clients: 10\n",
      "Global Test - Loss: 0.2589, Acc: 90.72%\n",
      "Round 71/100, Clients: 10\n",
      "Global Test - Loss: 0.2544, Acc: 90.68%\n",
      "Round 72/100, Clients: 10\n",
      "Global Test - Loss: 0.2576, Acc: 90.73%\n",
      "Round 73/100, Clients: 10\n",
      "Global Test - Loss: 0.2523, Acc: 90.73%\n",
      "Round 74/100, Clients: 10\n",
      "Global Test - Loss: 0.2572, Acc: 90.65%\n",
      "Round 75/100, Clients: 10\n",
      "Global Test - Loss: 0.2526, Acc: 90.84%\n",
      "Round 76/100, Clients: 10\n",
      "Global Test - Loss: 0.2503, Acc: 90.88%\n",
      "Round 77/100, Clients: 10\n",
      "Global Test - Loss: 0.2445, Acc: 91.11%\n",
      "Round 78/100, Clients: 10\n",
      "Global Test - Loss: 0.2440, Acc: 91.15%\n",
      "Round 79/100, Clients: 10\n",
      "Global Test - Loss: 0.2452, Acc: 91.12%\n",
      "Round 80/100, Clients: 10\n",
      "Global Test - Loss: 0.2419, Acc: 91.25%\n",
      "Round 81/100, Clients: 10\n",
      "Global Test - Loss: 0.2437, Acc: 91.20%\n",
      "Round 82/100, Clients: 10\n",
      "Global Test - Loss: 0.2418, Acc: 91.17%\n",
      "Round 83/100, Clients: 10\n",
      "Global Test - Loss: 0.2389, Acc: 91.21%\n",
      "Round 84/100, Clients: 10\n",
      "Global Test - Loss: 0.2354, Acc: 91.38%\n",
      "Round 85/100, Clients: 10\n",
      "Global Test - Loss: 0.2375, Acc: 91.38%\n",
      "Round 86/100, Clients: 10\n",
      "Global Test - Loss: 0.2342, Acc: 91.53%\n",
      "Round 87/100, Clients: 10\n",
      "Global Test - Loss: 0.2354, Acc: 91.52%\n",
      "Round 88/100, Clients: 10\n",
      "Global Test - Loss: 0.2364, Acc: 91.48%\n",
      "Round 89/100, Clients: 10\n",
      "Global Test - Loss: 0.2312, Acc: 91.58%\n",
      "Round 90/100, Clients: 10\n",
      "Global Test - Loss: 0.2304, Acc: 91.70%\n",
      "Round 91/100, Clients: 10\n",
      "Global Test - Loss: 0.2324, Acc: 91.44%\n",
      "Round 92/100, Clients: 10\n",
      "Global Test - Loss: 0.2277, Acc: 91.66%\n",
      "Round 93/100, Clients: 10\n",
      "Global Test - Loss: 0.2282, Acc: 91.72%\n",
      "Round 94/100, Clients: 10\n",
      "Global Test - Loss: 0.2273, Acc: 91.78%\n",
      "Round 95/100, Clients: 10\n",
      "Global Test - Loss: 0.2278, Acc: 91.75%\n",
      "Round 96/100, Clients: 10\n",
      "Global Test - Loss: 0.2299, Acc: 91.77%\n",
      "Round 97/100, Clients: 10\n",
      "Global Test - Loss: 0.2269, Acc: 91.77%\n",
      "Round 98/100, Clients: 10\n",
      "Global Test - Loss: 0.2227, Acc: 91.94%\n",
      "Round 99/100, Clients: 10\n",
      "Global Test - Loss: 0.2226, Acc: 91.84%\n",
      "Round 100/100, Clients: 10\n",
      "Global Test - Loss: 0.2207, Acc: 91.94%\n",
      "[6] Done. Total time: 1710.90s\n"
     ]
    }
   ],
   "source": [
    "# FedDyn-DF on Fashion-MNIST\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Model Definition (Fashion-MNIST CNN)\n",
    "# -----------------------------\n",
    "class Fashion_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),  # 注意这里是1通道\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3*3*128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)  # Fashion-MNIST 有10个类别\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.conv(x))\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Partitioning (Non-IID)\n",
    "# -----------------------------\n",
    "def partition_data(dataset, num_clients=100):\n",
    "    labels = np.array(dataset.targets)\n",
    "    idx_by_class = [np.where(labels == i)[0] for i in range(10)]\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "    for c in range(10):\n",
    "        np.random.shuffle(idx_by_class[c])\n",
    "        parts = np.array_split(idx_by_class[c], num_clients)\n",
    "        for i in range(num_clients):\n",
    "            client_indices[i].extend(parts[i])\n",
    "    return [Subset(dataset, inds) for inds in client_indices]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Client Class (FedDyn-DF)\n",
    "# -----------------------------\n",
    "class Client:\n",
    "    def __init__(self, model, data, lr, local_epochs, device):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.data = data\n",
    "        self.lr = lr\n",
    "        self.local_epochs = local_epochs\n",
    "        self.device = device\n",
    "        self.dyn_vector = {k: torch.zeros_like(v) for k, v in self.model.state_dict().items()}\n",
    "\n",
    "    def train(self, global_model):\n",
    "        self.model.load_state_dict(global_model.state_dict())\n",
    "        self.model.train()\n",
    "\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=self.lr, momentum=0.9)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loader = DataLoader(self.data, batch_size=32, shuffle=True)\n",
    "\n",
    "        for epoch in range(self.local_epochs):\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "\n",
    "                # FedDyn correction term\n",
    "                correction = 0.0\n",
    "                local_state = self.model.state_dict()\n",
    "                for name in local_state:\n",
    "                    p = local_state[name]\n",
    "                    dyn = self.dyn_vector[name]\n",
    "                    correction += (p * dyn).sum()\n",
    "\n",
    "                loss += correction\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Update dynamic correction vector\n",
    "        with torch.no_grad():\n",
    "            for k in self.model.state_dict().keys():\n",
    "                delta = global_model.state_dict()[k] - self.model.state_dict()[k]\n",
    "                self.dyn_vector[k] -= delta / (self.lr * self.local_epochs)\n",
    "\n",
    "        return copy.deepcopy(self.model.state_dict())\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        loader = DataLoader(self.data, batch_size=64, shuffle=False)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "                total_loss += loss.item() * x.size(0)\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += x.size(0)\n",
    "        return total_loss / total, correct / total\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Server Class (FedDyn-DF)\n",
    "# -----------------------------\n",
    "class Server:\n",
    "    def __init__(self, model, num_clients):\n",
    "        self.global_model = model\n",
    "        self.clients = []\n",
    "        self.num_clients = num_clients\n",
    "\n",
    "    def add_clients(self, client_list):\n",
    "        self.clients = client_list\n",
    "\n",
    "    def aggregate(self, client_states):\n",
    "        avg_state = copy.deepcopy(self.global_model.state_dict())\n",
    "        for k in avg_state:\n",
    "            avg_state[k] = sum(client[k] for client in client_states) / len(client_states)\n",
    "        self.global_model.load_state_dict(avg_state)\n",
    "\n",
    "    def federated_train(self, rounds):\n",
    "        for r in range(rounds):\n",
    "            selected = random.sample(self.clients, k=10)\n",
    "            client_states = []\n",
    "\n",
    "            print(f\"Round {r+1}/{rounds}, Clients: {len(selected)}\")\n",
    "\n",
    "            for client in selected:\n",
    "                state_dict = client.train(self.global_model)\n",
    "                client_states.append(state_dict)\n",
    "\n",
    "            self.aggregate(client_states)\n",
    "\n",
    "            # Evaluate\n",
    "            global_losses, global_accs = [], []\n",
    "            for client in self.clients:\n",
    "                client.model.load_state_dict(self.global_model.state_dict())\n",
    "                loss, acc = client.evaluate()\n",
    "                global_losses.append(loss)\n",
    "                global_accs.append(acc)\n",
    "\n",
    "            avg_loss = np.mean(global_losses)\n",
    "            avg_acc = np.mean(global_accs) * 100\n",
    "\n",
    "            print(f\"Global Test - Loss: {avg_loss:.4f}, Acc: {avg_acc:.2f}%\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Main Execution\n",
    "# -----------------------------\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    print(\"[0] Loading Fashion-MNIST...\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    fashion_train = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    print(f\"[1] Dataset loaded. Total samples: {len(fashion_train)}\")\n",
    "\n",
    "    print(\"[2] Partitioning data...\")\n",
    "    partition_start = time.time()\n",
    "    client_data = partition_data(fashion_train, num_clients=100)\n",
    "    print(f\"[3] Partition done in {time.time() - partition_start:.2f}s\")\n",
    "\n",
    "    print(\"[4] Initializing models...\")\n",
    "    global_model = Fashion_CNN().to(device)\n",
    "    server = Server(global_model, num_clients=100)\n",
    "    clients = [Client(global_model, data, lr=0.01, local_epochs=2, device=device) for data in client_data]\n",
    "    server.add_clients(clients)\n",
    "\n",
    "    print(\"[5] Starting federated training...\")\n",
    "    server.federated_train(rounds=100)\n",
    "\n",
    "    print(f\"[6] Done. Total time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eec16af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[0] Loading Fashion-MNIST...\n",
      "[1] Dataset loaded. Total samples: 60000\n",
      "[2] Partitioning data...\n",
      "[3] Partition done in 0.01s\n",
      "[4] Initializing models...\n",
      "[5] Starting federated training...\n",
      "Round 1/100, μ=0.1000, Clients: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khalil\\AppData\\Local\\Temp\\ipykernel_19328\\3546136707.py:48: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  labels = np.array(dataset.targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Test - Loss: 2.2065, Acc: 48.42%\n",
      "Round 2/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 1.2993, Acc: 60.05%\n",
      "Round 3/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 0.9480, Acc: 70.57%\n",
      "Round 4/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 0.8134, Acc: 72.79%\n",
      "Round 5/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 0.7232, Acc: 74.51%\n",
      "Round 6/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 0.6787, Acc: 76.32%\n",
      "Round 7/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 0.6301, Acc: 77.78%\n",
      "Round 8/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 0.5962, Acc: 78.64%\n",
      "Round 9/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 0.5644, Acc: 79.72%\n",
      "Round 10/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 0.5371, Acc: 81.06%\n",
      "Round 11/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 0.5200, Acc: 81.64%\n",
      "Round 12/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 0.4970, Acc: 82.64%\n",
      "Round 13/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 0.4808, Acc: 83.05%\n",
      "Round 14/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 0.4690, Acc: 83.35%\n",
      "Round 15/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 0.4530, Acc: 84.00%\n",
      "Round 16/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 0.4386, Acc: 84.68%\n",
      "Round 17/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 0.4305, Acc: 84.80%\n",
      "Round 18/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 0.4241, Acc: 85.35%\n",
      "Round 19/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 0.4095, Acc: 85.60%\n",
      "Round 20/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 0.3973, Acc: 85.77%\n",
      "Round 21/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 0.3883, Acc: 86.12%\n",
      "Round 22/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 0.3910, Acc: 86.28%\n",
      "Round 23/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 0.3728, Acc: 86.65%\n",
      "Round 24/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 0.3674, Acc: 86.95%\n",
      "Round 25/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 0.3729, Acc: 86.78%\n",
      "Round 26/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 0.3580, Acc: 87.25%\n",
      "Round 27/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 0.3576, Acc: 87.43%\n",
      "Round 28/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 0.3494, Acc: 87.56%\n",
      "Round 29/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 0.3486, Acc: 87.74%\n",
      "Round 30/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 0.3413, Acc: 87.98%\n",
      "Round 31/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 0.3378, Acc: 87.99%\n",
      "Round 32/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 0.3302, Acc: 88.07%\n",
      "Round 33/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 0.3282, Acc: 88.26%\n",
      "Round 34/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 0.3216, Acc: 88.40%\n",
      "Round 35/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 0.3170, Acc: 88.50%\n",
      "Round 36/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 0.3162, Acc: 88.58%\n",
      "Round 37/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 0.3131, Acc: 88.70%\n",
      "Round 38/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 0.3084, Acc: 88.84%\n",
      "Round 39/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 0.3118, Acc: 88.91%\n",
      "Round 40/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 0.3032, Acc: 89.05%\n",
      "Round 41/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 0.3026, Acc: 89.18%\n",
      "Round 42/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 0.3006, Acc: 89.32%\n",
      "Round 43/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 0.2986, Acc: 89.17%\n",
      "Round 44/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 0.2959, Acc: 89.40%\n",
      "Round 45/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 0.2950, Acc: 89.40%\n",
      "Round 46/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 0.2902, Acc: 89.56%\n",
      "Round 47/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 0.2887, Acc: 89.72%\n",
      "Round 48/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 0.2878, Acc: 89.55%\n",
      "Round 49/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 0.2792, Acc: 89.86%\n",
      "Round 50/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 0.2822, Acc: 89.97%\n",
      "Round 51/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 0.2757, Acc: 90.16%\n",
      "Round 52/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 0.2742, Acc: 90.20%\n",
      "Round 53/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 0.2721, Acc: 90.30%\n",
      "Round 54/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 0.2709, Acc: 90.36%\n",
      "Round 55/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 0.2660, Acc: 90.39%\n",
      "Round 56/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 0.2723, Acc: 90.29%\n",
      "Round 57/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 0.2641, Acc: 90.44%\n",
      "Round 58/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 0.2683, Acc: 90.30%\n",
      "Round 59/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 0.2663, Acc: 90.48%\n",
      "Round 60/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 0.2601, Acc: 90.75%\n",
      "Round 61/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 0.2578, Acc: 90.86%\n",
      "Round 62/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 0.2598, Acc: 90.72%\n",
      "Round 63/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 0.2574, Acc: 90.70%\n",
      "Round 64/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 0.2553, Acc: 90.84%\n",
      "Round 65/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 0.2512, Acc: 91.09%\n",
      "Round 66/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 0.2511, Acc: 91.04%\n",
      "Round 67/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 0.2518, Acc: 91.05%\n",
      "Round 68/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 0.2487, Acc: 91.10%\n",
      "Round 69/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 0.2498, Acc: 91.09%\n",
      "Round 70/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 0.2467, Acc: 91.06%\n",
      "Round 71/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 0.2432, Acc: 91.16%\n",
      "Round 72/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 0.2503, Acc: 91.08%\n",
      "Round 73/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 0.2453, Acc: 91.23%\n",
      "Round 74/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 0.2389, Acc: 91.46%\n",
      "Round 75/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 0.2403, Acc: 91.39%\n",
      "Round 76/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 0.2365, Acc: 91.61%\n",
      "Round 77/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 0.2348, Acc: 91.41%\n",
      "Round 78/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 0.2328, Acc: 91.69%\n",
      "Round 79/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 0.2332, Acc: 91.61%\n",
      "Round 80/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 0.2293, Acc: 91.66%\n",
      "Round 81/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 0.2328, Acc: 91.68%\n",
      "Round 82/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 0.2297, Acc: 91.76%\n",
      "Round 83/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 0.2270, Acc: 91.94%\n",
      "Round 84/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 0.2281, Acc: 91.89%\n",
      "Round 85/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 0.2245, Acc: 91.84%\n",
      "Round 86/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 0.2240, Acc: 92.01%\n",
      "Round 87/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 0.2223, Acc: 92.02%\n",
      "Round 88/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 0.2242, Acc: 91.94%\n",
      "Round 89/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 0.2230, Acc: 91.99%\n",
      "Round 90/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 0.2207, Acc: 92.02%\n",
      "Round 91/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 0.2191, Acc: 92.14%\n",
      "Round 92/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 0.2191, Acc: 92.03%\n",
      "Round 93/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 0.2142, Acc: 92.28%\n",
      "Round 94/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 0.2180, Acc: 92.10%\n",
      "Round 95/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 0.2141, Acc: 92.31%\n",
      "Round 96/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 0.2147, Acc: 92.33%\n",
      "Round 97/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 0.2140, Acc: 92.32%\n",
      "Round 98/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 0.2110, Acc: 92.42%\n",
      "Round 99/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 0.2113, Acc: 92.41%\n",
      "Round 100/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 0.2087, Acc: 92.47%\n",
      "[6] Done. Total time: 1554.09s\n"
     ]
    }
   ],
   "source": [
    "# FedSC-MTL on Fashion-MNIST\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Model Definition (Fashion-MNIST CNN)\n",
    "# -----------------------------\n",
    "class Fashion_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),  \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc1 = nn.Linear(3*3*128, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 10)  \n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        feat = self.relu(self.fc1(x))\n",
    "        out = self.fc2(feat)\n",
    "        if return_features:\n",
    "            return out, feat\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Partitioning (Non-IID)\n",
    "# -----------------------------\n",
    "def partition_data(dataset, num_clients=100):\n",
    "    labels = np.array(dataset.targets)\n",
    "    idx_by_class = [np.where(labels == i)[0] for i in range(10)]\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "    for c in range(10):\n",
    "        np.random.shuffle(idx_by_class[c])\n",
    "        parts = np.array_split(idx_by_class[c], num_clients)\n",
    "        for i in range(num_clients):\n",
    "            client_indices[i].extend(parts[i])\n",
    "    return [Subset(dataset, inds) for inds in client_indices]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Client Class (FedSC-MTL)\n",
    "# -----------------------------\n",
    "class Client:\n",
    "    def __init__(self, model, data, lr, local_epochs, device):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.data = data\n",
    "        self.lr = lr\n",
    "        self.local_epochs = local_epochs\n",
    "        self.device = device\n",
    "        self.ci = {k: torch.zeros_like(v) for k, v in self.model.state_dict().items()}\n",
    "\n",
    "    def train(self, global_model, cg, mu):\n",
    "        self.model.load_state_dict(global_model.state_dict())\n",
    "        self.model.train()\n",
    "\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=self.lr, momentum=0.9)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loader = DataLoader(self.data, batch_size=32, shuffle=True)\n",
    "\n",
    "        for epoch in range(self.local_epochs):\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                output, feat = self.model(x, return_features=True)\n",
    "                loss_cls = criterion(output, y)\n",
    "\n",
    "                # Feature distillation loss (example: zero vector as reference)\n",
    "                fref = torch.zeros_like(feat).to(self.device)\n",
    "                distill_loss = nn.MSELoss()(feat, fref)\n",
    "\n",
    "                # Control variable correction\n",
    "                grad_correction = 0.0\n",
    "                model_state = self.model.state_dict()\n",
    "                global_state = global_model.state_dict()\n",
    "\n",
    "                for name in model_state:\n",
    "                    p = model_state[name]\n",
    "                    w_t = global_state[name]\n",
    "                    c_global = cg[name]\n",
    "                    ci_local = self.ci[name]\n",
    "                    grad_correction += ((p - w_t) * (-ci_local + c_global + mu * (p - w_t))).sum()\n",
    "\n",
    "                total_loss = loss_cls + distill_loss + 0.5 * grad_correction\n",
    "                total_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Update local control ci\n",
    "        with torch.no_grad():\n",
    "            for k in self.model.state_dict().keys():\n",
    "                self.ci[k] = self.ci[k] - cg[k] + (global_model.state_dict()[k] - self.model.state_dict()[k]) / self.lr\n",
    "\n",
    "        return copy.deepcopy(self.model.state_dict()), self.ci\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        loader = DataLoader(self.data, batch_size=64, shuffle=False)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "                total_loss += loss.item() * x.size(0)\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += x.size(0)\n",
    "        return total_loss / total, correct / total\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Server Class (FedSC-MTL)\n",
    "# -----------------------------\n",
    "class Server:\n",
    "    def __init__(self, model, num_clients):\n",
    "        self.global_model = model\n",
    "        self.clients = []\n",
    "        self.num_clients = num_clients\n",
    "        self.cg = {k: torch.zeros_like(v) for k, v in self.global_model.state_dict().items()}\n",
    "\n",
    "    def add_clients(self, client_list):\n",
    "        self.clients = client_list\n",
    "\n",
    "    def aggregate(self, client_states):\n",
    "        avg_state = copy.deepcopy(self.global_model.state_dict())\n",
    "        for k in avg_state:\n",
    "            avg_state[k] = sum(client[k] for client in client_states) / len(client_states)\n",
    "        self.global_model.load_state_dict(avg_state)\n",
    "\n",
    "    def update_cg(self, ci_list):\n",
    "        for k in self.cg:\n",
    "            self.cg[k] = sum(ci[k] for ci in ci_list) / len(ci_list)\n",
    "\n",
    "    def federated_train(self, rounds, mu_scheduler):\n",
    "        for r in range(rounds):\n",
    "            selected = random.sample(self.clients, k=10)\n",
    "            mu = mu_scheduler(r)\n",
    "            client_states, ci_list = [], []\n",
    "\n",
    "            print(f\"Round {r+1}/{rounds}, μ={mu:.4f}, Clients: {len(selected)}\")\n",
    "\n",
    "            for client in selected:\n",
    "                state_dict, ci = client.train(self.global_model, self.cg, mu)\n",
    "                client_states.append(state_dict)\n",
    "                ci_list.append(ci)\n",
    "\n",
    "            self.aggregate(client_states)\n",
    "            self.update_cg(ci_list)\n",
    "\n",
    "            # Evaluate\n",
    "            global_losses, global_accs = [], []\n",
    "            for client in self.clients:\n",
    "                client.model.load_state_dict(self.global_model.state_dict())\n",
    "                loss, acc = client.evaluate()\n",
    "                global_losses.append(loss)\n",
    "                global_accs.append(acc)\n",
    "\n",
    "            avg_loss = np.mean(global_losses)\n",
    "            avg_acc = np.mean(global_accs) * 100\n",
    "\n",
    "            print(f\"Global Test - Loss: {avg_loss:.4f}, Acc: {avg_acc:.2f}%\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Main Execution\n",
    "# -----------------------------\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    print(\"[0] Loading Fashion-MNIST...\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    fashion_train = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    print(f\"[1] Dataset loaded. Total samples: {len(fashion_train)}\")\n",
    "\n",
    "    print(\"[2] Partitioning data...\")\n",
    "    partition_start = time.time()\n",
    "    client_data = partition_data(fashion_train, num_clients=100)\n",
    "    print(f\"[3] Partition done in {time.time() - partition_start:.2f}s\")\n",
    "\n",
    "    print(\"[4] Initializing models...\")\n",
    "    global_model = Fashion_CNN().to(device)\n",
    "    server = Server(global_model, num_clients=100)\n",
    "    clients = [Client(global_model, data, lr=0.01, local_epochs=2, device=device) for data in client_data]\n",
    "    server.add_clients(clients)\n",
    "\n",
    "    def mu_schedule(round_idx):\n",
    "        return 0.1 * (0.95 ** (round_idx // 10))  \n",
    "\n",
    "    print(\"[5] Starting federated training...\")\n",
    "    server.federated_train(rounds=100, mu_scheduler=mu_schedule)\n",
    "\n",
    "    print(f\"[6] Done. Total time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca09ef8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fedavg_acc = [\n",
    "    42.94, 59.91, 68.52, 72.29, 74.37, 75.62, 76.48, 77.77, 79.35, 79.03,\n",
    "    79.15, 80.50, 81.78, 82.20, 82.80, 83.07, 83.75, 84.14, 84.51, 84.95,\n",
    "    85.23, 85.40, 85.75, 86.08, 86.37, 86.50, 86.73, 87.02, 87.11, 87.29,\n",
    "    87.01, 87.49, 87.55, 87.77, 87.89, 88.04, 88.06, 88.17, 88.45, 88.26,\n",
    "    88.59, 88.68, 88.47, 88.99, 88.95, 89.16, 89.34, 89.35, 89.24, 89.50,\n",
    "    89.49, 89.81, 89.78, 89.95, 89.70, 90.07, 90.03, 90.06, 89.99, 89.92,\n",
    "    90.21, 90.19, 90.25, 90.32, 90.41, 90.50, 90.55, 90.50, 90.70, 90.57,\n",
    "    90.79, 90.73, 90.95, 91.00, 90.87, 90.99, 91.02, 91.19, 91.19, 91.33,\n",
    "    91.17, 91.43, 91.50, 91.39, 91.54, 91.49, 91.57, 91.64, 91.83, 91.67,\n",
    "    91.67, 91.71, 91.73, 91.70, 91.92, 91.90, 92.00, 91.98, 92.06, 92.07\n",
    "]\n",
    "\n",
    "# FedProx 数据\n",
    "fedprox_acc = [\n",
    "    26.38, 36.03, 40.40, 50.60, 47.60, 60.52, 46.29, 52.74, 52.22, 56.54,\n",
    "    56.94, 66.56, 62.28, 57.85, 65.85, 73.83, 59.17, 70.02, 54.59, 62.38,\n",
    "    69.07, 67.89, 69.64, 69.17, 65.05, 74.53, 71.51, 69.89, 74.74, 69.10,\n",
    "    67.34, 67.97, 69.37, 75.43, 67.21, 76.24, 56.84, 73.24, 70.95, 77.00,\n",
    "    75.01, 72.62, 64.90, 57.01, 68.13, 65.32, 74.91, 70.43, 67.24, 70.43,\n",
    "    74.47, 68.21, 59.30, 77.30, 67.38, 66.58, 68.63, 72.21, 72.48, 72.21,\n",
    "    69.05, 65.33, 72.19, 72.53, 76.36, 56.35, 56.38, 80.23, 72.09, 72.75,\n",
    "    77.81, 74.63, 76.24, 70.81, 74.09, 68.89, 73.06, 78.79, 80.43, 73.24,\n",
    "    74.69, 75.28, 75.72, 76.60, 77.50, 75.12, 77.04, 76.08, 75.49, 80.20,\n",
    "    73.44, 72.04, 69.89, 76.14, 78.25, 72.04, 78.80, 63.68, 79.76, 79.95\n",
    "]\n",
    "\n",
    "# SCAFFOLD 数据\n",
    "scaffold_acc = [\n",
    "    38.61, 56.73, 69.06, 72.54, 73.38, 75.63, 76.30, 77.31, 77.95, 78.76,\n",
    "    79.44, 80.34, 81.01, 81.95, 82.12, 82.47, 83.34, 83.70, 84.24, 84.31,\n",
    "    84.48, 84.63, 85.67, 85.67, 85.88, 86.39, 86.47, 86.75, 86.61, 87.04,\n",
    "    87.18, 87.53, 87.57, 87.92, 87.84, 87.95, 88.15, 88.23, 88.43, 88.21,\n",
    "    88.50, 88.84, 88.69, 88.91, 88.98, 89.13, 89.25, 89.20, 89.46, 89.48,\n",
    "    89.59, 89.58, 89.81, 89.86, 89.90, 90.03, 90.07, 89.89, 90.25, 90.11,\n",
    "    90.26, 90.25, 90.38, 90.50, 90.47, 90.49, 90.76, 90.77, 90.64, 90.72,\n",
    "    90.74, 90.78, 90.98, 91.05, 91.04, 90.98, 91.23, 91.14, 91.26, 91.24,\n",
    "    91.19, 91.31, 91.17, 91.49, 91.54, 91.65, 91.52, 91.49, 91.54, 91.61,\n",
    "    91.73, 91.79, 91.87, 91.78, 91.85, 91.76, 91.78, 91.93, 92.07, 91.99\n",
    "]\n",
    "\n",
    "fedict_acc = [\n",
    "    3.92, 5.54, 7.92, 8.83, 9.68, 9.75, 9.98, 10.00, 10.00, 10.00,\n",
    "    10.00, 10.00, 10.01, 10.01, 15.72, 15.39, 24.35, 51.00, 50.15, 57.35,\n",
    "    61.94, 66.53, 63.69, 60.78, 66.74, 68.40, 69.67, 69.97, 70.95, 70.84,\n",
    "    69.48, 70.04, 70.44, 69.60, 69.84, 70.31, 71.29, 70.85, 70.83, 71.45,\n",
    "    70.95, 71.39, 71.03, 70.71, 72.29, 71.89, 72.17, 72.43, 72.54, 70.62,\n",
    "    72.61, 72.81, 72.18, 72.42, 73.21, 72.51, 72.62, 71.52, 72.62, 73.11,\n",
    "    72.94, 72.73, 73.08, 71.99, 73.34, 73.11, 72.57, 73.40, 72.00, 73.84,\n",
    "    73.10, 72.28, 72.70, 73.26, 71.96, 73.06, 72.89, 73.25, 72.63, 73.20,\n",
    "    73.19, 70.97, 73.39, 73.57, 73.06, 73.12, 71.78, 73.33, 73.52, 73.51,\n",
    "    73.95, 73.61, 72.95, 73.47, 73.80, 71.90, 73.97, 73.48, 73.77, 73.29\n",
    "]\n",
    "\n",
    "feddyn_df_acc = [\n",
    "    44.21, 62.47, 69.46, 73.90, 75.84, 76.86, 78.48, 78.92, 79.38, 80.80,\n",
    "    81.58, 81.97, 82.75, 82.74, 83.75, 84.28, 84.28, 84.60, 84.98, 85.29,\n",
    "    85.70, 85.68, 86.02, 86.06, 86.45, 86.76, 86.83, 87.03, 87.00, 87.13,\n",
    "    87.33, 87.76, 87.77, 87.75, 87.73, 88.07, 88.27, 88.28, 88.33, 88.38,\n",
    "    88.65, 88.83, 88.76, 88.95, 89.01, 89.00, 89.09, 89.15, 89.40, 89.31,\n",
    "    89.53, 89.42, 89.49, 89.60, 89.61, 89.80, 89.67, 89.91, 89.78, 89.92,\n",
    "    90.05, 90.22, 89.95, 90.31, 90.38, 90.39, 90.57, 90.54, 90.45, 90.72,\n",
    "    90.68, 90.73, 90.73, 90.65, 90.84, 90.88, 91.11, 91.15, 91.12, 91.25,\n",
    "    91.20, 91.17, 91.21, 91.38, 91.38, 91.53, 91.52, 91.48, 91.58, 91.70,\n",
    "    91.44, 91.66, 91.72, 91.78, 91.75, 91.77, 91.77, 91.94, 91.84, 91.94\n",
    "]\n",
    "\n",
    "fedsc_mtl_acc = [\n",
    "    48.42, 60.05, 70.57, 72.79, 74.51, 76.32, 77.78, 78.64, 79.72, 81.06,\n",
    "    81.64, 82.64, 83.05, 83.35, 84.00, 84.68, 84.80, 85.35, 85.60, 85.77,\n",
    "    86.12, 86.28, 86.65, 86.95, 86.78, 87.25, 87.43, 87.56, 87.74, 87.98,\n",
    "    87.99, 88.07, 88.26, 88.40, 88.50, 88.58, 88.70, 88.84, 88.91, 89.05,\n",
    "    89.18, 89.32, 89.17, 89.40, 89.40, 89.56, 89.72, 89.55, 89.86, 89.97,\n",
    "    90.16, 90.20, 90.30, 90.36, 90.39, 90.29, 90.44, 90.30, 90.48, 90.75,\n",
    "    90.86, 90.72, 90.70, 90.84, 91.09, 91.04, 91.05, 91.10, 91.09, 91.06,\n",
    "    91.16, 91.08, 91.23, 91.46, 91.39, 91.61, 91.41, 91.69, 91.61, 91.66,\n",
    "    91.68, 91.76, 91.94, 91.89, 91.84, 92.01, 92.02, 91.94, 91.99, 92.02,\n",
    "    92.14, 92.03, 92.28, 92.10, 92.31, 92.33, 92.32, 92.42, 92.41, 92.47\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "rounds = list(range(1, 101))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(rounds, fedavg_acc, label='FedAvg')\n",
    "plt.plot(rounds, fedprox_acc, label='FedProx')\n",
    "plt.plot(rounds, scaffold_acc, label='SCAFFOLD')\n",
    "plt.plot(rounds, fedict_acc, label='FedICT')\n",
    "plt.plot(rounds, feddyn_df_acc, label='FedDyn-DF')\n",
    "plt.plot(rounds, fedsc_mtl_acc, label='FedSC-MTL')\n",
    "\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.title('Test Accuracy vs. Round (Fashion-MNIST)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d7510c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84c7711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b49a005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
