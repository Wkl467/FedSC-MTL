{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T15:01:03.733382Z",
     "start_time": "2025-06-10T15:01:03.721092Z"
    },
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FEMNIST data...\n",
      "Starting Federated Training...\n",
      "Round 1/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 2.8573, Acc: 31.85%\n",
      "Client Avg - Loss: 0.8899, Acc: 80.43%\n",
      "Round 2/100, μ=0.0980, Clients: 10\n",
      "Global Test - Loss: 1.8109, Acc: 54.45%\n",
      "Client Avg - Loss: 0.5387, Acc: 86.60%\n",
      "Round 3/100, μ=0.0960, Clients: 10\n",
      "Global Test - Loss: 1.3468, Acc: 62.32%\n",
      "Client Avg - Loss: 0.5571, Acc: 85.82%\n",
      "Round 4/100, μ=0.0941, Clients: 10\n",
      "Global Test - Loss: 1.0962, Acc: 67.97%\n",
      "Client Avg - Loss: 0.3743, Acc: 89.81%\n",
      "Round 5/100, μ=0.0922, Clients: 10\n",
      "Global Test - Loss: 0.9456, Acc: 70.49%\n",
      "Client Avg - Loss: 0.3309, Acc: 91.80%\n",
      "Round 6/100, μ=0.0904, Clients: 10\n",
      "Global Test - Loss: 0.9135, Acc: 70.99%\n",
      "Client Avg - Loss: 0.2974, Acc: 92.20%\n",
      "Round 7/100, μ=0.0886, Clients: 10\n",
      "Global Test - Loss: 0.8129, Acc: 73.22%\n",
      "Client Avg - Loss: 0.2276, Acc: 94.40%\n",
      "Round 8/100, μ=0.0868, Clients: 10\n",
      "Global Test - Loss: 0.8810, Acc: 72.15%\n",
      "Client Avg - Loss: 0.2243, Acc: 94.54%\n",
      "Round 9/100, μ=0.0851, Clients: 10\n",
      "Global Test - Loss: 0.7514, Acc: 76.26%\n",
      "Client Avg - Loss: 0.2589, Acc: 93.69%\n",
      "Round 10/100, μ=0.0834, Clients: 10\n",
      "Global Test - Loss: 0.7537, Acc: 73.61%\n",
      "Client Avg - Loss: 0.2374, Acc: 93.83%\n",
      "Round 11/100, μ=0.0817, Clients: 10\n",
      "Global Test - Loss: 0.6835, Acc: 77.51%\n",
      "Client Avg - Loss: 0.2368, Acc: 93.26%\n",
      "Round 12/100, μ=0.0801, Clients: 10\n",
      "Global Test - Loss: 0.7163, Acc: 76.57%\n",
      "Client Avg - Loss: 0.2113, Acc: 94.49%\n",
      "Round 13/100, μ=0.0785, Clients: 10\n",
      "Global Test - Loss: 0.7109, Acc: 75.95%\n",
      "Client Avg - Loss: 0.2413, Acc: 93.09%\n",
      "Round 14/100, μ=0.0769, Clients: 10\n",
      "Global Test - Loss: 0.6440, Acc: 78.97%\n",
      "Client Avg - Loss: 0.2356, Acc: 92.87%\n",
      "Round 15/100, μ=0.0754, Clients: 10\n",
      "Global Test - Loss: 0.6743, Acc: 76.91%\n",
      "Client Avg - Loss: 0.2207, Acc: 93.85%\n",
      "Round 16/100, μ=0.0739, Clients: 10\n",
      "Global Test - Loss: 0.7731, Acc: 73.10%\n",
      "Client Avg - Loss: 0.2375, Acc: 92.50%\n",
      "Round 17/100, μ=0.0724, Clients: 10\n",
      "Global Test - Loss: 0.6460, Acc: 76.06%\n",
      "Client Avg - Loss: 0.1932, Acc: 94.87%\n",
      "Round 18/100, μ=0.0709, Clients: 10\n",
      "Global Test - Loss: 0.6867, Acc: 73.35%\n",
      "Client Avg - Loss: 0.1945, Acc: 94.32%\n",
      "Round 19/100, μ=0.0695, Clients: 10\n",
      "Global Test - Loss: 0.6977, Acc: 74.65%\n",
      "Client Avg - Loss: 0.2309, Acc: 92.86%\n",
      "Round 20/100, μ=0.0681, Clients: 10\n",
      "Global Test - Loss: 0.6441, Acc: 76.14%\n",
      "Client Avg - Loss: 0.2216, Acc: 93.46%\n",
      "Round 21/100, μ=0.0668, Clients: 10\n",
      "Global Test - Loss: 0.6787, Acc: 76.11%\n",
      "Client Avg - Loss: 0.1833, Acc: 94.83%\n",
      "Round 22/100, μ=0.0654, Clients: 10\n",
      "Global Test - Loss: 0.6135, Acc: 79.10%\n",
      "Client Avg - Loss: 0.2469, Acc: 92.71%\n",
      "Round 23/100, μ=0.0641, Clients: 10\n",
      "Global Test - Loss: 0.6338, Acc: 78.80%\n",
      "Client Avg - Loss: 0.1775, Acc: 95.08%\n",
      "Round 24/100, μ=0.0628, Clients: 10\n",
      "Global Test - Loss: 0.6436, Acc: 76.41%\n",
      "Client Avg - Loss: 0.2024, Acc: 93.63%\n",
      "Round 25/100, μ=0.0616, Clients: 10\n",
      "Global Test - Loss: 0.6222, Acc: 78.75%\n",
      "Client Avg - Loss: 0.1660, Acc: 95.22%\n",
      "Round 26/100, μ=0.0603, Clients: 10\n",
      "Global Test - Loss: 0.6250, Acc: 79.40%\n",
      "Client Avg - Loss: 0.1729, Acc: 95.20%\n",
      "Round 27/100, μ=0.0591, Clients: 10\n",
      "Global Test - Loss: 0.5591, Acc: 80.33%\n",
      "Client Avg - Loss: 0.1628, Acc: 95.20%\n",
      "Round 28/100, μ=0.0580, Clients: 10\n",
      "Global Test - Loss: 0.6364, Acc: 76.76%\n",
      "Client Avg - Loss: 0.1666, Acc: 94.97%\n",
      "Round 29/100, μ=0.0568, Clients: 10\n",
      "Global Test - Loss: 0.6600, Acc: 74.21%\n",
      "Client Avg - Loss: 0.1946, Acc: 93.84%\n",
      "Round 30/100, μ=0.0557, Clients: 10\n",
      "Global Test - Loss: 0.5473, Acc: 80.59%\n",
      "Client Avg - Loss: 0.1487, Acc: 95.79%\n",
      "Round 31/100, μ=0.0545, Clients: 10\n",
      "Global Test - Loss: 0.5967, Acc: 76.69%\n",
      "Client Avg - Loss: 0.1773, Acc: 94.76%\n",
      "Round 32/100, μ=0.0535, Clients: 10\n",
      "Global Test - Loss: 0.6268, Acc: 77.77%\n",
      "Client Avg - Loss: 0.1282, Acc: 96.66%\n",
      "Round 33/100, μ=0.0524, Clients: 10\n",
      "Global Test - Loss: 0.5932, Acc: 78.54%\n",
      "Client Avg - Loss: 0.1186, Acc: 97.05%\n",
      "Round 34/100, μ=0.0513, Clients: 10\n",
      "Global Test - Loss: 0.5546, Acc: 80.96%\n",
      "Client Avg - Loss: 0.1761, Acc: 95.04%\n",
      "Round 35/100, μ=0.0503, Clients: 10\n",
      "Global Test - Loss: 0.5496, Acc: 79.63%\n",
      "Client Avg - Loss: 0.1961, Acc: 94.18%\n",
      "Round 36/100, μ=0.0493, Clients: 10\n",
      "Global Test - Loss: 0.5583, Acc: 80.49%\n",
      "Client Avg - Loss: 0.1323, Acc: 96.60%\n",
      "Round 37/100, μ=0.0483, Clients: 10\n",
      "Global Test - Loss: 0.6036, Acc: 79.15%\n",
      "Client Avg - Loss: 0.1328, Acc: 96.31%\n",
      "Round 38/100, μ=0.0474, Clients: 10\n",
      "Global Test - Loss: 0.6216, Acc: 79.07%\n",
      "Client Avg - Loss: 0.1177, Acc: 96.92%\n",
      "Round 39/100, μ=0.0464, Clients: 10\n",
      "Global Test - Loss: 0.5804, Acc: 80.40%\n",
      "Client Avg - Loss: 0.1737, Acc: 94.41%\n",
      "Round 40/100, μ=0.0455, Clients: 10\n",
      "Global Test - Loss: 0.5754, Acc: 78.11%\n",
      "Client Avg - Loss: 0.1627, Acc: 95.28%\n",
      "Round 41/100, μ=0.0446, Clients: 10\n",
      "Global Test - Loss: 0.6097, Acc: 79.10%\n",
      "Client Avg - Loss: 0.1639, Acc: 95.11%\n",
      "Round 42/100, μ=0.0437, Clients: 10\n",
      "Global Test - Loss: 0.5713, Acc: 78.35%\n",
      "Client Avg - Loss: 0.1514, Acc: 95.31%\n",
      "Round 43/100, μ=0.0428, Clients: 10\n",
      "Global Test - Loss: 0.6024, Acc: 77.39%\n",
      "Client Avg - Loss: 0.1339, Acc: 96.26%\n",
      "Round 44/100, μ=0.0419, Clients: 10\n",
      "Global Test - Loss: 0.5611, Acc: 80.07%\n",
      "Client Avg - Loss: 0.1246, Acc: 96.51%\n",
      "Round 45/100, μ=0.0411, Clients: 10\n",
      "Global Test - Loss: 0.5741, Acc: 78.94%\n",
      "Client Avg - Loss: 0.1738, Acc: 94.14%\n",
      "Round 46/100, μ=0.0403, Clients: 10\n",
      "Global Test - Loss: 0.6615, Acc: 75.18%\n",
      "Client Avg - Loss: 0.1755, Acc: 94.31%\n",
      "Round 47/100, μ=0.0395, Clients: 10\n",
      "Global Test - Loss: 0.5536, Acc: 80.98%\n",
      "Client Avg - Loss: 0.1350, Acc: 96.40%\n",
      "Round 48/100, μ=0.0387, Clients: 10\n",
      "Global Test - Loss: 0.5685, Acc: 79.13%\n",
      "Client Avg - Loss: 0.1975, Acc: 93.18%\n",
      "Round 49/100, μ=0.0379, Clients: 10\n",
      "Global Test - Loss: 0.5852, Acc: 76.94%\n",
      "Client Avg - Loss: 0.1437, Acc: 95.71%\n",
      "Round 50/100, μ=0.0372, Clients: 10\n",
      "Global Test - Loss: 0.5923, Acc: 77.81%\n",
      "Client Avg - Loss: 0.1587, Acc: 94.97%\n",
      "Round 51/100, μ=0.0364, Clients: 10\n",
      "Global Test - Loss: 0.5589, Acc: 80.60%\n",
      "Client Avg - Loss: 0.0923, Acc: 97.57%\n",
      "Round 52/100, μ=0.0357, Clients: 10\n",
      "Global Test - Loss: 0.5606, Acc: 79.46%\n",
      "Client Avg - Loss: 0.1413, Acc: 95.56%\n",
      "Round 53/100, μ=0.0350, Clients: 10\n",
      "Global Test - Loss: 0.5475, Acc: 80.78%\n",
      "Client Avg - Loss: 0.1274, Acc: 96.11%\n",
      "Round 54/100, μ=0.0343, Clients: 10\n",
      "Global Test - Loss: 0.5965, Acc: 79.37%\n",
      "Client Avg - Loss: 0.1130, Acc: 96.97%\n",
      "Round 55/100, μ=0.0336, Clients: 10\n",
      "Global Test - Loss: 0.5668, Acc: 79.69%\n",
      "Client Avg - Loss: 0.1538, Acc: 95.35%\n",
      "Round 56/100, μ=0.0329, Clients: 10\n",
      "Global Test - Loss: 0.5809, Acc: 77.15%\n",
      "Client Avg - Loss: 0.1607, Acc: 94.69%\n",
      "Round 57/100, μ=0.0323, Clients: 10\n",
      "Global Test - Loss: 0.6124, Acc: 77.21%\n",
      "Client Avg - Loss: 0.1412, Acc: 95.41%\n",
      "Round 58/100, μ=0.0316, Clients: 10\n",
      "Global Test - Loss: 0.5052, Acc: 81.55%\n",
      "Client Avg - Loss: 0.1305, Acc: 96.00%\n",
      "Round 59/100, μ=0.0310, Clients: 10\n",
      "Global Test - Loss: 0.5651, Acc: 80.01%\n",
      "Client Avg - Loss: 0.1260, Acc: 96.28%\n",
      "Round 60/100, μ=0.0304, Clients: 10\n",
      "Global Test - Loss: 0.5546, Acc: 80.83%\n",
      "Client Avg - Loss: 0.1211, Acc: 96.34%\n",
      "Round 61/100, μ=0.0298, Clients: 10\n",
      "Global Test - Loss: 0.5896, Acc: 77.62%\n",
      "Client Avg - Loss: 0.1560, Acc: 94.08%\n",
      "Round 62/100, μ=0.0292, Clients: 10\n",
      "Global Test - Loss: 0.5557, Acc: 78.06%\n",
      "Client Avg - Loss: 0.1202, Acc: 96.27%\n",
      "Round 63/100, μ=0.0286, Clients: 10\n",
      "Global Test - Loss: 0.5242, Acc: 81.02%\n",
      "Client Avg - Loss: 0.1224, Acc: 96.44%\n",
      "Round 64/100, μ=0.0280, Clients: 10\n",
      "Global Test - Loss: 0.5850, Acc: 78.23%\n",
      "Client Avg - Loss: 0.1231, Acc: 96.21%\n",
      "Round 65/100, μ=0.0274, Clients: 10\n",
      "Global Test - Loss: 0.5537, Acc: 80.09%\n",
      "Client Avg - Loss: 0.1267, Acc: 96.29%\n",
      "Round 66/100, μ=0.0269, Clients: 10\n",
      "Global Test - Loss: 0.5747, Acc: 79.15%\n",
      "Client Avg - Loss: 0.1428, Acc: 95.03%\n",
      "Round 67/100, μ=0.0264, Clients: 10\n",
      "Global Test - Loss: 0.6187, Acc: 79.79%\n",
      "Client Avg - Loss: 0.1187, Acc: 96.65%\n",
      "Round 68/100, μ=0.0258, Clients: 10\n",
      "Global Test - Loss: 0.5473, Acc: 79.63%\n",
      "Client Avg - Loss: 0.1615, Acc: 94.63%\n",
      "Round 69/100, μ=0.0253, Clients: 10\n",
      "Global Test - Loss: 0.5555, Acc: 79.06%\n",
      "Client Avg - Loss: 0.1332, Acc: 96.06%\n",
      "Round 70/100, μ=0.0248, Clients: 10\n",
      "Global Test - Loss: 0.5112, Acc: 81.99%\n",
      "Client Avg - Loss: 0.1210, Acc: 96.31%\n",
      "Round 71/100, μ=0.0243, Clients: 10\n",
      "Global Test - Loss: 0.5598, Acc: 78.78%\n",
      "Client Avg - Loss: 0.1725, Acc: 93.87%\n",
      "Round 72/100, μ=0.0238, Clients: 10\n",
      "Global Test - Loss: 0.5372, Acc: 79.28%\n",
      "Client Avg - Loss: 0.1016, Acc: 97.11%\n",
      "Round 73/100, μ=0.0233, Clients: 10\n",
      "Global Test - Loss: 0.4981, Acc: 82.05%\n",
      "Client Avg - Loss: 0.1125, Acc: 96.75%\n",
      "Round 74/100, μ=0.0229, Clients: 10\n",
      "Global Test - Loss: 0.6136, Acc: 78.16%\n",
      "Client Avg - Loss: 0.1029, Acc: 96.96%\n",
      "Round 75/100, μ=0.0224, Clients: 10\n",
      "Global Test - Loss: 0.5214, Acc: 81.14%\n",
      "Client Avg - Loss: 0.0784, Acc: 97.94%\n",
      "Round 76/100, μ=0.0220, Clients: 10\n",
      "Global Test - Loss: 0.5748, Acc: 78.53%\n",
      "Client Avg - Loss: 0.1338, Acc: 95.01%\n",
      "Round 77/100, μ=0.0215, Clients: 10\n",
      "Global Test - Loss: 0.5792, Acc: 78.89%\n",
      "Client Avg - Loss: 0.1074, Acc: 96.91%\n",
      "Round 78/100, μ=0.0211, Clients: 10\n",
      "Global Test - Loss: 0.5645, Acc: 78.74%\n",
      "Client Avg - Loss: 0.0958, Acc: 97.16%\n",
      "Round 79/100, μ=0.0207, Clients: 10\n",
      "Global Test - Loss: 0.5841, Acc: 79.25%\n",
      "Client Avg - Loss: 0.1740, Acc: 93.95%\n",
      "Round 80/100, μ=0.0203, Clients: 10\n",
      "Global Test - Loss: 0.5130, Acc: 80.64%\n",
      "Client Avg - Loss: 0.1254, Acc: 96.06%\n",
      "Round 81/100, μ=0.0199, Clients: 10\n",
      "Global Test - Loss: 0.4825, Acc: 81.99%\n",
      "Client Avg - Loss: 0.0973, Acc: 97.00%\n",
      "Round 82/100, μ=0.0195, Clients: 10\n",
      "Global Test - Loss: 0.5829, Acc: 79.97%\n",
      "Client Avg - Loss: 0.1364, Acc: 94.58%\n",
      "Round 83/100, μ=0.0191, Clients: 10\n",
      "Global Test - Loss: 0.5358, Acc: 79.89%\n",
      "Client Avg - Loss: 0.1198, Acc: 96.20%\n",
      "Round 84/100, μ=0.0187, Clients: 10\n",
      "Global Test - Loss: 0.5315, Acc: 79.83%\n",
      "Client Avg - Loss: 0.0992, Acc: 97.02%\n",
      "Round 85/100, μ=0.0183, Clients: 10\n",
      "Global Test - Loss: 0.5332, Acc: 80.00%\n",
      "Client Avg - Loss: 0.1124, Acc: 96.24%\n",
      "Round 86/100, μ=0.0180, Clients: 10\n",
      "Global Test - Loss: 0.4658, Acc: 83.43%\n",
      "Client Avg - Loss: 0.0859, Acc: 97.64%\n",
      "Round 87/100, μ=0.0176, Clients: 10\n",
      "Global Test - Loss: 0.5499, Acc: 79.12%\n",
      "Client Avg - Loss: 0.1227, Acc: 96.47%\n",
      "Round 88/100, μ=0.0172, Clients: 10\n",
      "Global Test - Loss: 0.5770, Acc: 76.42%\n",
      "Client Avg - Loss: 0.1162, Acc: 95.90%\n",
      "Round 89/100, μ=0.0169, Clients: 10\n",
      "Global Test - Loss: 0.4822, Acc: 82.71%\n",
      "Client Avg - Loss: 0.0947, Acc: 96.97%\n",
      "Round 90/100, μ=0.0166, Clients: 10\n",
      "Global Test - Loss: 0.4921, Acc: 82.86%\n",
      "Client Avg - Loss: 0.1236, Acc: 95.74%\n",
      "Round 91/100, μ=0.0162, Clients: 10\n",
      "Global Test - Loss: 0.5133, Acc: 82.02%\n",
      "Client Avg - Loss: 0.1415, Acc: 94.83%\n",
      "Round 92/100, μ=0.0159, Clients: 10\n",
      "Global Test - Loss: 0.5214, Acc: 80.80%\n",
      "Client Avg - Loss: 0.1368, Acc: 95.18%\n",
      "Round 93/100, μ=0.0156, Clients: 10\n",
      "Global Test - Loss: 0.4803, Acc: 83.46%\n",
      "Client Avg - Loss: 0.0861, Acc: 97.50%\n",
      "Round 94/100, μ=0.0153, Clients: 10\n",
      "Global Test - Loss: 0.5340, Acc: 78.69%\n",
      "Client Avg - Loss: 0.1306, Acc: 95.24%\n",
      "Round 95/100, μ=0.0150, Clients: 10\n",
      "Global Test - Loss: 0.4906, Acc: 81.42%\n",
      "Client Avg - Loss: 0.1064, Acc: 96.28%\n",
      "Round 96/100, μ=0.0147, Clients: 10\n",
      "Global Test - Loss: 0.5649, Acc: 78.26%\n",
      "Client Avg - Loss: 0.1110, Acc: 95.97%\n",
      "Round 97/100, μ=0.0144, Clients: 10\n",
      "Global Test - Loss: 0.4948, Acc: 82.27%\n",
      "Client Avg - Loss: 0.1225, Acc: 95.93%\n",
      "Round 98/100, μ=0.0141, Clients: 10\n",
      "Global Test - Loss: 0.5667, Acc: 80.14%\n",
      "Client Avg - Loss: 0.1337, Acc: 94.98%\n",
      "Round 99/100, μ=0.0138, Clients: 10\n",
      "Global Test - Loss: 0.4951, Acc: 81.72%\n",
      "Client Avg - Loss: 0.1254, Acc: 95.72%\n",
      "Round 100/100, μ=0.0135, Clients: 10\n",
      "Global Test - Loss: 0.5126, Acc: 80.51%\n",
      "Client Avg - Loss: 0.0891, Acc: 97.23%\n",
      "Training complete! Results saved.\n"
     ]
    }
   ],
   "source": [
    "# FedProx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def load_femnist_data(num_clients=100, iid_degree=0.1):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    full_dataset = datasets.EMNIST(\n",
    "        root='./data',\n",
    "        split='byclass',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    \n",
    "    client_data = {i: {'x': [], 'y': []} for i in range(num_clients)}\n",
    "    targets = full_dataset.targets.numpy()\n",
    "\n",
    "    for class_idx in range(62):  \n",
    "        class_indices = np.where(targets == class_idx)[0]\n",
    "        np.random.shuffle(class_indices)\n",
    "\n",
    "        proportions = np.random.dirichlet(np.repeat(iid_degree, num_clients))\n",
    "        allocations = (proportions * len(class_indices)).astype(int)\n",
    "        allocations[-1] = len(class_indices) - np.sum(allocations[:-1])\n",
    "\n",
    "        start_idx = 0\n",
    "        for client_id in range(num_clients):\n",
    "            end_idx = start_idx + allocations[client_id]\n",
    "            client_indices = class_indices[start_idx:end_idx]\n",
    "\n",
    "            for idx in client_indices:\n",
    "                img, label = full_dataset[idx]\n",
    "                client_data[client_id]['x'].append(img)\n",
    "                client_data[client_id]['y'].append(label)\n",
    "\n",
    "            start_idx = end_idx\n",
    "\n",
    "    client_loaders = {}\n",
    "    for client_id, data in client_data.items():\n",
    "        if len(data['x']) == 0:\n",
    "            continue\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(\n",
    "            data['x'], data['y'], test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        train_dataset = CustomDataset(x_train, y_train)\n",
    "        test_dataset = CustomDataset(x_test, y_test)\n",
    "\n",
    "        client_loaders[client_id] = {\n",
    "            'train': DataLoader(train_dataset, batch_size=32, shuffle=True),\n",
    "            'test': DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "        }\n",
    "\n",
    "    return client_loaders\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "class FemnistCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FemnistCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
    "        self.fc1 = nn.Linear(7*7*64, 512)\n",
    "        self.fc2 = nn.Linear(512, 62)  # 62个类别\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 7*7*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class FedProxClient:\n",
    "    def __init__(self, client_id, train_loader, test_loader, device):\n",
    "        self.client_id = client_id\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        self.model = FemnistCNN().to(device)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def train(self, global_model, mu, local_epochs, lr=0.01):\n",
    "        self.model.load_state_dict(global_model.state_dict())\n",
    "        self.model.train()\n",
    "\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=lr)\n",
    "\n",
    "        train_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for epoch in range(local_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for data, targets in self.train_loader:\n",
    "                data, targets = data.to(self.device), targets.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = self.model(data)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                proximal_term = 0.0\n",
    "                for w, w_t in zip(self.model.parameters(), global_model.parameters()):\n",
    "                    proximal_term += (w - w_t).norm(2)\n",
    "\n",
    "                loss = loss + (mu / 2) * proximal_term\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            epoch_loss /= len(self.train_loader)\n",
    "            train_loss += epoch_loss\n",
    "\n",
    "        train_loss /= local_epochs\n",
    "        train_acc = 100. * correct / total\n",
    "\n",
    "        return copy.deepcopy(self.model.state_dict()), train_loss, train_acc\n",
    "\n",
    "    def test(self, model=None):\n",
    "        if model:\n",
    "            self.model.load_state_dict(model)\n",
    "        self.model.eval()\n",
    "\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, targets in self.test_loader:\n",
    "                data, targets = data.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(data)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        test_loss /= len(self.test_loader)\n",
    "        test_acc = 100. * correct / total\n",
    "\n",
    "        return test_loss, test_acc\n",
    "\n",
    "# ======================\n",
    "# FedProx server\n",
    "# ======================\n",
    "class FedProxServer:\n",
    "    def __init__(self, num_clients, device, mu=0.1, dynamic_mu=False):\n",
    "        self.global_model = FemnistCNN().to(device)\n",
    "        self.device = device\n",
    "        self.clients = []\n",
    "        self.mu = mu\n",
    "        self.dynamic_mu = dynamic_mu\n",
    "        self.num_clients = num_clients\n",
    "\n",
    "    def add_clients(self, client_loaders):\n",
    "        for client_id, loaders in client_loaders.items():\n",
    "            self.clients.append(FedProxClient(\n",
    "                client_id,\n",
    "                loaders['train'],\n",
    "                loaders['test'],\n",
    "                self.device\n",
    "            ))\n",
    "\n",
    "    def aggregate(self, client_updates):\n",
    "        global_dict = self.global_model.state_dict()\n",
    "\n",
    "        total_samples = sum([samples for _, samples, _ in client_updates])\n",
    "        averaged_params = {}\n",
    "\n",
    "        for key in global_dict.keys():\n",
    "            averaged_params[key] = torch.zeros_like(global_dict[key])\n",
    "\n",
    "        for model_state, samples, _ in client_updates:\n",
    "            for key in model_state.keys():\n",
    "                averaged_params[key] += model_state[key] * (samples / total_samples)\n",
    "\n",
    "        self.global_model.load_state_dict(averaged_params)\n",
    "        return averaged_params\n",
    "\n",
    "    def select_clients(self, fraction=0.1):\n",
    "        num_selected = max(int(self.num_clients * fraction), 1)\n",
    "        return np.random.choice(self.clients, num_selected, replace=False)\n",
    "\n",
    "    def adaptive_mu(self, round_idx, base_mu=0.1, decay_rate=0.98):\n",
    "        if self.dynamic_mu:\n",
    "            return base_mu * (decay_rate ** round_idx)\n",
    "        return self.mu\n",
    "\n",
    "    def evaluate_global_model(self, test_loader=None):\n",
    "        self.global_model.eval()\n",
    "\n",
    "        if test_loader:\n",
    "            return self._centralized_eval(test_loader)\n",
    "        else:\n",
    "            return self._federated_eval()\n",
    "\n",
    "    def _centralized_eval(self, test_loader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        test_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, targets in test_loader:\n",
    "                data, targets = data.to(self.device), targets.to(self.device)\n",
    "                outputs = self.global_model(data)\n",
    "                loss = F.cross_entropy(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_acc = 100. * correct / total\n",
    "        return test_loss, test_acc\n",
    "\n",
    "    def _federated_eval(self):\n",
    "        total_loss = 0.0\n",
    "        total_acc = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        for client in self.clients:\n",
    "            samples = len(client.test_loader.dataset)\n",
    "            loss, acc = client.test(self.global_model.state_dict())\n",
    "\n",
    "            total_loss += loss * samples\n",
    "            total_acc += acc * samples\n",
    "            total_samples += samples\n",
    "\n",
    "        avg_loss = total_loss / total_samples\n",
    "        avg_acc = total_acc / total_samples\n",
    "        return avg_loss, avg_acc\n",
    "\n",
    "# ======================\n",
    "# main function\n",
    "# ======================\n",
    "def main():\n",
    "    num_rounds = 100\n",
    "    num_clients = 100\n",
    "    client_fraction = 0.1\n",
    "    local_epochs = 5\n",
    "    base_mu = 0.1\n",
    "    dynamic_mu = True  \n",
    "\n",
    "    print(\"Loading EMNIST data...\")\n",
    "    client_loaders = load_femnist_data(num_clients=num_clients, iid_degree=0.1)\n",
    "\n",
    "    server = FedProxServer(\n",
    "        num_clients=num_clients,\n",
    "        device=device,\n",
    "        mu=base_mu,\n",
    "        dynamic_mu=dynamic_mu\n",
    "    )\n",
    "    server.add_clients(client_loaders)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    test_dataset = datasets.EMNIST(\n",
    "        root='./data',\n",
    "        split='byclass',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transform\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    history = {\n",
    "        'round': [],\n",
    "        'mu': [],\n",
    "        'global_loss': [],\n",
    "        'global_acc': [],\n",
    "        'client_losses': [],\n",
    "        'client_accs': []\n",
    "    }\n",
    "\n",
    "    print(\"Starting Federated Training...\")\n",
    "    for round_idx in range(num_rounds):\n",
    "        mu = server.adaptive_mu(round_idx, base_mu=base_mu)\n",
    "\n",
    "        selected_clients = server.select_clients(fraction=client_fraction)\n",
    "        print(f\"Round {round_idx+1}/{num_rounds}, μ={mu:.4f}, Clients: {len(selected_clients)}\")\n",
    "\n",
    "        client_updates = []\n",
    "        client_stats = {'loss': [], 'acc': []}\n",
    "\n",
    "        for client in selected_clients:\n",
    "            model_state, loss, acc = client.train(\n",
    "                global_model=server.global_model,\n",
    "                mu=mu,\n",
    "                local_epochs=local_epochs,\n",
    "                lr=0.01\n",
    "            )\n",
    "            samples = len(client.train_loader.dataset)\n",
    "            client_updates.append((model_state, samples, client.client_id))\n",
    "            client_stats['loss'].append(loss)\n",
    "            client_stats['acc'].append(acc)\n",
    "\n",
    "        server.aggregate(client_updates)\n",
    "\n",
    "        global_loss, global_acc = server.evaluate_global_model(test_loader=test_loader)\n",
    "\n",
    "        history['round'].append(round_idx)\n",
    "        history['mu'].append(mu)\n",
    "        history['global_loss'].append(global_loss)\n",
    "        history['global_acc'].append(global_acc)\n",
    "        history['client_losses'].append(client_stats['loss'])\n",
    "        history['client_accs'].append(client_stats['acc'])\n",
    "\n",
    "        print(f\"Global Test - Loss: {global_loss:.4f}, Acc: {global_acc:.2f}%\")\n",
    "        print(f\"Client Avg - Loss: {np.mean(client_stats['loss']):.4f}, Acc: {np.mean(client_stats['acc']):.2f}%\")\n",
    "\n",
    "    torch.save({\n",
    "        'model': server.global_model.state_dict(),\n",
    "        'history': history\n",
    "    }, 'fedprox_femnist_results.pth')\n",
    "    print(\"Training complete! Results saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[0] Loading EMNIST...\n",
      "[1] Dataset loaded. Total samples: 112800\n",
      "[2] Partitioning data...\n",
      "[3] Partition done in 0.01s\n",
      "[4] Initializing models...\n",
      "[5] Starting federated training...\n",
      "Round 1/100, Clients: 10\n",
      "Global Test - Loss: 3.8508, Acc: 2.13%\n",
      "Round 2/100, Clients: 10\n",
      "Global Test - Loss: 3.8487, Acc: 2.21%\n",
      "Round 3/100, Clients: 10\n",
      "Global Test - Loss: 3.8466, Acc: 2.26%\n",
      "Round 4/100, Clients: 10\n",
      "Global Test - Loss: 3.8445, Acc: 2.30%\n",
      "Round 5/100, Clients: 10\n",
      "Global Test - Loss: 3.8425, Acc: 2.35%\n",
      "Round 6/100, Clients: 10\n",
      "Global Test - Loss: 3.8405, Acc: 2.43%\n",
      "Round 7/100, Clients: 10\n",
      "Global Test - Loss: 3.8386, Acc: 2.52%\n",
      "Round 8/100, Clients: 10\n",
      "Global Test - Loss: 3.8366, Acc: 2.62%\n",
      "Round 9/100, Clients: 10\n",
      "Global Test - Loss: 3.8346, Acc: 2.88%\n",
      "Round 10/100, Clients: 10\n",
      "Global Test - Loss: 3.8327, Acc: 3.11%\n",
      "Round 11/100, Clients: 10\n",
      "Global Test - Loss: 3.8308, Acc: 3.36%\n",
      "Round 12/100, Clients: 10\n",
      "Global Test - Loss: 3.8289, Acc: 3.67%\n",
      "Round 13/100, Clients: 10\n",
      "Global Test - Loss: 3.8269, Acc: 4.04%\n",
      "Round 14/100, Clients: 10\n",
      "Global Test - Loss: 3.8249, Acc: 4.47%\n",
      "Round 15/100, Clients: 10\n",
      "Global Test - Loss: 3.8228, Acc: 4.88%\n",
      "Round 16/100, Clients: 10\n",
      "Global Test - Loss: 3.8206, Acc: 5.34%\n",
      "Round 17/100, Clients: 10\n",
      "Global Test - Loss: 3.8184, Acc: 5.78%\n",
      "Round 18/100, Clients: 10\n",
      "Global Test - Loss: 3.8160, Acc: 6.17%\n",
      "Round 19/100, Clients: 10\n",
      "Global Test - Loss: 3.8135, Acc: 6.59%\n",
      "Round 20/100, Clients: 10\n",
      "Global Test - Loss: 3.8110, Acc: 7.07%\n",
      "Round 21/100, Clients: 10\n",
      "Global Test - Loss: 3.8084, Acc: 7.44%\n",
      "Round 22/100, Clients: 10\n",
      "Global Test - Loss: 3.8056, Acc: 7.81%\n",
      "Round 23/100, Clients: 10\n",
      "Global Test - Loss: 3.8028, Acc: 8.25%\n",
      "Round 24/100, Clients: 10\n",
      "Global Test - Loss: 3.7999, Acc: 8.63%\n",
      "Round 25/100, Clients: 10\n",
      "Global Test - Loss: 3.7967, Acc: 9.04%\n",
      "Round 26/100, Clients: 10\n",
      "Global Test - Loss: 3.7935, Acc: 9.45%\n",
      "Round 27/100, Clients: 10\n",
      "Global Test - Loss: 3.7901, Acc: 9.77%\n",
      "Round 28/100, Clients: 10\n",
      "Global Test - Loss: 3.7865, Acc: 10.17%\n",
      "Round 29/100, Clients: 10\n",
      "Global Test - Loss: 3.7828, Acc: 10.59%\n",
      "Round 30/100, Clients: 10\n",
      "Global Test - Loss: 3.7789, Acc: 10.94%\n",
      "Round 31/100, Clients: 10\n",
      "Global Test - Loss: 3.7747, Acc: 11.23%\n",
      "Round 32/100, Clients: 10\n",
      "Global Test - Loss: 3.7703, Acc: 11.68%\n",
      "Round 33/100, Clients: 10\n",
      "Global Test - Loss: 3.7656, Acc: 12.09%\n",
      "Round 34/100, Clients: 10\n",
      "Global Test - Loss: 3.7606, Acc: 12.47%\n",
      "Round 35/100, Clients: 10\n",
      "Global Test - Loss: 3.7553, Acc: 12.77%\n",
      "Round 36/100, Clients: 10\n",
      "Global Test - Loss: 3.7497, Acc: 13.18%\n",
      "Round 37/100, Clients: 10\n",
      "Global Test - Loss: 3.7437, Acc: 13.66%\n",
      "Round 38/100, Clients: 10\n",
      "Global Test - Loss: 3.7372, Acc: 14.00%\n",
      "Round 39/100, Clients: 10\n",
      "Global Test - Loss: 3.7303, Acc: 14.43%\n",
      "Round 40/100, Clients: 10\n",
      "Global Test - Loss: 3.7230, Acc: 14.86%\n",
      "Round 41/100, Clients: 10\n",
      "Global Test - Loss: 3.7152, Acc: 15.35%\n",
      "Round 42/100, Clients: 10\n",
      "Global Test - Loss: 3.7069, Acc: 15.78%\n",
      "Round 43/100, Clients: 10\n",
      "Global Test - Loss: 3.6981, Acc: 16.29%\n",
      "Round 44/100, Clients: 10\n",
      "Global Test - Loss: 3.6885, Acc: 16.77%\n",
      "Round 45/100, Clients: 10\n",
      "Global Test - Loss: 3.6784, Acc: 17.53%\n",
      "Round 46/100, Clients: 10\n",
      "Global Test - Loss: 3.6673, Acc: 18.21%\n",
      "Round 47/100, Clients: 10\n",
      "Global Test - Loss: 3.6551, Acc: 19.00%\n",
      "Round 48/100, Clients: 10\n",
      "Global Test - Loss: 3.6419, Acc: 19.94%\n",
      "Round 49/100, Clients: 10\n",
      "Global Test - Loss: 3.6280, Acc: 20.76%\n",
      "Round 50/100, Clients: 10\n",
      "Global Test - Loss: 3.6128, Acc: 21.64%\n",
      "Round 51/100, Clients: 10\n",
      "Global Test - Loss: 3.5962, Acc: 22.42%\n",
      "Round 52/100, Clients: 10\n",
      "Global Test - Loss: 3.5784, Acc: 23.30%\n",
      "Round 53/100, Clients: 10\n",
      "Global Test - Loss: 3.5590, Acc: 24.11%\n",
      "Round 54/100, Clients: 10\n",
      "Global Test - Loss: 3.5382, Acc: 24.69%\n",
      "Round 55/100, Clients: 10\n",
      "Global Test - Loss: 3.5155, Acc: 25.30%\n",
      "Round 56/100, Clients: 10\n",
      "Global Test - Loss: 3.4910, Acc: 25.84%\n",
      "Round 57/100, Clients: 10\n",
      "Global Test - Loss: 3.4644, Acc: 26.49%\n",
      "Round 58/100, Clients: 10\n",
      "Global Test - Loss: 3.4354, Acc: 27.12%\n",
      "Round 59/100, Clients: 10\n",
      "Global Test - Loss: 3.4038, Acc: 27.78%\n",
      "Round 60/100, Clients: 10\n",
      "Global Test - Loss: 3.3701, Acc: 28.51%\n",
      "Round 61/100, Clients: 10\n",
      "Global Test - Loss: 3.3340, Acc: 29.29%\n",
      "Round 62/100, Clients: 10\n",
      "Global Test - Loss: 3.2946, Acc: 30.21%\n",
      "Round 63/100, Clients: 10\n",
      "Global Test - Loss: 3.2526, Acc: 30.98%\n",
      "Round 64/100, Clients: 10\n",
      "Global Test - Loss: 3.2076, Acc: 31.85%\n",
      "Round 65/100, Clients: 10\n",
      "Global Test - Loss: 3.1599, Acc: 32.78%\n",
      "Round 66/100, Clients: 10\n",
      "Global Test - Loss: 3.1088, Acc: 33.71%\n",
      "Round 67/100, Clients: 10\n",
      "Global Test - Loss: 3.0553, Acc: 34.54%\n",
      "Round 68/100, Clients: 10\n",
      "Global Test - Loss: 2.9992, Acc: 35.38%\n",
      "Round 69/100, Clients: 10\n",
      "Global Test - Loss: 2.9409, Acc: 36.18%\n",
      "Round 70/100, Clients: 10\n",
      "Global Test - Loss: 2.8813, Acc: 37.08%\n",
      "Round 71/100, Clients: 10\n",
      "Global Test - Loss: 2.8204, Acc: 37.94%\n",
      "Round 72/100, Clients: 10\n",
      "Global Test - Loss: 2.7576, Acc: 38.78%\n",
      "Round 73/100, Clients: 10\n",
      "Global Test - Loss: 2.6949, Acc: 39.56%\n",
      "Round 74/100, Clients: 10\n",
      "Global Test - Loss: 2.6320, Acc: 40.31%\n",
      "Round 75/100, Clients: 10\n",
      "Global Test - Loss: 2.5702, Acc: 41.16%\n",
      "Round 76/100, Clients: 10\n",
      "Global Test - Loss: 2.5102, Acc: 41.97%\n",
      "Round 77/100, Clients: 10\n",
      "Global Test - Loss: 2.4513, Acc: 42.90%\n",
      "Round 78/100, Clients: 10\n",
      "Global Test - Loss: 2.3941, Acc: 43.65%\n",
      "Round 79/100, Clients: 10\n",
      "Global Test - Loss: 2.3397, Acc: 44.28%\n",
      "Round 80/100, Clients: 10\n",
      "Global Test - Loss: 2.2864, Acc: 44.92%\n",
      "Round 81/100, Clients: 10\n",
      "Global Test - Loss: 2.2358, Acc: 45.69%\n",
      "Round 82/100, Clients: 10\n",
      "Global Test - Loss: 2.1886, Acc: 46.31%\n",
      "Round 83/100, Clients: 10\n",
      "Global Test - Loss: 2.1444, Acc: 46.98%\n",
      "Round 84/100, Clients: 10\n",
      "Global Test - Loss: 2.1018, Acc: 47.61%\n",
      "Round 85/100, Clients: 10\n",
      "Global Test - Loss: 2.0622, Acc: 48.25%\n",
      "Round 86/100, Clients: 10\n",
      "Global Test - Loss: 2.0249, Acc: 48.82%\n",
      "Round 87/100, Clients: 10\n",
      "Global Test - Loss: 1.9897, Acc: 49.12%\n",
      "Round 88/100, Clients: 10\n",
      "Global Test - Loss: 1.9565, Acc: 49.72%\n",
      "Round 89/100, Clients: 10\n",
      "Global Test - Loss: 1.9253, Acc: 50.22%\n",
      "Round 90/100, Clients: 10\n",
      "Global Test - Loss: 1.8957, Acc: 50.59%\n",
      "Round 91/100, Clients: 10\n",
      "Global Test - Loss: 1.8671, Acc: 51.23%\n",
      "Round 92/100, Clients: 10\n",
      "Global Test - Loss: 1.8412, Acc: 51.54%\n",
      "Round 93/100, Clients: 10\n",
      "Global Test - Loss: 1.8162, Acc: 52.03%\n",
      "Round 94/100, Clients: 10\n",
      "Global Test - Loss: 1.7926, Acc: 52.35%\n",
      "Round 95/100, Clients: 10\n",
      "Global Test - Loss: 1.7702, Acc: 52.78%\n",
      "Round 96/100, Clients: 10\n",
      "Global Test - Loss: 1.7493, Acc: 53.20%\n",
      "Round 97/100, Clients: 10\n",
      "Global Test - Loss: 1.7287, Acc: 53.67%\n",
      "Round 98/100, Clients: 10\n",
      "Global Test - Loss: 1.7091, Acc: 53.96%\n",
      "Round 99/100, Clients: 10\n",
      "Global Test - Loss: 1.6907, Acc: 54.37%\n",
      "Round 100/100, Clients: 10\n",
      "Global Test - Loss: 1.6726, Acc: 54.72%\n",
      "[6] Done. Total time: 2173.10s\n"
     ]
    }
   ],
   "source": [
    "# FedAVG\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Model Definition\n",
    "# -----------------------------\n",
    "class EMNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*5*5, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 47)  # EMNIST Balanced has 47 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.conv(x))\n",
    "\n",
    "# -----------------------------\n",
    "# 2. EMNIST Partitioning (Non-IID)\n",
    "# -----------------------------\n",
    "def partition_data(dataset, num_clients=100):\n",
    "    labels = dataset.targets.numpy() if torch.is_tensor(dataset.targets) else np.array(dataset.targets)\n",
    "    idx_by_class = [np.where(labels == i)[0] for i in range(47)]\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "    for c in range(47):\n",
    "        np.random.shuffle(idx_by_class[c])\n",
    "        parts = np.array_split(idx_by_class[c], num_clients)\n",
    "        for i in range(num_clients):\n",
    "            client_indices[i].extend(parts[i])\n",
    "    return [Subset(dataset, inds) for inds in client_indices]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Client Class (FedAvg)\n",
    "# -----------------------------\n",
    "class Client:\n",
    "    def __init__(self, model, data, lr, local_epochs, device):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.data = data\n",
    "        self.lr = lr\n",
    "        self.local_epochs = local_epochs\n",
    "        self.device = device\n",
    "\n",
    "    def train(self, global_model):\n",
    "        self.model.load_state_dict(global_model.state_dict())\n",
    "        self.model.train()\n",
    "\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=self.lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loader = DataLoader(self.data, batch_size=32, shuffle=True)\n",
    "\n",
    "        for epoch in range(self.local_epochs):\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        return copy.deepcopy(self.model.state_dict())\n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        loader = DataLoader(self.data, batch_size=64, shuffle=False)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "                total_loss += loss.item() * x.size(0)\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += x.size(0)\n",
    "        return total_loss / total, correct / total\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Server Class (FedAvg)\n",
    "# -----------------------------\n",
    "class Server:\n",
    "    def __init__(self, model, num_clients):\n",
    "        self.global_model = model\n",
    "        self.clients = []\n",
    "        self.num_clients = num_clients\n",
    "\n",
    "    def add_clients(self, client_list):\n",
    "        self.clients = client_list\n",
    "\n",
    "    def aggregate(self, client_states):\n",
    "        avg_state = copy.deepcopy(self.global_model.state_dict())\n",
    "        for k in avg_state:\n",
    "            avg_state[k] = sum(client[k] for client in client_states) / len(client_states)\n",
    "        self.global_model.load_state_dict(avg_state)\n",
    "\n",
    "    def federated_train(self, rounds):\n",
    "        for r in range(rounds):\n",
    "            round_start = time.time()\n",
    "            selected = random.sample(self.clients, k=10)\n",
    "            client_states = []\n",
    "\n",
    "            print(f\"Round {r+1}/{rounds}, Clients: {len(selected)}\")\n",
    "\n",
    "            for client in selected:\n",
    "                state_dict = client.train(self.global_model)\n",
    "                client_states.append(state_dict)\n",
    "\n",
    "            self.aggregate(client_states)\n",
    "\n",
    "            # 全部客户端用于评估\n",
    "            global_losses, global_accs = [], []\n",
    "            for client in self.clients:\n",
    "                client.model.load_state_dict(self.global_model.state_dict())\n",
    "                loss, acc = client.evaluate()\n",
    "                global_losses.append(loss)\n",
    "                global_accs.append(acc)\n",
    "\n",
    "            avg_loss = np.mean(global_losses)\n",
    "            avg_acc = np.mean(global_accs) * 100\n",
    "\n",
    "            print(f\"Global Test - Loss: {avg_loss:.4f}, Acc: {avg_acc:.2f}%\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Main Execution\n",
    "# -----------------------------\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    print(\"[0] Loading EMNIST...\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    emnist_train = datasets.EMNIST(root=\"./data\", split=\"balanced\", train=True, download=True, transform=transform)\n",
    "    print(f\"[1] Dataset loaded. Total samples: {len(emnist_train)}\")\n",
    "\n",
    "    print(\"[2] Partitioning data...\")\n",
    "    partition_start = time.time()\n",
    "    client_data = partition_data(emnist_train, num_clients=100)\n",
    "    print(f\"[3] Partition done in {time.time() - partition_start:.2f}s\")\n",
    "\n",
    "    print(\"[4] Initializing models...\")\n",
    "    global_model = EMNIST_CNN().to(device)\n",
    "    server = Server(global_model, num_clients=100)\n",
    "    clients = [Client(global_model, data, lr=0.001, local_epochs=2, device=device) for data in client_data]\n",
    "    server.add_clients(clients)\n",
    "\n",
    "    print(\"[5] Starting federated training...\")\n",
    "    server.federated_train(rounds=100)\n",
    "\n",
    "    print(f\"[6] Done. Total time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[0] Loading EMNIST...\n",
      "[1] Dataset loaded. Total samples: 112800\n",
      "[2] Partitioning data...\n",
      "[3] Partition done in 0.01s\n",
      "[4] Initializing models...\n",
      "[5] Starting federated training...\n",
      "Round 1/100, Clients: 10\n",
      "Global Test - Loss: 3.8496, Acc: 2.36%\n",
      "Round 2/100, Clients: 10\n",
      "Global Test - Loss: 3.8472, Acc: 2.67%\n",
      "Round 3/100, Clients: 10\n",
      "Global Test - Loss: 3.8450, Acc: 3.01%\n",
      "Round 4/100, Clients: 10\n",
      "Global Test - Loss: 3.8428, Acc: 3.36%\n",
      "Round 5/100, Clients: 10\n",
      "Global Test - Loss: 3.8407, Acc: 3.77%\n",
      "Round 6/100, Clients: 10\n",
      "Global Test - Loss: 3.8387, Acc: 4.24%\n",
      "Round 7/100, Clients: 10\n",
      "Global Test - Loss: 3.8366, Acc: 4.68%\n",
      "Round 8/100, Clients: 10\n",
      "Global Test - Loss: 3.8345, Acc: 5.09%\n",
      "Round 9/100, Clients: 10\n",
      "Global Test - Loss: 3.8324, Acc: 5.47%\n",
      "Round 10/100, Clients: 10\n",
      "Global Test - Loss: 3.8303, Acc: 5.83%\n",
      "Round 11/100, Clients: 10\n",
      "Global Test - Loss: 3.8281, Acc: 6.22%\n",
      "Round 12/100, Clients: 10\n",
      "Global Test - Loss: 3.8259, Acc: 6.61%\n",
      "Round 13/100, Clients: 10\n",
      "Global Test - Loss: 3.8236, Acc: 6.94%\n",
      "Round 14/100, Clients: 10\n",
      "Global Test - Loss: 3.8212, Acc: 7.44%\n",
      "Round 15/100, Clients: 10\n",
      "Global Test - Loss: 3.8187, Acc: 7.82%\n",
      "Round 16/100, Clients: 10\n",
      "Global Test - Loss: 3.8161, Acc: 8.31%\n",
      "Round 17/100, Clients: 10\n",
      "Global Test - Loss: 3.8134, Acc: 8.75%\n",
      "Round 18/100, Clients: 10\n",
      "Global Test - Loss: 3.8105, Acc: 9.22%\n",
      "Round 19/100, Clients: 10\n",
      "Global Test - Loss: 3.8075, Acc: 9.65%\n",
      "Round 20/100, Clients: 10\n",
      "Global Test - Loss: 3.8043, Acc: 10.18%\n",
      "Round 21/100, Clients: 10\n",
      "Global Test - Loss: 3.8010, Acc: 10.59%\n",
      "Round 22/100, Clients: 10\n",
      "Global Test - Loss: 3.7975, Acc: 11.14%\n",
      "Round 23/100, Clients: 10\n",
      "Global Test - Loss: 3.7938, Acc: 11.56%\n",
      "Round 24/100, Clients: 10\n",
      "Global Test - Loss: 3.7899, Acc: 12.00%\n",
      "Round 25/100, Clients: 10\n",
      "Global Test - Loss: 3.7859, Acc: 12.32%\n",
      "Round 26/100, Clients: 10\n",
      "Global Test - Loss: 3.7816, Acc: 12.81%\n",
      "Round 27/100, Clients: 10\n",
      "Global Test - Loss: 3.7771, Acc: 13.17%\n",
      "Round 28/100, Clients: 10\n",
      "Global Test - Loss: 3.7723, Acc: 13.55%\n",
      "Round 29/100, Clients: 10\n",
      "Global Test - Loss: 3.7672, Acc: 13.97%\n",
      "Round 30/100, Clients: 10\n",
      "Global Test - Loss: 3.7619, Acc: 14.43%\n",
      "Round 31/100, Clients: 10\n",
      "Global Test - Loss: 3.7562, Acc: 14.77%\n",
      "Round 32/100, Clients: 10\n",
      "Global Test - Loss: 3.7502, Acc: 15.12%\n",
      "Round 33/100, Clients: 10\n",
      "Global Test - Loss: 3.7437, Acc: 15.54%\n",
      "Round 34/100, Clients: 10\n",
      "Global Test - Loss: 3.7369, Acc: 15.90%\n",
      "Round 35/100, Clients: 10\n",
      "Global Test - Loss: 3.7296, Acc: 16.22%\n",
      "Round 36/100, Clients: 10\n",
      "Global Test - Loss: 3.7219, Acc: 16.65%\n",
      "Round 37/100, Clients: 10\n",
      "Global Test - Loss: 3.7137, Acc: 16.95%\n",
      "Round 38/100, Clients: 10\n",
      "Global Test - Loss: 3.7050, Acc: 17.25%\n",
      "Round 39/100, Clients: 10\n",
      "Global Test - Loss: 3.6957, Acc: 17.52%\n",
      "Round 40/100, Clients: 10\n",
      "Global Test - Loss: 3.6856, Acc: 17.97%\n",
      "Round 41/100, Clients: 10\n",
      "Global Test - Loss: 3.6749, Acc: 18.38%\n",
      "Round 42/100, Clients: 10\n",
      "Global Test - Loss: 3.6635, Acc: 18.88%\n",
      "Round 43/100, Clients: 10\n",
      "Global Test - Loss: 3.6512, Acc: 19.22%\n",
      "Round 44/100, Clients: 10\n",
      "Global Test - Loss: 3.6381, Acc: 19.65%\n",
      "Round 45/100, Clients: 10\n",
      "Global Test - Loss: 3.6239, Acc: 20.11%\n",
      "Round 46/100, Clients: 10\n",
      "Global Test - Loss: 3.6086, Acc: 20.65%\n",
      "Round 47/100, Clients: 10\n",
      "Global Test - Loss: 3.5922, Acc: 21.05%\n",
      "Round 48/100, Clients: 10\n",
      "Global Test - Loss: 3.5743, Acc: 21.66%\n",
      "Round 49/100, Clients: 10\n",
      "Global Test - Loss: 3.5551, Acc: 22.41%\n",
      "Round 50/100, Clients: 10\n",
      "Global Test - Loss: 3.5344, Acc: 23.19%\n",
      "Round 51/100, Clients: 10\n",
      "Global Test - Loss: 3.5121, Acc: 24.09%\n",
      "Round 52/100, Clients: 10\n",
      "Global Test - Loss: 3.4880, Acc: 24.98%\n",
      "Round 53/100, Clients: 10\n",
      "Global Test - Loss: 3.4618, Acc: 25.65%\n",
      "Round 54/100, Clients: 10\n",
      "Global Test - Loss: 3.4335, Acc: 26.71%\n",
      "Round 55/100, Clients: 10\n",
      "Global Test - Loss: 3.4025, Acc: 27.61%\n",
      "Round 56/100, Clients: 10\n",
      "Global Test - Loss: 3.3691, Acc: 28.69%\n",
      "Round 57/100, Clients: 10\n",
      "Global Test - Loss: 3.3330, Acc: 29.87%\n",
      "Round 58/100, Clients: 10\n",
      "Global Test - Loss: 3.2936, Acc: 31.05%\n",
      "Round 59/100, Clients: 10\n",
      "Global Test - Loss: 3.2514, Acc: 32.26%\n",
      "Round 60/100, Clients: 10\n",
      "Global Test - Loss: 3.2058, Acc: 33.32%\n",
      "Round 61/100, Clients: 10\n",
      "Global Test - Loss: 3.1574, Acc: 34.38%\n",
      "Round 62/100, Clients: 10\n",
      "Global Test - Loss: 3.1057, Acc: 35.31%\n",
      "Round 63/100, Clients: 10\n",
      "Global Test - Loss: 3.0504, Acc: 36.48%\n",
      "Round 64/100, Clients: 10\n",
      "Global Test - Loss: 2.9919, Acc: 37.43%\n",
      "Round 65/100, Clients: 10\n",
      "Global Test - Loss: 2.9307, Acc: 38.30%\n",
      "Round 66/100, Clients: 10\n",
      "Global Test - Loss: 2.8668, Acc: 39.10%\n",
      "Round 67/100, Clients: 10\n",
      "Global Test - Loss: 2.8018, Acc: 39.98%\n",
      "Round 68/100, Clients: 10\n",
      "Global Test - Loss: 2.7348, Acc: 40.94%\n",
      "Round 69/100, Clients: 10\n",
      "Global Test - Loss: 2.6670, Acc: 41.67%\n",
      "Round 70/100, Clients: 10\n",
      "Global Test - Loss: 2.5994, Acc: 42.75%\n",
      "Round 71/100, Clients: 10\n",
      "Global Test - Loss: 2.5319, Acc: 43.56%\n",
      "Round 72/100, Clients: 10\n",
      "Global Test - Loss: 2.4658, Acc: 44.46%\n",
      "Round 73/100, Clients: 10\n",
      "Global Test - Loss: 2.4010, Acc: 45.14%\n",
      "Round 74/100, Clients: 10\n",
      "Global Test - Loss: 2.3374, Acc: 45.97%\n",
      "Round 75/100, Clients: 10\n",
      "Global Test - Loss: 2.2767, Acc: 46.91%\n",
      "Round 76/100, Clients: 10\n",
      "Global Test - Loss: 2.2189, Acc: 47.62%\n",
      "Round 77/100, Clients: 10\n",
      "Global Test - Loss: 2.1645, Acc: 48.33%\n",
      "Round 78/100, Clients: 10\n",
      "Global Test - Loss: 2.1130, Acc: 48.94%\n",
      "Round 79/100, Clients: 10\n",
      "Global Test - Loss: 2.0642, Acc: 49.66%\n",
      "Round 80/100, Clients: 10\n",
      "Global Test - Loss: 2.0185, Acc: 50.28%\n",
      "Round 81/100, Clients: 10\n",
      "Global Test - Loss: 1.9761, Acc: 50.65%\n",
      "Round 82/100, Clients: 10\n",
      "Global Test - Loss: 1.9365, Acc: 51.26%\n",
      "Round 83/100, Clients: 10\n",
      "Global Test - Loss: 1.8992, Acc: 51.81%\n",
      "Round 84/100, Clients: 10\n",
      "Global Test - Loss: 1.8647, Acc: 52.23%\n",
      "Round 85/100, Clients: 10\n",
      "Global Test - Loss: 1.8327, Acc: 52.69%\n",
      "Round 86/100, Clients: 10\n",
      "Global Test - Loss: 1.8029, Acc: 53.15%\n",
      "Round 87/100, Clients: 10\n",
      "Global Test - Loss: 1.7752, Acc: 53.53%\n",
      "Round 88/100, Clients: 10\n",
      "Global Test - Loss: 1.7492, Acc: 54.11%\n",
      "Round 89/100, Clients: 10\n",
      "Global Test - Loss: 1.7243, Acc: 54.41%\n",
      "Round 90/100, Clients: 10\n",
      "Global Test - Loss: 1.7015, Acc: 54.78%\n",
      "Round 91/100, Clients: 10\n",
      "Global Test - Loss: 1.6800, Acc: 55.15%\n",
      "Round 92/100, Clients: 10\n",
      "Global Test - Loss: 1.6598, Acc: 55.57%\n",
      "Round 93/100, Clients: 10\n",
      "Global Test - Loss: 1.6401, Acc: 55.77%\n",
      "Round 94/100, Clients: 10\n",
      "Global Test - Loss: 1.6220, Acc: 56.12%\n",
      "Round 95/100, Clients: 10\n",
      "Global Test - Loss: 1.6047, Acc: 56.48%\n",
      "Round 96/100, Clients: 10\n",
      "Global Test - Loss: 1.5887, Acc: 56.83%\n",
      "Round 97/100, Clients: 10\n",
      "Global Test - Loss: 1.5726, Acc: 57.04%\n",
      "Round 98/100, Clients: 10\n",
      "Global Test - Loss: 1.5576, Acc: 57.35%\n",
      "Round 99/100, Clients: 10\n",
      "Global Test - Loss: 1.5434, Acc: 57.60%\n",
      "Round 100/100, Clients: 10\n",
      "Global Test - Loss: 1.5299, Acc: 57.89%\n",
      "[6] Done. Total time: 2737.32s\n"
     ]
    }
   ],
   "source": [
    "# SCAFFOLD\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Model Definition\n",
    "# -----------------------------\n",
    "class EMNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*5*5, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 47)  # EMNIST Balanced has 47 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.conv(x))\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Partitioning (Non-IID)\n",
    "# -----------------------------\n",
    "def partition_data(dataset, num_clients=100):\n",
    "    labels = dataset.targets.numpy() if torch.is_tensor(dataset.targets) else np.array(dataset.targets)\n",
    "    idx_by_class = [np.where(labels == i)[0] for i in range(47)]\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "    for c in range(47):\n",
    "        np.random.shuffle(idx_by_class[c])\n",
    "        parts = np.array_split(idx_by_class[c], num_clients)\n",
    "        for i in range(num_clients):\n",
    "            client_indices[i].extend(parts[i])\n",
    "    return [Subset(dataset, inds) for inds in client_indices]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Client Class (SCAFFOLD)\n",
    "# -----------------------------\n",
    "class Client:\n",
    "    def __init__(self, model, data, lr, local_epochs, device):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.data = data\n",
    "        self.lr = lr\n",
    "        self.local_epochs = local_epochs\n",
    "        self.device = device\n",
    "        self.ci = {k: torch.zeros_like(v) for k, v in self.model.state_dict().items()}\n",
    "\n",
    "    def train(self, global_model, global_control):\n",
    "        self.model.load_state_dict(global_model.state_dict())\n",
    "        self.model.train()\n",
    "\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=self.lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loader = DataLoader(self.data, batch_size=32, shuffle=True)\n",
    "\n",
    "        for epoch in range(self.local_epochs):\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "\n",
    "                # SCAFFOLD correction term\n",
    "                control = torch.tensor(0.0, device=self.device)\n",
    "\n",
    "                model_state = self.model.state_dict()\n",
    "                global_state = global_model.state_dict()\n",
    "\n",
    "                for name in model_state:\n",
    "                    p = model_state[name]\n",
    "                    w_t = global_state[name]\n",
    "                    c = global_control[name]\n",
    "                    ci = self.ci[name]\n",
    "                    control += ((p - w_t) * (c - ci)).sum()\n",
    "\n",
    "                loss += 0.5 * control\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Update local control variates\n",
    "        delta_ci = {}\n",
    "        with torch.no_grad():\n",
    "            for k in self.model.state_dict().keys():\n",
    "                delta = global_control[k] - self.ci[k] + \\\n",
    "                        (self.model.state_dict()[k] - global_model.state_dict()[k]) / (self.local_epochs * self.lr)\n",
    "                delta_ci[k] = delta\n",
    "                self.ci[k] += delta\n",
    "\n",
    "        return copy.deepcopy(self.model.state_dict()), delta_ci\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        loader = DataLoader(self.data, batch_size=64, shuffle=False)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "                total_loss += loss.item() * x.size(0)\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += x.size(0)\n",
    "        return total_loss / total, correct / total\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Server Class (SCAFFOLD)\n",
    "# -----------------------------\n",
    "class Server:\n",
    "    def __init__(self, model, num_clients):\n",
    "        self.global_model = model\n",
    "        self.clients = []\n",
    "        self.num_clients = num_clients\n",
    "        self.global_control = {k: torch.zeros_like(v) for k, v in self.global_model.state_dict().items()}\n",
    "\n",
    "    def add_clients(self, client_list):\n",
    "        self.clients = client_list\n",
    "\n",
    "    def aggregate(self, client_states):\n",
    "        avg_state = copy.deepcopy(self.global_model.state_dict())\n",
    "        for k in avg_state:\n",
    "            avg_state[k] = sum(client[k] for client in client_states) / len(client_states)\n",
    "        self.global_model.load_state_dict(avg_state)\n",
    "\n",
    "    def update_control(self, delta_controls):\n",
    "        for k in self.global_control:\n",
    "            self.global_control[k] += sum(delta[k] for delta in delta_controls) / len(delta_controls)\n",
    "\n",
    "    def federated_train(self, rounds):\n",
    "        for r in range(rounds):\n",
    "            selected = random.sample(self.clients, k=10)\n",
    "            client_states, delta_controls = [], []\n",
    "\n",
    "            print(f\"Round {r+1}/{rounds}, Clients: {len(selected)}\")\n",
    "\n",
    "            for client in selected:\n",
    "                state_dict, delta_ci = client.train(self.global_model, self.global_control)\n",
    "                client_states.append(state_dict)\n",
    "                delta_controls.append(delta_ci)\n",
    "\n",
    "            self.aggregate(client_states)\n",
    "            self.update_control(delta_controls)\n",
    "\n",
    "            # Evaluate\n",
    "            global_losses, global_accs = [], []\n",
    "            for client in self.clients:\n",
    "                client.model.load_state_dict(self.global_model.state_dict())\n",
    "                loss, acc = client.evaluate()\n",
    "                global_losses.append(loss)\n",
    "                global_accs.append(acc)\n",
    "\n",
    "            avg_loss = np.mean(global_losses)\n",
    "            avg_acc = np.mean(global_accs) * 100\n",
    "\n",
    "            print(f\"Global Test - Loss: {avg_loss:.4f}, Acc: {avg_acc:.2f}%\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Main Execution\n",
    "# -----------------------------\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    print(\"[0] Loading EMNIST...\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    emnist_train = datasets.EMNIST(root=\"./data\", split=\"balanced\", train=True, download=True, transform=transform)\n",
    "    print(f\"[1] Dataset loaded. Total samples: {len(emnist_train)}\")\n",
    "\n",
    "    print(\"[2] Partitioning data...\")\n",
    "    partition_start = time.time()\n",
    "    client_data = partition_data(emnist_train, num_clients=100)\n",
    "    print(f\"[3] Partition done in {time.time() - partition_start:.2f}s\")\n",
    "\n",
    "    print(\"[4] Initializing models...\")\n",
    "    global_model = EMNIST_CNN().to(device)\n",
    "    server = Server(global_model, num_clients=100)\n",
    "    clients = [Client(global_model, data, lr=0.001, local_epochs=2, device=device) for data in client_data]\n",
    "    server.add_clients(clients)\n",
    "\n",
    "    print(\"[5] Starting federated training...\")\n",
    "    server.federated_train(rounds=100)\n",
    "\n",
    "    print(f\"[6] Done. Total time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[0] Loading EMNIST...\n",
      "[1] Dataset loaded. Total samples: 112800\n",
      "[2] Partitioning data...\n",
      "[3] Partition done in 0.01s\n",
      "[4] Initializing models...\n",
      "[5] Starting federated training...\n",
      "Round 1/100, Clients: 10\n",
      "Global Test - Loss: 3.8537, Acc: 2.74%\n",
      "Round 2/100, Clients: 10\n",
      "Global Test - Loss: 3.8537, Acc: 2.75%\n",
      "Round 3/100, Clients: 10\n",
      "Global Test - Loss: 3.8537, Acc: 2.77%\n",
      "Round 4/100, Clients: 10\n",
      "Global Test - Loss: 3.8536, Acc: 2.79%\n",
      "Round 5/100, Clients: 10\n",
      "Global Test - Loss: 3.8536, Acc: 2.80%\n",
      "Round 6/100, Clients: 10\n",
      "Global Test - Loss: 3.8536, Acc: 2.81%\n",
      "Round 7/100, Clients: 10\n",
      "Global Test - Loss: 3.8535, Acc: 2.82%\n",
      "Round 8/100, Clients: 10\n",
      "Global Test - Loss: 3.8535, Acc: 2.84%\n",
      "Round 9/100, Clients: 10\n",
      "Global Test - Loss: 3.8535, Acc: 2.86%\n",
      "Round 10/100, Clients: 10\n",
      "Global Test - Loss: 3.8534, Acc: 2.88%\n",
      "Round 11/100, Clients: 10\n",
      "Global Test - Loss: 3.8534, Acc: 2.89%\n",
      "Round 12/100, Clients: 10\n",
      "Global Test - Loss: 3.8534, Acc: 2.91%\n",
      "Round 13/100, Clients: 10\n",
      "Global Test - Loss: 3.8533, Acc: 2.92%\n",
      "Round 14/100, Clients: 10\n",
      "Global Test - Loss: 3.8533, Acc: 2.94%\n",
      "Round 15/100, Clients: 10\n",
      "Global Test - Loss: 3.8533, Acc: 2.95%\n",
      "Round 16/100, Clients: 10\n",
      "Global Test - Loss: 3.8532, Acc: 2.97%\n",
      "Round 17/100, Clients: 10\n",
      "Global Test - Loss: 3.8532, Acc: 3.00%\n",
      "Round 18/100, Clients: 10\n",
      "Global Test - Loss: 3.8532, Acc: 3.01%\n",
      "Round 19/100, Clients: 10\n",
      "Global Test - Loss: 3.8531, Acc: 3.02%\n",
      "Round 20/100, Clients: 10\n",
      "Global Test - Loss: 3.8531, Acc: 3.04%\n",
      "Round 21/100, Clients: 10\n",
      "Global Test - Loss: 3.8531, Acc: 3.04%\n",
      "Round 22/100, Clients: 10\n",
      "Global Test - Loss: 3.8530, Acc: 3.05%\n",
      "Round 23/100, Clients: 10\n",
      "Global Test - Loss: 3.8530, Acc: 3.07%\n",
      "Round 24/100, Clients: 10\n",
      "Global Test - Loss: 3.8530, Acc: 3.09%\n",
      "Round 25/100, Clients: 10\n",
      "Global Test - Loss: 3.8529, Acc: 3.11%\n",
      "Round 26/100, Clients: 10\n",
      "Global Test - Loss: 3.8529, Acc: 3.12%\n",
      "Round 27/100, Clients: 10\n",
      "Global Test - Loss: 3.8529, Acc: 3.14%\n",
      "Round 28/100, Clients: 10\n",
      "Global Test - Loss: 3.8529, Acc: 3.15%\n",
      "Round 29/100, Clients: 10\n",
      "Global Test - Loss: 3.8528, Acc: 3.17%\n",
      "Round 30/100, Clients: 10\n",
      "Global Test - Loss: 3.8528, Acc: 3.18%\n",
      "Round 31/100, Clients: 10\n",
      "Global Test - Loss: 3.8528, Acc: 3.20%\n",
      "Round 32/100, Clients: 10\n",
      "Global Test - Loss: 3.8527, Acc: 3.21%\n",
      "Round 33/100, Clients: 10\n",
      "Global Test - Loss: 3.8527, Acc: 3.23%\n",
      "Round 34/100, Clients: 10\n",
      "Global Test - Loss: 3.8527, Acc: 3.25%\n",
      "Round 35/100, Clients: 10\n",
      "Global Test - Loss: 3.8527, Acc: 3.26%\n",
      "Round 36/100, Clients: 10\n",
      "Global Test - Loss: 3.8526, Acc: 3.28%\n",
      "Round 37/100, Clients: 10\n",
      "Global Test - Loss: 3.8526, Acc: 3.29%\n",
      "Round 38/100, Clients: 10\n",
      "Global Test - Loss: 3.8526, Acc: 3.31%\n",
      "Round 39/100, Clients: 10\n",
      "Global Test - Loss: 3.8526, Acc: 3.32%\n",
      "Round 40/100, Clients: 10\n",
      "Global Test - Loss: 3.8525, Acc: 3.33%\n",
      "Round 41/100, Clients: 10\n",
      "Global Test - Loss: 3.8525, Acc: 3.34%\n",
      "Round 42/100, Clients: 10\n",
      "Global Test - Loss: 3.8525, Acc: 3.35%\n",
      "Round 43/100, Clients: 10\n",
      "Global Test - Loss: 3.8525, Acc: 3.37%\n",
      "Round 44/100, Clients: 10\n",
      "Global Test - Loss: 3.8524, Acc: 3.39%\n",
      "Round 45/100, Clients: 10\n",
      "Global Test - Loss: 3.8524, Acc: 3.41%\n",
      "Round 46/100, Clients: 10\n",
      "Global Test - Loss: 3.8524, Acc: 3.42%\n",
      "Round 47/100, Clients: 10\n",
      "Global Test - Loss: 3.8524, Acc: 3.43%\n",
      "Round 48/100, Clients: 10\n",
      "Global Test - Loss: 3.8523, Acc: 3.44%\n",
      "Round 49/100, Clients: 10\n",
      "Global Test - Loss: 3.8523, Acc: 3.46%\n",
      "Round 50/100, Clients: 10\n",
      "Global Test - Loss: 3.8523, Acc: 3.47%\n",
      "Round 51/100, Clients: 10\n",
      "Global Test - Loss: 3.8523, Acc: 3.49%\n",
      "Round 52/100, Clients: 10\n",
      "Global Test - Loss: 3.8522, Acc: 3.50%\n",
      "Round 53/100, Clients: 10\n",
      "Global Test - Loss: 3.8522, Acc: 3.51%\n",
      "Round 54/100, Clients: 10\n",
      "Global Test - Loss: 3.8522, Acc: 3.52%\n",
      "Round 55/100, Clients: 10\n",
      "Global Test - Loss: 3.8522, Acc: 3.54%\n",
      "Round 56/100, Clients: 10\n",
      "Global Test - Loss: 3.8522, Acc: 3.55%\n",
      "Round 57/100, Clients: 10\n",
      "Global Test - Loss: 3.8521, Acc: 3.57%\n",
      "Round 58/100, Clients: 10\n",
      "Global Test - Loss: 3.8521, Acc: 3.59%\n",
      "Round 59/100, Clients: 10\n",
      "Global Test - Loss: 3.8521, Acc: 3.61%\n",
      "Round 60/100, Clients: 10\n",
      "Global Test - Loss: 3.8521, Acc: 3.63%\n",
      "Round 61/100, Clients: 10\n",
      "Global Test - Loss: 3.8520, Acc: 3.65%\n",
      "Round 62/100, Clients: 10\n",
      "Global Test - Loss: 3.8520, Acc: 3.66%\n",
      "Round 63/100, Clients: 10\n",
      "Global Test - Loss: 3.8520, Acc: 3.67%\n",
      "Round 64/100, Clients: 10\n",
      "Global Test - Loss: 3.8520, Acc: 3.68%\n",
      "Round 65/100, Clients: 10\n",
      "Global Test - Loss: 3.8520, Acc: 3.68%\n",
      "Round 66/100, Clients: 10\n",
      "Global Test - Loss: 3.8519, Acc: 3.70%\n",
      "Round 67/100, Clients: 10\n",
      "Global Test - Loss: 3.8519, Acc: 3.72%\n",
      "Round 68/100, Clients: 10\n",
      "Global Test - Loss: 3.8519, Acc: 3.73%\n",
      "Round 69/100, Clients: 10\n",
      "Global Test - Loss: 3.8519, Acc: 3.74%\n",
      "Round 70/100, Clients: 10\n",
      "Global Test - Loss: 3.8519, Acc: 3.76%\n",
      "Round 71/100, Clients: 10\n",
      "Global Test - Loss: 3.8518, Acc: 3.76%\n",
      "Round 72/100, Clients: 10\n",
      "Global Test - Loss: 3.8518, Acc: 3.78%\n",
      "Round 73/100, Clients: 10\n",
      "Global Test - Loss: 3.8518, Acc: 3.80%\n",
      "Round 74/100, Clients: 10\n",
      "Global Test - Loss: 3.8518, Acc: 3.82%\n",
      "Round 75/100, Clients: 10\n",
      "Global Test - Loss: 3.8518, Acc: 3.83%\n",
      "Round 76/100, Clients: 10\n",
      "Global Test - Loss: 3.8517, Acc: 3.85%\n",
      "Round 77/100, Clients: 10\n",
      "Global Test - Loss: 3.8517, Acc: 3.86%\n",
      "Round 78/100, Clients: 10\n",
      "Global Test - Loss: 3.8517, Acc: 3.87%\n",
      "Round 79/100, Clients: 10\n",
      "Global Test - Loss: 3.8517, Acc: 3.89%\n",
      "Round 80/100, Clients: 10\n",
      "Global Test - Loss: 3.8517, Acc: 3.89%\n",
      "Round 81/100, Clients: 10\n",
      "Global Test - Loss: 3.8517, Acc: 3.90%\n",
      "Round 82/100, Clients: 10\n",
      "Global Test - Loss: 3.8516, Acc: 3.92%\n",
      "Round 83/100, Clients: 10\n",
      "Global Test - Loss: 3.8516, Acc: 3.93%\n",
      "Round 84/100, Clients: 10\n",
      "Global Test - Loss: 3.8516, Acc: 3.94%\n",
      "Round 85/100, Clients: 10\n",
      "Global Test - Loss: 3.8516, Acc: 3.96%\n",
      "Round 86/100, Clients: 10\n",
      "Global Test - Loss: 3.8516, Acc: 3.98%\n",
      "Round 87/100, Clients: 10\n",
      "Global Test - Loss: 3.8515, Acc: 3.99%\n",
      "Round 88/100, Clients: 10\n",
      "Global Test - Loss: 3.8515, Acc: 4.02%\n",
      "Round 89/100, Clients: 10\n",
      "Global Test - Loss: 3.8515, Acc: 4.03%\n",
      "Round 90/100, Clients: 10\n",
      "Global Test - Loss: 3.8515, Acc: 4.04%\n",
      "Round 91/100, Clients: 10\n",
      "Global Test - Loss: 3.8515, Acc: 4.05%\n",
      "Round 92/100, Clients: 10\n",
      "Global Test - Loss: 3.8515, Acc: 4.07%\n",
      "Round 93/100, Clients: 10\n",
      "Global Test - Loss: 3.8514, Acc: 4.09%\n",
      "Round 94/100, Clients: 10\n",
      "Global Test - Loss: 3.8514, Acc: 4.10%\n",
      "Round 95/100, Clients: 10\n",
      "Global Test - Loss: 3.8514, Acc: 4.10%\n",
      "Round 96/100, Clients: 10\n",
      "Global Test - Loss: 3.8514, Acc: 4.10%\n",
      "Round 97/100, Clients: 10\n",
      "Global Test - Loss: 3.8514, Acc: 4.12%\n",
      "Round 98/100, Clients: 10\n",
      "Global Test - Loss: 3.8514, Acc: 4.12%\n",
      "Round 99/100, Clients: 10\n",
      "Global Test - Loss: 3.8513, Acc: 4.13%\n",
      "Round 100/100, Clients: 10\n",
      "Global Test - Loss: 3.8513, Acc: 4.14%\n",
      "[6] Done. Total time: 1909.17s\n"
     ]
    }
   ],
   "source": [
    "# FedICT\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Model Definition\n",
    "# -----------------------------\n",
    "class EMNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*5*5, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 47)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.conv(x))\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Partitioning (Non-IID)\n",
    "# -----------------------------\n",
    "def partition_data(dataset, num_clients=100):\n",
    "    labels = dataset.targets.numpy() if torch.is_tensor(dataset.targets) else np.array(dataset.targets)\n",
    "    idx_by_class = [np.where(labels == i)[0] for i in range(47)]\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "    for c in range(47):\n",
    "        np.random.shuffle(idx_by_class[c])\n",
    "        parts = np.array_split(idx_by_class[c], num_clients)\n",
    "        for i in range(num_clients):\n",
    "            client_indices[i].extend(parts[i])\n",
    "    return [Subset(dataset, inds) for inds in client_indices]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Client Class (FedICT)\n",
    "# -----------------------------\n",
    "class Client:\n",
    "    def __init__(self, model, data, lr, local_epochs, device):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.data = data\n",
    "        self.lr = lr\n",
    "        self.local_epochs = local_epochs\n",
    "        self.device = device\n",
    "\n",
    "    def local_train(self):\n",
    "        self.model.train()\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=self.lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loader = DataLoader(self.data, batch_size=32, shuffle=True)\n",
    "\n",
    "        for epoch in range(self.local_epochs):\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        return copy.deepcopy(self.model.state_dict())\n",
    "\n",
    "    def get_logits(self):\n",
    "        self.model.eval()\n",
    "        loader = DataLoader(self.data, batch_size=64, shuffle=False)\n",
    "        all_logits, all_targets = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x = x.to(self.device)\n",
    "                logits = self.model(x)\n",
    "                all_logits.append(logits.cpu())\n",
    "                all_targets.append(y)\n",
    "\n",
    "        all_logits = torch.cat(all_logits, dim=0)\n",
    "        all_targets = torch.cat(all_targets, dim=0)\n",
    "        return all_logits, all_targets\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        loader = DataLoader(self.data, batch_size=64, shuffle=False)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "                total_loss += loss.item() * x.size(0)\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += x.size(0)\n",
    "        return total_loss / total, correct / total\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Server Class (FedICT)\n",
    "# -----------------------------\n",
    "class Server:\n",
    "    def __init__(self, model, num_clients):\n",
    "        self.global_model = model\n",
    "        self.clients = []\n",
    "        self.num_clients = num_clients\n",
    "\n",
    "    def add_clients(self, client_list):\n",
    "        self.clients = client_list\n",
    "\n",
    "    def federated_train(self, rounds):\n",
    "        for r in range(rounds):\n",
    "            selected = random.sample(self.clients, k=10)\n",
    "            client_states = []\n",
    "            all_logits, all_targets, all_images = [], [], []\n",
    "\n",
    "            print(f\"Round {r+1}/{rounds}, Clients: {len(selected)}\")\n",
    "\n",
    "            # Local training and get logits\n",
    "            for client in selected:\n",
    "                state_dict = client.local_train()\n",
    "                client_states.append(state_dict)\n",
    "\n",
    "                client.model.load_state_dict(state_dict)\n",
    "                logits, targets = client.get_logits()\n",
    "                all_logits.append(logits)\n",
    "                all_targets.append(targets)\n",
    "\n",
    "                # 收集原始图片\n",
    "                for x, _ in DataLoader(client.data, batch_size=64, shuffle=False):\n",
    "                    all_images.append(x)\n",
    "\n",
    "            # Aggregate pseudo labels (soft distillation)\n",
    "            concat_logits = torch.cat(all_logits, dim=0)\n",
    "            pseudo_labels = concat_logits.softmax(dim=1)\n",
    "\n",
    "            images_tensor = torch.cat(all_images, dim=0)\n",
    "\n",
    "            # Create loader for distillation\n",
    "            loader = DataLoader(torch.utils.data.TensorDataset(images_tensor, pseudo_labels), batch_size=64, shuffle=True)\n",
    "\n",
    "            # Train global model using images + soft labels\n",
    "            self.global_model.train()\n",
    "            optimizer = optim.SGD(self.global_model.parameters(), lr=0.001)\n",
    "\n",
    "            for x, soft_y in loader:\n",
    "                x = x.to(self.global_model.fc[-1].weight.device)\n",
    "                soft_y = soft_y.to(self.global_model.fc[-1].weight.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = self.global_model(x)\n",
    "                loss = nn.KLDivLoss(reduction=\"batchmean\")(output.log_softmax(dim=1), soft_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Evaluate\n",
    "            global_losses, global_accs = [], []\n",
    "            for client in self.clients:\n",
    "                client.model.load_state_dict(self.global_model.state_dict())\n",
    "                loss, acc = client.evaluate()\n",
    "                global_losses.append(loss)\n",
    "                global_accs.append(acc)\n",
    "\n",
    "            avg_loss = np.mean(global_losses)\n",
    "            avg_acc = np.mean(global_accs) * 100\n",
    "\n",
    "            print(f\"Global Test - Loss: {avg_loss:.4f}, Acc: {avg_acc:.2f}%\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Main Execution\n",
    "# -----------------------------\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    print(\"[0] Loading EMNIST...\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    emnist_train = datasets.EMNIST(root=\"./data\", split=\"balanced\", train=True, download=True, transform=transform)\n",
    "    print(f\"[1] Dataset loaded. Total samples: {len(emnist_train)}\")\n",
    "\n",
    "    print(\"[2] Partitioning data...\")\n",
    "    partition_start = time.time()\n",
    "    client_data = partition_data(emnist_train, num_clients=100)\n",
    "    print(f\"[3] Partition done in {time.time() - partition_start:.2f}s\")\n",
    "\n",
    "    print(\"[4] Initializing models...\")\n",
    "    global_model = EMNIST_CNN().to(device)\n",
    "    server = Server(global_model, num_clients=100)\n",
    "    clients = [Client(global_model, data, lr=0.001, local_epochs=2, device=device) for data in client_data]\n",
    "    server.add_clients(clients)\n",
    "\n",
    "    print(\"[5] Starting federated training...\")\n",
    "    server.federated_train(rounds=100)\n",
    "\n",
    "    print(f\"[6] Done. Total time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[0] Loading EMNIST...\n",
      "[1] Dataset loaded. Total samples: 112800\n",
      "[2] Partitioning data...\n",
      "[3] Partition done in 0.01s\n",
      "[4] Initializing models...\n",
      "[5] Starting federated training...\n",
      "Round 1/100, Clients: 10\n",
      "Global Test - Loss: 3.8527, Acc: 2.01%\n",
      "Round 2/100, Clients: 10\n",
      "Global Test - Loss: 3.8515, Acc: 2.03%\n",
      "Round 3/100, Clients: 10\n",
      "Global Test - Loss: 3.8503, Acc: 2.06%\n",
      "Round 4/100, Clients: 10\n",
      "Global Test - Loss: 3.8492, Acc: 2.09%\n",
      "Round 5/100, Clients: 10\n",
      "Global Test - Loss: 3.8482, Acc: 2.14%\n",
      "Round 6/100, Clients: 10\n",
      "Global Test - Loss: 3.8472, Acc: 2.20%\n",
      "Round 7/100, Clients: 10\n",
      "Global Test - Loss: 3.8463, Acc: 2.30%\n",
      "Round 8/100, Clients: 10\n",
      "Global Test - Loss: 3.8454, Acc: 2.46%\n",
      "Round 9/100, Clients: 10\n",
      "Global Test - Loss: 3.8445, Acc: 2.64%\n",
      "Round 10/100, Clients: 10\n",
      "Global Test - Loss: 3.8436, Acc: 2.88%\n",
      "Round 11/100, Clients: 10\n",
      "Global Test - Loss: 3.8426, Acc: 3.11%\n",
      "Round 12/100, Clients: 10\n",
      "Global Test - Loss: 3.8417, Acc: 3.36%\n",
      "Round 13/100, Clients: 10\n",
      "Global Test - Loss: 3.8408, Acc: 3.63%\n",
      "Round 14/100, Clients: 10\n",
      "Global Test - Loss: 3.8398, Acc: 3.89%\n",
      "Round 15/100, Clients: 10\n",
      "Global Test - Loss: 3.8389, Acc: 4.16%\n",
      "Round 16/100, Clients: 10\n",
      "Global Test - Loss: 3.8379, Acc: 4.45%\n",
      "Round 17/100, Clients: 10\n",
      "Global Test - Loss: 3.8369, Acc: 4.73%\n",
      "Round 18/100, Clients: 10\n",
      "Global Test - Loss: 3.8359, Acc: 5.01%\n",
      "Round 19/100, Clients: 10\n",
      "Global Test - Loss: 3.8348, Acc: 5.22%\n",
      "Round 20/100, Clients: 10\n",
      "Global Test - Loss: 3.8337, Acc: 5.49%\n",
      "Round 21/100, Clients: 10\n",
      "Global Test - Loss: 3.8326, Acc: 5.71%\n",
      "Round 22/100, Clients: 10\n",
      "Global Test - Loss: 3.8314, Acc: 5.93%\n",
      "Round 23/100, Clients: 10\n",
      "Global Test - Loss: 3.8302, Acc: 6.12%\n",
      "Round 24/100, Clients: 10\n",
      "Global Test - Loss: 3.8289, Acc: 6.37%\n",
      "Round 25/100, Clients: 10\n",
      "Global Test - Loss: 3.8276, Acc: 6.66%\n",
      "Round 26/100, Clients: 10\n",
      "Global Test - Loss: 3.8262, Acc: 6.84%\n",
      "Round 27/100, Clients: 10\n",
      "Global Test - Loss: 3.8248, Acc: 7.08%\n",
      "Round 28/100, Clients: 10\n",
      "Global Test - Loss: 3.8234, Acc: 7.34%\n",
      "Round 29/100, Clients: 10\n",
      "Global Test - Loss: 3.8219, Acc: 7.59%\n",
      "Round 30/100, Clients: 10\n",
      "Global Test - Loss: 3.8203, Acc: 7.84%\n",
      "Round 31/100, Clients: 10\n",
      "Global Test - Loss: 3.8186, Acc: 8.11%\n",
      "Round 32/100, Clients: 10\n",
      "Global Test - Loss: 3.8169, Acc: 8.35%\n",
      "Round 33/100, Clients: 10\n",
      "Global Test - Loss: 3.8151, Acc: 8.60%\n",
      "Round 34/100, Clients: 10\n",
      "Global Test - Loss: 3.8132, Acc: 8.89%\n",
      "Round 35/100, Clients: 10\n",
      "Global Test - Loss: 3.8113, Acc: 9.24%\n",
      "Round 36/100, Clients: 10\n",
      "Global Test - Loss: 3.8092, Acc: 9.49%\n",
      "Round 37/100, Clients: 10\n",
      "Global Test - Loss: 3.8071, Acc: 9.74%\n",
      "Round 38/100, Clients: 10\n",
      "Global Test - Loss: 3.8048, Acc: 10.04%\n",
      "Round 39/100, Clients: 10\n",
      "Global Test - Loss: 3.8024, Acc: 10.42%\n",
      "Round 40/100, Clients: 10\n",
      "Global Test - Loss: 3.8000, Acc: 10.80%\n",
      "Round 41/100, Clients: 10\n",
      "Global Test - Loss: 3.7973, Acc: 11.18%\n",
      "Round 42/100, Clients: 10\n",
      "Global Test - Loss: 3.7945, Acc: 11.62%\n",
      "Round 43/100, Clients: 10\n",
      "Global Test - Loss: 3.7916, Acc: 12.05%\n",
      "Round 44/100, Clients: 10\n",
      "Global Test - Loss: 3.7885, Acc: 12.48%\n",
      "Round 45/100, Clients: 10\n",
      "Global Test - Loss: 3.7852, Acc: 12.87%\n",
      "Round 46/100, Clients: 10\n",
      "Global Test - Loss: 3.7818, Acc: 13.27%\n",
      "Round 47/100, Clients: 10\n",
      "Global Test - Loss: 3.7781, Acc: 13.65%\n",
      "Round 48/100, Clients: 10\n",
      "Global Test - Loss: 3.7743, Acc: 13.98%\n",
      "Round 49/100, Clients: 10\n",
      "Global Test - Loss: 3.7702, Acc: 14.29%\n",
      "Round 50/100, Clients: 10\n",
      "Global Test - Loss: 3.7659, Acc: 14.59%\n",
      "Round 51/100, Clients: 10\n",
      "Global Test - Loss: 3.7613, Acc: 14.98%\n",
      "Round 52/100, Clients: 10\n",
      "Global Test - Loss: 3.7565, Acc: 15.27%\n",
      "Round 53/100, Clients: 10\n",
      "Global Test - Loss: 3.7513, Acc: 15.55%\n",
      "Round 54/100, Clients: 10\n",
      "Global Test - Loss: 3.7459, Acc: 15.91%\n",
      "Round 55/100, Clients: 10\n",
      "Global Test - Loss: 3.7401, Acc: 16.19%\n",
      "Round 56/100, Clients: 10\n",
      "Global Test - Loss: 3.7340, Acc: 16.54%\n",
      "Round 57/100, Clients: 10\n",
      "Global Test - Loss: 3.7276, Acc: 16.92%\n",
      "Round 58/100, Clients: 10\n",
      "Global Test - Loss: 3.7206, Acc: 17.32%\n",
      "Round 59/100, Clients: 10\n",
      "Global Test - Loss: 3.7132, Acc: 17.67%\n",
      "Round 60/100, Clients: 10\n",
      "Global Test - Loss: 3.7053, Acc: 18.12%\n",
      "Round 61/100, Clients: 10\n",
      "Global Test - Loss: 3.6969, Acc: 18.54%\n",
      "Round 62/100, Clients: 10\n",
      "Global Test - Loss: 3.6879, Acc: 18.96%\n",
      "Round 63/100, Clients: 10\n",
      "Global Test - Loss: 3.6783, Acc: 19.48%\n",
      "Round 64/100, Clients: 10\n",
      "Global Test - Loss: 3.6678, Acc: 19.93%\n",
      "Round 65/100, Clients: 10\n",
      "Global Test - Loss: 3.6567, Acc: 20.45%\n",
      "Round 66/100, Clients: 10\n",
      "Global Test - Loss: 3.6448, Acc: 20.95%\n",
      "Round 67/100, Clients: 10\n",
      "Global Test - Loss: 3.6321, Acc: 21.61%\n",
      "Round 68/100, Clients: 10\n",
      "Global Test - Loss: 3.6184, Acc: 22.11%\n",
      "Round 69/100, Clients: 10\n",
      "Global Test - Loss: 3.6036, Acc: 22.77%\n",
      "Round 70/100, Clients: 10\n",
      "Global Test - Loss: 3.5878, Acc: 23.43%\n",
      "Round 71/100, Clients: 10\n",
      "Global Test - Loss: 3.5705, Acc: 24.02%\n",
      "Round 72/100, Clients: 10\n",
      "Global Test - Loss: 3.5520, Acc: 24.65%\n",
      "Round 73/100, Clients: 10\n",
      "Global Test - Loss: 3.5320, Acc: 25.23%\n",
      "Round 74/100, Clients: 10\n",
      "Global Test - Loss: 3.5102, Acc: 25.82%\n",
      "Round 75/100, Clients: 10\n",
      "Global Test - Loss: 3.4865, Acc: 26.50%\n",
      "Round 76/100, Clients: 10\n",
      "Global Test - Loss: 3.4612, Acc: 27.21%\n",
      "Round 77/100, Clients: 10\n",
      "Global Test - Loss: 3.4339, Acc: 27.86%\n",
      "Round 78/100, Clients: 10\n",
      "Global Test - Loss: 3.4043, Acc: 28.53%\n",
      "Round 79/100, Clients: 10\n",
      "Global Test - Loss: 3.3724, Acc: 29.28%\n",
      "Round 80/100, Clients: 10\n",
      "Global Test - Loss: 3.3378, Acc: 30.00%\n",
      "Round 81/100, Clients: 10\n",
      "Global Test - Loss: 3.3008, Acc: 30.88%\n",
      "Round 82/100, Clients: 10\n",
      "Global Test - Loss: 3.2603, Acc: 31.61%\n",
      "Round 83/100, Clients: 10\n",
      "Global Test - Loss: 3.2167, Acc: 32.59%\n",
      "Round 84/100, Clients: 10\n",
      "Global Test - Loss: 3.1705, Acc: 33.39%\n",
      "Round 85/100, Clients: 10\n",
      "Global Test - Loss: 3.1209, Acc: 34.16%\n",
      "Round 86/100, Clients: 10\n",
      "Global Test - Loss: 3.0687, Acc: 34.98%\n",
      "Round 87/100, Clients: 10\n",
      "Global Test - Loss: 3.0139, Acc: 35.96%\n",
      "Round 88/100, Clients: 10\n",
      "Global Test - Loss: 2.9566, Acc: 36.67%\n",
      "Round 89/100, Clients: 10\n",
      "Global Test - Loss: 2.8964, Acc: 37.41%\n",
      "Round 90/100, Clients: 10\n",
      "Global Test - Loss: 2.8348, Acc: 38.26%\n",
      "Round 91/100, Clients: 10\n",
      "Global Test - Loss: 2.7719, Acc: 39.16%\n",
      "Round 92/100, Clients: 10\n",
      "Global Test - Loss: 2.7077, Acc: 39.79%\n",
      "Round 93/100, Clients: 10\n",
      "Global Test - Loss: 2.6433, Acc: 40.88%\n",
      "Round 94/100, Clients: 10\n",
      "Global Test - Loss: 2.5787, Acc: 41.61%\n",
      "Round 95/100, Clients: 10\n",
      "Global Test - Loss: 2.5150, Acc: 42.59%\n",
      "Round 96/100, Clients: 10\n",
      "Global Test - Loss: 2.4518, Acc: 43.54%\n",
      "Round 97/100, Clients: 10\n",
      "Global Test - Loss: 2.3912, Acc: 44.23%\n",
      "Round 98/100, Clients: 10\n",
      "Global Test - Loss: 2.3320, Acc: 45.08%\n",
      "Round 99/100, Clients: 10\n",
      "Global Test - Loss: 2.2750, Acc: 45.77%\n",
      "Round 100/100, Clients: 10\n",
      "Global Test - Loss: 2.2203, Acc: 46.42%\n",
      "[6] Done. Total time: 1697.59s\n"
     ]
    }
   ],
   "source": [
    "# FedDyn-DF\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Model Definition\n",
    "# -----------------------------\n",
    "class EMNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*5*5, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 47)  # EMNIST Balanced has 47 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.conv(x))\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Partitioning (Non-IID)\n",
    "# -----------------------------\n",
    "def partition_data(dataset, num_clients=100):\n",
    "    labels = dataset.targets.numpy() if torch.is_tensor(dataset.targets) else np.array(dataset.targets)\n",
    "    idx_by_class = [np.where(labels == i)[0] for i in range(47)]\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "    for c in range(47):\n",
    "        np.random.shuffle(idx_by_class[c])\n",
    "        parts = np.array_split(idx_by_class[c], num_clients)\n",
    "        for i in range(num_clients):\n",
    "            client_indices[i].extend(parts[i])\n",
    "    return [Subset(dataset, inds) for inds in client_indices]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Client Class (FedDyn-DF)\n",
    "# -----------------------------\n",
    "class Client:\n",
    "    def __init__(self, model, data, lr, local_epochs, device):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.data = data\n",
    "        self.lr = lr\n",
    "        self.local_epochs = local_epochs\n",
    "        self.device = device\n",
    "        # Dynamic correction vector (tracker)\n",
    "        self.dyn_vector = {k: torch.zeros_like(v) for k, v in self.model.state_dict().items()}\n",
    "\n",
    "    def train(self, global_model):\n",
    "        self.model.load_state_dict(global_model.state_dict())\n",
    "        self.model.train()\n",
    "\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=self.lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loader = DataLoader(self.data, batch_size=32, shuffle=True)\n",
    "\n",
    "        for epoch in range(self.local_epochs):\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "\n",
    "                # FedDyn correction term\n",
    "                correction = 0.0\n",
    "                local_state = self.model.state_dict()\n",
    "                for name in local_state:\n",
    "                    p = local_state[name]\n",
    "                    dyn = self.dyn_vector[name]\n",
    "                    correction += (p * dyn).sum()\n",
    "\n",
    "                loss += correction\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Update dynamic correction vector\n",
    "        with torch.no_grad():\n",
    "            for k in self.model.state_dict().keys():\n",
    "                delta = global_model.state_dict()[k] - self.model.state_dict()[k]\n",
    "                self.dyn_vector[k] -= delta / (self.lr * self.local_epochs)\n",
    "\n",
    "        return copy.deepcopy(self.model.state_dict())\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        loader = DataLoader(self.data, batch_size=64, shuffle=False)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "                total_loss += loss.item() * x.size(0)\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += x.size(0)\n",
    "        return total_loss / total, correct / total\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Server Class (FedDyn-DF)\n",
    "# -----------------------------\n",
    "class Server:\n",
    "    def __init__(self, model, num_clients):\n",
    "        self.global_model = model\n",
    "        self.clients = []\n",
    "        self.num_clients = num_clients\n",
    "\n",
    "    def add_clients(self, client_list):\n",
    "        self.clients = client_list\n",
    "\n",
    "    def aggregate(self, client_states):\n",
    "        avg_state = copy.deepcopy(self.global_model.state_dict())\n",
    "        for k in avg_state:\n",
    "            avg_state[k] = sum(client[k] for client in client_states) / len(client_states)\n",
    "        self.global_model.load_state_dict(avg_state)\n",
    "\n",
    "    def federated_train(self, rounds):\n",
    "        for r in range(rounds):\n",
    "            selected = random.sample(self.clients, k=10)\n",
    "            client_states = []\n",
    "\n",
    "            print(f\"Round {r+1}/{rounds}, Clients: {len(selected)}\")\n",
    "\n",
    "            for client in selected:\n",
    "                state_dict = client.train(self.global_model)\n",
    "                client_states.append(state_dict)\n",
    "\n",
    "            self.aggregate(client_states)\n",
    "\n",
    "            # Evaluate\n",
    "            global_losses, global_accs = [], []\n",
    "            for client in self.clients:\n",
    "                client.model.load_state_dict(self.global_model.state_dict())\n",
    "                loss, acc = client.evaluate()\n",
    "                global_losses.append(loss)\n",
    "                global_accs.append(acc)\n",
    "\n",
    "            avg_loss = np.mean(global_losses)\n",
    "            avg_acc = np.mean(global_accs) * 100\n",
    "\n",
    "            print(f\"Global Test - Loss: {avg_loss:.4f}, Acc: {avg_acc:.2f}%\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Main Execution\n",
    "# -----------------------------\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    print(\"[0] Loading EMNIST...\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    emnist_train = datasets.EMNIST(root=\"./data\", split=\"balanced\", train=True, download=True, transform=transform)\n",
    "    print(f\"[1] Dataset loaded. Total samples: {len(emnist_train)}\")\n",
    "\n",
    "    print(\"[2] Partitioning data...\")\n",
    "    partition_start = time.time()\n",
    "    client_data = partition_data(emnist_train, num_clients=100)\n",
    "    print(f\"[3] Partition done in {time.time() - partition_start:.2f}s\")\n",
    "\n",
    "    print(\"[4] Initializing models...\")\n",
    "    global_model = EMNIST_CNN().to(device)\n",
    "    server = Server(global_model, num_clients=100)\n",
    "    clients = [Client(global_model, data, lr=0.001, local_epochs=2, device=device) for data in client_data]\n",
    "    server.add_clients(clients)\n",
    "\n",
    "    print(\"[5] Starting federated training...\")\n",
    "    server.federated_train(rounds=100)\n",
    "\n",
    "    print(f\"[6] Done. Total time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[0] Loading EMNIST...\n",
      "[1] Dataset loaded. Total samples: 112800\n",
      "[2] Partitioning data...\n",
      "[3] Partition done in 0.02s\n",
      "[4] Initializing models...\n",
      "[5] Starting federated training...\n",
      "Round 1/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 3.8506, Acc: 2.76%\n",
      "Round 2/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 3.8491, Acc: 2.96%\n",
      "Round 3/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 3.8477, Acc: 3.18%\n",
      "Round 4/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 3.8464, Acc: 3.47%\n",
      "Round 5/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 3.8452, Acc: 3.77%\n",
      "Round 6/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 3.8441, Acc: 4.00%\n",
      "Round 7/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 3.8430, Acc: 4.25%\n",
      "Round 8/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 3.8420, Acc: 4.43%\n",
      "Round 9/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 3.8409, Acc: 4.59%\n",
      "Round 10/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 3.8399, Acc: 4.67%\n",
      "Round 11/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 3.8389, Acc: 4.77%\n",
      "Round 12/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 3.8379, Acc: 4.88%\n",
      "Round 13/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 3.8369, Acc: 4.99%\n",
      "Round 14/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 3.8359, Acc: 5.07%\n",
      "Round 15/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 3.8349, Acc: 5.14%\n",
      "Round 16/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 3.8339, Acc: 5.12%\n",
      "Round 17/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 3.8329, Acc: 5.13%\n",
      "Round 18/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 3.8318, Acc: 5.12%\n",
      "Round 19/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 3.8307, Acc: 5.17%\n",
      "Round 20/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 3.8296, Acc: 5.17%\n",
      "Round 21/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 3.8284, Acc: 5.27%\n",
      "Round 22/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 3.8273, Acc: 5.34%\n",
      "Round 23/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 3.8261, Acc: 5.36%\n",
      "Round 24/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 3.8248, Acc: 5.47%\n",
      "Round 25/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 3.8235, Acc: 5.52%\n",
      "Round 26/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 3.8222, Acc: 5.67%\n",
      "Round 27/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 3.8208, Acc: 5.80%\n",
      "Round 28/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 3.8194, Acc: 5.86%\n",
      "Round 29/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 3.8180, Acc: 5.92%\n",
      "Round 30/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 3.8165, Acc: 6.07%\n",
      "Round 31/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 3.8149, Acc: 6.19%\n",
      "Round 32/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 3.8133, Acc: 6.32%\n",
      "Round 33/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 3.8116, Acc: 6.49%\n",
      "Round 34/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 3.8099, Acc: 6.61%\n",
      "Round 35/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 3.8081, Acc: 6.77%\n",
      "Round 36/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 3.8063, Acc: 6.87%\n",
      "Round 37/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 3.8044, Acc: 7.08%\n",
      "Round 38/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 3.8024, Acc: 7.28%\n",
      "Round 39/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 3.8004, Acc: 7.42%\n",
      "Round 40/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 3.7983, Acc: 7.61%\n",
      "Round 41/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 3.7961, Acc: 7.72%\n",
      "Round 42/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 3.7938, Acc: 7.88%\n",
      "Round 43/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 3.7915, Acc: 8.03%\n",
      "Round 44/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 3.7891, Acc: 8.18%\n",
      "Round 45/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 3.7866, Acc: 8.37%\n",
      "Round 46/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 3.7840, Acc: 8.49%\n",
      "Round 47/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 3.7813, Acc: 8.68%\n",
      "Round 48/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 3.7785, Acc: 8.95%\n",
      "Round 49/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 3.7756, Acc: 9.17%\n",
      "Round 50/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 3.7727, Acc: 9.32%\n",
      "Round 51/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 3.7697, Acc: 9.59%\n",
      "Round 52/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 3.7665, Acc: 9.96%\n",
      "Round 53/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 3.7633, Acc: 10.19%\n",
      "Round 54/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 3.7599, Acc: 10.50%\n",
      "Round 55/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 3.7563, Acc: 10.86%\n",
      "Round 56/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 3.7526, Acc: 11.20%\n",
      "Round 57/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 3.7488, Acc: 11.66%\n",
      "Round 58/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 3.7449, Acc: 11.88%\n",
      "Round 59/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 3.7408, Acc: 12.43%\n",
      "Round 60/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 3.7367, Acc: 12.83%\n",
      "Round 61/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 3.7323, Acc: 13.35%\n",
      "Round 62/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 3.7278, Acc: 13.76%\n",
      "Round 63/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 3.7232, Acc: 14.27%\n",
      "Round 64/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 3.7184, Acc: 14.79%\n",
      "Round 65/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 3.7134, Acc: 15.36%\n",
      "Round 66/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 3.7084, Acc: 15.86%\n",
      "Round 67/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 3.7030, Acc: 16.30%\n",
      "Round 68/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 3.6975, Acc: 16.78%\n",
      "Round 69/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 3.6919, Acc: 17.36%\n",
      "Round 70/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 3.6860, Acc: 17.79%\n",
      "Round 71/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 3.6800, Acc: 18.24%\n",
      "Round 72/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 3.6737, Acc: 18.84%\n",
      "Round 73/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 3.6672, Acc: 19.29%\n",
      "Round 74/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 3.6606, Acc: 19.71%\n",
      "Round 75/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 3.6535, Acc: 20.22%\n",
      "Round 76/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 3.6464, Acc: 20.89%\n",
      "Round 77/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 3.6391, Acc: 21.43%\n",
      "Round 78/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 3.6317, Acc: 22.03%\n",
      "Round 79/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 3.6238, Acc: 22.62%\n",
      "Round 80/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 3.6157, Acc: 23.10%\n",
      "Round 81/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 3.6073, Acc: 23.70%\n",
      "Round 82/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 3.5986, Acc: 24.18%\n",
      "Round 83/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 3.5896, Acc: 24.81%\n",
      "Round 84/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 3.5804, Acc: 25.32%\n",
      "Round 85/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 3.5710, Acc: 25.85%\n",
      "Round 86/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 3.5612, Acc: 26.36%\n",
      "Round 87/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 3.5511, Acc: 26.86%\n",
      "Round 88/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 3.5408, Acc: 27.34%\n",
      "Round 89/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 3.5305, Acc: 27.77%\n",
      "Round 90/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 3.5196, Acc: 28.32%\n",
      "Round 91/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 3.5085, Acc: 28.84%\n",
      "Round 92/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 3.4970, Acc: 29.19%\n",
      "Round 93/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 3.4849, Acc: 29.61%\n",
      "Round 94/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 3.4727, Acc: 30.07%\n",
      "Round 95/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 3.4602, Acc: 30.50%\n",
      "Round 96/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 3.4468, Acc: 30.94%\n",
      "Round 97/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 3.4336, Acc: 31.43%\n",
      "Round 98/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 3.4200, Acc: 31.88%\n",
      "Round 99/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 3.4060, Acc: 32.31%\n",
      "Round 100/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 3.3922, Acc: 32.91%\n",
      "[6] Done. Total time: 1693.47s\n"
     ]
    }
   ],
   "source": [
    "# FedSC-MTL\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Model Definition\n",
    "# -----------------------------\n",
    "class EMNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc1 = nn.Linear(64*5*5, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 47)\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        feat = self.relu(self.fc1(x))\n",
    "        out = self.fc2(feat)\n",
    "        if return_features:\n",
    "            return out, feat\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Partitioning (Non-IID)\n",
    "# -----------------------------\n",
    "def partition_data(dataset, num_clients=100):\n",
    "    labels = dataset.targets.numpy() if torch.is_tensor(dataset.targets) else np.array(dataset.targets)\n",
    "    idx_by_class = [np.where(labels == i)[0] for i in range(47)]\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "    for c in range(47):\n",
    "        np.random.shuffle(idx_by_class[c])\n",
    "        parts = np.array_split(idx_by_class[c], num_clients)\n",
    "        for i in range(num_clients):\n",
    "            client_indices[i].extend(parts[i])\n",
    "    return [Subset(dataset, inds) for inds in client_indices]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Client Class (FedSC-MTL)\n",
    "# -----------------------------\n",
    "class Client:\n",
    "    def __init__(self, model, data, lr, local_epochs, device):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.data = data\n",
    "        self.lr = lr\n",
    "        self.local_epochs = local_epochs\n",
    "        self.device = device\n",
    "        self.ci = {k: torch.zeros_like(v) for k, v in self.model.state_dict().items()}\n",
    "\n",
    "    def train(self, global_model, cg, mu):\n",
    "        self.model.load_state_dict(global_model.state_dict())\n",
    "        self.model.train()\n",
    "\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=self.lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loader = DataLoader(self.data, batch_size=32, shuffle=True)\n",
    "\n",
    "        for epoch in range(self.local_epochs):\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                output, feat = self.model(x, return_features=True)\n",
    "                loss_cls = criterion(output, y)\n",
    "\n",
    "                # 特征蒸馏损失（这里以零向量作为参考特征示例，你可根据实际替换）\n",
    "                fref = torch.zeros_like(feat).to(self.device)\n",
    "                distill_loss = nn.MSELoss()(feat, fref)\n",
    "\n",
    "                # 控制变量修正项\n",
    "                grad_correction = 0.0\n",
    "                model_state = self.model.state_dict()\n",
    "                global_state = global_model.state_dict()\n",
    "\n",
    "                for name in model_state:\n",
    "                    p = model_state[name]\n",
    "                    w_t = global_state[name]\n",
    "                    c_global = cg[name]\n",
    "                    ci_local = self.ci[name]\n",
    "                    grad_correction += ((p - w_t) * (-ci_local + c_global + mu * (p - w_t))).sum()\n",
    "\n",
    "                # 合并总损失\n",
    "                total_loss = loss_cls + distill_loss + 0.5 * grad_correction\n",
    "\n",
    "                total_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # 更新 local control ci\n",
    "        with torch.no_grad():\n",
    "            for k in self.model.state_dict().keys():\n",
    "                self.ci[k] = self.ci[k] - cg[k] + (global_model.state_dict()[k] - self.model.state_dict()[k]) / self.lr\n",
    "\n",
    "        return copy.deepcopy(self.model.state_dict()), self.ci\n",
    "\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        loader = DataLoader(self.data, batch_size=64, shuffle=False)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "                total_loss += loss.item() * x.size(0)\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += x.size(0)\n",
    "        return total_loss / total, correct / total\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Server Class (FedSC-MTL)\n",
    "# -----------------------------\n",
    "class Server:\n",
    "    def __init__(self, model, num_clients):\n",
    "        self.global_model = model\n",
    "        self.clients = []\n",
    "        self.num_clients = num_clients\n",
    "        self.cg = {k: torch.zeros_like(v) for k, v in self.global_model.state_dict().items()}\n",
    "\n",
    "    def add_clients(self, client_list):\n",
    "        self.clients = client_list\n",
    "\n",
    "    def aggregate(self, client_states):\n",
    "        avg_state = copy.deepcopy(self.global_model.state_dict())\n",
    "        for k in avg_state:\n",
    "            avg_state[k] = sum(client[k] for client in client_states) / len(client_states)\n",
    "        self.global_model.load_state_dict(avg_state)\n",
    "\n",
    "    def update_cg(self, ci_list):\n",
    "        for k in self.cg:\n",
    "            self.cg[k] = sum(ci[k] for ci in ci_list) / len(ci_list)\n",
    "\n",
    "    def federated_train(self, rounds, mu_scheduler):\n",
    "        for r in range(rounds):\n",
    "            selected = random.sample(self.clients, k=10)\n",
    "            mu = mu_scheduler(r)\n",
    "            client_states, ci_list = [], []\n",
    "\n",
    "            print(f\"Round {r+1}/{rounds}, μ={mu:.4f}, Clients: {len(selected)}\")\n",
    "\n",
    "            for client in selected:\n",
    "                state_dict, ci = client.train(self.global_model, self.cg, mu)\n",
    "                client_states.append(state_dict)\n",
    "                ci_list.append(ci)\n",
    "\n",
    "            self.aggregate(client_states)\n",
    "            self.update_cg(ci_list)\n",
    "\n",
    "            # Evaluate\n",
    "            global_losses, global_accs = [], []\n",
    "            for client in self.clients:\n",
    "                client.model.load_state_dict(self.global_model.state_dict())\n",
    "                loss, acc = client.evaluate()\n",
    "                global_losses.append(loss)\n",
    "                global_accs.append(acc)\n",
    "\n",
    "            avg_loss = np.mean(global_losses)\n",
    "            avg_acc = np.mean(global_accs) * 100\n",
    "\n",
    "            print(f\"Global Test - Loss: {avg_loss:.4f}, Acc: {avg_acc:.2f}%\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Main Execution\n",
    "# -----------------------------\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    print(\"[0] Loading EMNIST...\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    emnist_train = datasets.EMNIST(root=\"./data\", split=\"balanced\", train=True, download=True, transform=transform)\n",
    "    print(f\"[1] Dataset loaded. Total samples: {len(emnist_train)}\")\n",
    "\n",
    "    print(\"[2] Partitioning data...\")\n",
    "    partition_start = time.time()\n",
    "    client_data = partition_data(emnist_train, num_clients=100)\n",
    "    print(f\"[3] Partition done in {time.time() - partition_start:.2f}s\")\n",
    "\n",
    "    print(\"[4] Initializing models...\")\n",
    "    global_model = EMNIST_CNN().to(device)\n",
    "    server = Server(global_model, num_clients=100)\n",
    "    clients = [Client(global_model, data, lr=0.001, local_epochs=2, device=device) for data in client_data]\n",
    "    server.add_clients(clients)\n",
    "\n",
    "    def mu_schedule(round_idx):\n",
    "        return 0.1 * (0.95 ** (round_idx // 10))  # 每10轮衰减\n",
    "\n",
    "    print(\"[5] Starting federated training...\")\n",
    "    server.federated_train(rounds=100, mu_scheduler=mu_schedule)\n",
    "\n",
    "    print(f\"[6] Done. Total time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fedavg_acc = [\n",
    "    2.13, 2.21, 2.26, 2.30, 2.35, 2.43, 2.52, 2.62, 2.88, 3.11,\n",
    "    3.36, 3.67, 4.04, 4.47, 4.88, 5.34, 5.78, 6.17, 6.59, 7.07,\n",
    "    7.44, 7.81, 8.25, 8.63, 9.04, 9.45, 9.77, 10.17, 10.59, 10.94,\n",
    "    11.23, 11.68, 12.09, 12.47, 12.77, 13.18, 13.66, 14.00, 14.43, 14.86,\n",
    "    15.35, 15.78, 16.29, 16.77, 17.53, 18.21, 19.00, 19.94, 20.76, 21.64,\n",
    "    22.42, 23.30, 24.11, 24.69, 25.30, 25.84, 26.49, 27.12, 27.78, 28.51,\n",
    "    29.29, 30.21, 30.98, 31.85, 32.78, 33.71, 34.54, 35.38, 36.18, 37.08,\n",
    "    37.94, 38.78, 39.56, 40.31, 41.16, 41.97, 42.90, 43.65, 44.28, 44.92,\n",
    "    45.69, 46.31, 46.98, 47.61, 48.25, 48.82, 49.12, 49.72, 50.22, 50.59,\n",
    "    51.23, 51.54, 52.03, 52.35, 52.78, 53.20, 53.67, 53.96, 54.37, 54.72\n",
    "]\n",
    "\n",
    "# FedProx 数据\n",
    "fedprox_acc = [\n",
    "    31.85, 54.45, 62.32, 67.97, 70.49, 70.99, 73.22, 72.15, 76.26, 73.61,\n",
    "    77.51, 76.57, 75.95, 78.97, 76.91, 73.10, 76.06, 73.35, 74.65, 76.14,\n",
    "    76.11, 79.10, 78.80, 76.41, 78.75, 79.40, 80.33, 76.76, 74.21, 80.59,\n",
    "    76.69, 77.77, 78.54, 80.96, 79.63, 80.49, 79.15, 79.07, 80.40, 78.11,\n",
    "    79.10, 78.35, 77.39, 80.07, 78.94, 75.18, 80.98, 79.13, 76.94, 77.81,\n",
    "    80.60, 79.46, 80.78, 79.37, 79.69, 77.15, 77.21, 81.55, 80.01, 80.83,\n",
    "    77.62, 78.06, 81.02, 78.23, 80.09, 79.15, 79.79, 79.63, 79.06, 81.99,\n",
    "    78.78, 79.28, 82.05, 78.16, 81.14, 78.53, 78.89, 78.74, 79.25, 80.64,\n",
    "    81.99, 79.97, 79.89, 79.83, 80.00, 83.43, 79.12, 76.42, 82.71, 82.86,\n",
    "    82.02, 80.80, 83.46, 78.69, 81.42, 78.26, 82.27, 80.14, 81.72, 80.51\n",
    "]\n",
    "\n",
    "# SCAFFOLD 数据\n",
    "scaffold_acc = [\n",
    "    2.36, 2.67, 3.01, 3.36, 3.77, 4.24, 4.68, 5.09, 5.47, 5.83,\n",
    "    6.22, 6.61, 6.94, 7.44, 7.82, 8.31, 8.75, 9.22, 9.65, 10.18,\n",
    "    10.59, 11.14, 11.56, 12.00, 12.32, 12.81, 13.17, 13.55, 13.97, 14.43,\n",
    "    14.77, 15.12, 15.54, 15.90, 16.22, 16.65, 16.95, 17.25, 17.52, 17.97,\n",
    "    18.38, 18.88, 19.22, 19.65, 20.11, 20.65, 21.05, 21.66, 22.41, 23.19,\n",
    "    24.09, 24.98, 25.65, 26.71, 27.61, 28.69, 29.87, 31.05, 32.26, 33.32,\n",
    "    34.38, 35.31, 36.48, 37.43, 38.30, 39.10, 39.98, 40.94, 41.67, 42.75,\n",
    "    43.56, 44.46, 45.14, 45.97, 46.91, 47.62, 48.33, 48.94, 49.66, 50.28,\n",
    "    50.65, 51.26, 51.81, 52.23, 52.69, 53.15, 53.53, 54.11, 54.41, 54.78,\n",
    "    55.15, 55.57, 55.77, 56.12, 56.48, 56.83, 57.04, 57.35, 57.60, 57.89\n",
    "]\n",
    "\n",
    "fedict_acc = [\n",
    "    2.74, 2.75, 2.77, 2.79, 2.80, 2.81, 2.82, 2.84, 2.86, 2.88,\n",
    "    2.89, 2.91, 2.92, 2.94, 2.95, 2.97, 3.00, 3.01, 3.02, 3.04,\n",
    "    3.04, 3.05, 3.07, 3.09, 3.11, 3.12, 3.14, 3.15, 3.17, 3.18,\n",
    "    3.20, 3.21, 3.23, 3.25, 3.26, 3.28, 3.29, 3.31, 3.32, 3.33,\n",
    "    3.34, 3.35, 3.35, 3.37, 3.39, 3.41, 3.42, 3.43, 3.44, 3.46,\n",
    "    3.47, 3.49, 3.50, 3.51, 3.52, 3.54, 3.55, 3.57, 3.59, 3.61,\n",
    "    3.63, 3.65, 3.66, 3.67, 3.68, 3.68, 3.70, 3.72, 3.73, 3.74,\n",
    "    3.76, 3.76, 3.78, 3.80, 3.82, 3.83, 3.85, 3.86, 3.87, 3.89,\n",
    "    3.89, 3.90, 3.92, 3.93, 3.94, 3.96, 3.98, 3.99, 4.02, 4.03,\n",
    "    4.04, 4.05, 4.07, 4.09, 4.10, 4.10, 4.12, 4.12, 4.13, 4.14\n",
    "]\n",
    "\n",
    "feddyn_df_acc = [\n",
    "    2.01, 2.03, 2.06, 2.09, 2.14, 2.20, 2.30, 2.46, 2.64, 2.88,\n",
    "    3.11, 3.36, 3.63, 3.89, 4.16, 4.45, 4.73, 5.01, 5.22, 5.49,\n",
    "    5.71, 5.93, 6.12, 6.37, 6.66, 6.84, 7.08, 7.34, 7.59, 7.84,\n",
    "    8.11, 8.35, 8.60, 8.89, 9.24, 9.49, 9.74, 10.04, 10.42, 10.80,\n",
    "    11.18, 11.62, 12.05, 12.48, 12.87, 13.27, 13.65, 13.98, 14.29, 14.59,\n",
    "    14.98, 15.27, 15.55, 15.91, 16.19, 16.54, 16.92, 17.32, 17.67, 18.12,\n",
    "    18.54, 18.96, 19.48, 19.93, 20.45, 20.95, 21.61, 22.11, 22.77, 23.43,\n",
    "    24.02, 24.65, 25.23, 25.82, 26.50, 27.21, 27.86, 28.53, 29.28, 30.00,\n",
    "    30.88, 31.61, 32.59, 33.39, 34.16, 34.98, 35.96, 36.67, 37.41, 38.26,\n",
    "    39.16, 39.79, 40.88, 41.61, 42.59, 43.54, 44.23, 45.08, 45.77, 46.42\n",
    "]\n",
    "\n",
    "fedsc_mtl_acc = [\n",
    "    2.76, 2.96, 3.18, 3.47, 3.77, 4.00, 4.25, 4.43, 4.59, 4.67,\n",
    "    4.77, 4.88, 4.99, 5.07, 5.14, 5.12, 5.13, 5.12, 5.17, 5.17,\n",
    "    5.27, 5.34, 5.36, 5.47, 5.52, 5.67, 5.80, 5.86, 5.92, 6.07,\n",
    "    6.19, 6.32, 6.49, 6.61, 6.77, 6.87, 7.08, 7.28, 7.42, 7.61,\n",
    "    7.72, 7.88, 8.03, 8.18, 8.37, 8.49, 8.68, 8.95, 9.17, 9.32,\n",
    "    9.59, 9.96, 10.19, 10.50, 10.86, 11.20, 11.66, 11.88, 12.43, 12.83,\n",
    "    13.35, 13.76, 14.27, 14.79, 15.36, 15.86, 16.30, 16.78, 17.36, 17.79,\n",
    "    18.24, 18.84, 19.29, 19.71, 20.22, 20.89, 21.43, 22.03, 22.62, 23.10,\n",
    "    23.70, 24.18, 24.81, 25.32, 25.85, 26.36, 26.86, 27.34, 27.77, 28.32,\n",
    "    28.84, 29.19, 29.61, 30.07, 30.50, 30.94, 31.43, 31.88, 32.31, 32.91\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "rounds = list(range(1, 101))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(rounds, fedavg_acc, label='FedAvg')\n",
    "plt.plot(rounds, fedprox_acc, label='FedProx')\n",
    "plt.plot(rounds, scaffold_acc, label='SCAFFOLD')\n",
    "plt.plot(rounds, fedict_acc, label='FedICT')\n",
    "plt.plot(rounds, feddyn_df_acc, label='FedDyn-DF')\n",
    "plt.plot(rounds, fedsc_mtl_acc, label='FedSC-MTL')\n",
    "\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.title('Test Accuracy vs. Round (EMNIST)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
