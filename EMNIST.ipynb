{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T15:01:03.733382Z",
     "start_time": "2025-06-10T15:01:03.721092Z"
    },
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FEMNIST data...\n",
      "Starting Federated Training...\n",
      "Round 1/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 2.8573, Acc: 31.85%\n",
      "Client Avg - Loss: 0.8899, Acc: 80.43%\n",
      "Round 2/100, μ=0.0980, Clients: 10\n",
      "Global Test - Loss: 1.8109, Acc: 54.45%\n",
      "Client Avg - Loss: 0.5387, Acc: 86.60%\n",
      "Round 3/100, μ=0.0960, Clients: 10\n",
      "Global Test - Loss: 1.3468, Acc: 62.32%\n",
      "Client Avg - Loss: 0.5571, Acc: 85.82%\n",
      "Round 4/100, μ=0.0941, Clients: 10\n",
      "Global Test - Loss: 1.0962, Acc: 67.97%\n",
      "Client Avg - Loss: 0.3743, Acc: 89.81%\n",
      "Round 5/100, μ=0.0922, Clients: 10\n",
      "Global Test - Loss: 0.9456, Acc: 70.49%\n",
      "Client Avg - Loss: 0.3309, Acc: 91.80%\n",
      "Round 6/100, μ=0.0904, Clients: 10\n",
      "Global Test - Loss: 0.9135, Acc: 70.99%\n",
      "Client Avg - Loss: 0.2974, Acc: 92.20%\n",
      "Round 7/100, μ=0.0886, Clients: 10\n",
      "Global Test - Loss: 0.8129, Acc: 73.22%\n",
      "Client Avg - Loss: 0.2276, Acc: 94.40%\n",
      "Round 8/100, μ=0.0868, Clients: 10\n",
      "Global Test - Loss: 0.8810, Acc: 72.15%\n",
      "Client Avg - Loss: 0.2243, Acc: 94.54%\n",
      "Round 9/100, μ=0.0851, Clients: 10\n",
      "Global Test - Loss: 0.7514, Acc: 76.26%\n",
      "Client Avg - Loss: 0.2589, Acc: 93.69%\n",
      "Round 10/100, μ=0.0834, Clients: 10\n",
      "Global Test - Loss: 0.7537, Acc: 73.61%\n",
      "Client Avg - Loss: 0.2374, Acc: 93.83%\n",
      "Round 11/100, μ=0.0817, Clients: 10\n",
      "Global Test - Loss: 0.6835, Acc: 77.51%\n",
      "Client Avg - Loss: 0.2368, Acc: 93.26%\n",
      "Round 12/100, μ=0.0801, Clients: 10\n",
      "Global Test - Loss: 0.7163, Acc: 76.57%\n",
      "Client Avg - Loss: 0.2113, Acc: 94.49%\n",
      "Round 13/100, μ=0.0785, Clients: 10\n",
      "Global Test - Loss: 0.7109, Acc: 75.95%\n",
      "Client Avg - Loss: 0.2413, Acc: 93.09%\n",
      "Round 14/100, μ=0.0769, Clients: 10\n",
      "Global Test - Loss: 0.6440, Acc: 78.97%\n",
      "Client Avg - Loss: 0.2356, Acc: 92.87%\n",
      "Round 15/100, μ=0.0754, Clients: 10\n",
      "Global Test - Loss: 0.6743, Acc: 76.91%\n",
      "Client Avg - Loss: 0.2207, Acc: 93.85%\n",
      "Round 16/100, μ=0.0739, Clients: 10\n",
      "Global Test - Loss: 0.7731, Acc: 73.10%\n",
      "Client Avg - Loss: 0.2375, Acc: 92.50%\n",
      "Round 17/100, μ=0.0724, Clients: 10\n",
      "Global Test - Loss: 0.6460, Acc: 76.06%\n",
      "Client Avg - Loss: 0.1932, Acc: 94.87%\n",
      "Round 18/100, μ=0.0709, Clients: 10\n",
      "Global Test - Loss: 0.6867, Acc: 73.35%\n",
      "Client Avg - Loss: 0.1945, Acc: 94.32%\n",
      "Round 19/100, μ=0.0695, Clients: 10\n",
      "Global Test - Loss: 0.6977, Acc: 74.65%\n",
      "Client Avg - Loss: 0.2309, Acc: 92.86%\n",
      "Round 20/100, μ=0.0681, Clients: 10\n",
      "Global Test - Loss: 0.6441, Acc: 76.14%\n",
      "Client Avg - Loss: 0.2216, Acc: 93.46%\n",
      "Round 21/100, μ=0.0668, Clients: 10\n",
      "Global Test - Loss: 0.6787, Acc: 76.11%\n",
      "Client Avg - Loss: 0.1833, Acc: 94.83%\n",
      "Round 22/100, μ=0.0654, Clients: 10\n",
      "Global Test - Loss: 0.6135, Acc: 79.10%\n",
      "Client Avg - Loss: 0.2469, Acc: 92.71%\n",
      "Round 23/100, μ=0.0641, Clients: 10\n",
      "Global Test - Loss: 0.6338, Acc: 78.80%\n",
      "Client Avg - Loss: 0.1775, Acc: 95.08%\n",
      "Round 24/100, μ=0.0628, Clients: 10\n",
      "Global Test - Loss: 0.6436, Acc: 76.41%\n",
      "Client Avg - Loss: 0.2024, Acc: 93.63%\n",
      "Round 25/100, μ=0.0616, Clients: 10\n",
      "Global Test - Loss: 0.6222, Acc: 78.75%\n",
      "Client Avg - Loss: 0.1660, Acc: 95.22%\n",
      "Round 26/100, μ=0.0603, Clients: 10\n",
      "Global Test - Loss: 0.6250, Acc: 79.40%\n",
      "Client Avg - Loss: 0.1729, Acc: 95.20%\n",
      "Round 27/100, μ=0.0591, Clients: 10\n",
      "Global Test - Loss: 0.5591, Acc: 80.33%\n",
      "Client Avg - Loss: 0.1628, Acc: 95.20%\n",
      "Round 28/100, μ=0.0580, Clients: 10\n",
      "Global Test - Loss: 0.6364, Acc: 76.76%\n",
      "Client Avg - Loss: 0.1666, Acc: 94.97%\n",
      "Round 29/100, μ=0.0568, Clients: 10\n",
      "Global Test - Loss: 0.6600, Acc: 74.21%\n",
      "Client Avg - Loss: 0.1946, Acc: 93.84%\n",
      "Round 30/100, μ=0.0557, Clients: 10\n",
      "Global Test - Loss: 0.5473, Acc: 80.59%\n",
      "Client Avg - Loss: 0.1487, Acc: 95.79%\n",
      "Round 31/100, μ=0.0545, Clients: 10\n",
      "Global Test - Loss: 0.5967, Acc: 76.69%\n",
      "Client Avg - Loss: 0.1773, Acc: 94.76%\n",
      "Round 32/100, μ=0.0535, Clients: 10\n",
      "Global Test - Loss: 0.6268, Acc: 77.77%\n",
      "Client Avg - Loss: 0.1282, Acc: 96.66%\n",
      "Round 33/100, μ=0.0524, Clients: 10\n",
      "Global Test - Loss: 0.5932, Acc: 78.54%\n",
      "Client Avg - Loss: 0.1186, Acc: 97.05%\n",
      "Round 34/100, μ=0.0513, Clients: 10\n",
      "Global Test - Loss: 0.5546, Acc: 80.96%\n",
      "Client Avg - Loss: 0.1761, Acc: 95.04%\n",
      "Round 35/100, μ=0.0503, Clients: 10\n",
      "Global Test - Loss: 0.5496, Acc: 79.63%\n",
      "Client Avg - Loss: 0.1961, Acc: 94.18%\n",
      "Round 36/100, μ=0.0493, Clients: 10\n",
      "Global Test - Loss: 0.5583, Acc: 80.49%\n",
      "Client Avg - Loss: 0.1323, Acc: 96.60%\n",
      "Round 37/100, μ=0.0483, Clients: 10\n",
      "Global Test - Loss: 0.6036, Acc: 79.15%\n",
      "Client Avg - Loss: 0.1328, Acc: 96.31%\n",
      "Round 38/100, μ=0.0474, Clients: 10\n",
      "Global Test - Loss: 0.6216, Acc: 79.07%\n",
      "Client Avg - Loss: 0.1177, Acc: 96.92%\n",
      "Round 39/100, μ=0.0464, Clients: 10\n",
      "Global Test - Loss: 0.5804, Acc: 80.40%\n",
      "Client Avg - Loss: 0.1737, Acc: 94.41%\n",
      "Round 40/100, μ=0.0455, Clients: 10\n",
      "Global Test - Loss: 0.5754, Acc: 78.11%\n",
      "Client Avg - Loss: 0.1627, Acc: 95.28%\n",
      "Round 41/100, μ=0.0446, Clients: 10\n",
      "Global Test - Loss: 0.6097, Acc: 79.10%\n",
      "Client Avg - Loss: 0.1639, Acc: 95.11%\n",
      "Round 42/100, μ=0.0437, Clients: 10\n",
      "Global Test - Loss: 0.5713, Acc: 78.35%\n",
      "Client Avg - Loss: 0.1514, Acc: 95.31%\n",
      "Round 43/100, μ=0.0428, Clients: 10\n",
      "Global Test - Loss: 0.6024, Acc: 77.39%\n",
      "Client Avg - Loss: 0.1339, Acc: 96.26%\n",
      "Round 44/100, μ=0.0419, Clients: 10\n",
      "Global Test - Loss: 0.5611, Acc: 80.07%\n",
      "Client Avg - Loss: 0.1246, Acc: 96.51%\n",
      "Round 45/100, μ=0.0411, Clients: 10\n",
      "Global Test - Loss: 0.5741, Acc: 78.94%\n",
      "Client Avg - Loss: 0.1738, Acc: 94.14%\n",
      "Round 46/100, μ=0.0403, Clients: 10\n",
      "Global Test - Loss: 0.6615, Acc: 75.18%\n",
      "Client Avg - Loss: 0.1755, Acc: 94.31%\n",
      "Round 47/100, μ=0.0395, Clients: 10\n",
      "Global Test - Loss: 0.5536, Acc: 80.98%\n",
      "Client Avg - Loss: 0.1350, Acc: 96.40%\n",
      "Round 48/100, μ=0.0387, Clients: 10\n",
      "Global Test - Loss: 0.5685, Acc: 79.13%\n",
      "Client Avg - Loss: 0.1975, Acc: 93.18%\n",
      "Round 49/100, μ=0.0379, Clients: 10\n",
      "Global Test - Loss: 0.5852, Acc: 76.94%\n",
      "Client Avg - Loss: 0.1437, Acc: 95.71%\n",
      "Round 50/100, μ=0.0372, Clients: 10\n",
      "Global Test - Loss: 0.5923, Acc: 77.81%\n",
      "Client Avg - Loss: 0.1587, Acc: 94.97%\n",
      "Round 51/100, μ=0.0364, Clients: 10\n",
      "Global Test - Loss: 0.5589, Acc: 80.60%\n",
      "Client Avg - Loss: 0.0923, Acc: 97.57%\n",
      "Round 52/100, μ=0.0357, Clients: 10\n",
      "Global Test - Loss: 0.5606, Acc: 79.46%\n",
      "Client Avg - Loss: 0.1413, Acc: 95.56%\n",
      "Round 53/100, μ=0.0350, Clients: 10\n",
      "Global Test - Loss: 0.5475, Acc: 80.78%\n",
      "Client Avg - Loss: 0.1274, Acc: 96.11%\n",
      "Round 54/100, μ=0.0343, Clients: 10\n",
      "Global Test - Loss: 0.5965, Acc: 79.37%\n",
      "Client Avg - Loss: 0.1130, Acc: 96.97%\n",
      "Round 55/100, μ=0.0336, Clients: 10\n",
      "Global Test - Loss: 0.5668, Acc: 79.69%\n",
      "Client Avg - Loss: 0.1538, Acc: 95.35%\n",
      "Round 56/100, μ=0.0329, Clients: 10\n",
      "Global Test - Loss: 0.5809, Acc: 77.15%\n",
      "Client Avg - Loss: 0.1607, Acc: 94.69%\n",
      "Round 57/100, μ=0.0323, Clients: 10\n",
      "Global Test - Loss: 0.6124, Acc: 77.21%\n",
      "Client Avg - Loss: 0.1412, Acc: 95.41%\n",
      "Round 58/100, μ=0.0316, Clients: 10\n",
      "Global Test - Loss: 0.5052, Acc: 81.55%\n",
      "Client Avg - Loss: 0.1305, Acc: 96.00%\n",
      "Round 59/100, μ=0.0310, Clients: 10\n",
      "Global Test - Loss: 0.5651, Acc: 80.01%\n",
      "Client Avg - Loss: 0.1260, Acc: 96.28%\n",
      "Round 60/100, μ=0.0304, Clients: 10\n",
      "Global Test - Loss: 0.5546, Acc: 80.83%\n",
      "Client Avg - Loss: 0.1211, Acc: 96.34%\n",
      "Round 61/100, μ=0.0298, Clients: 10\n",
      "Global Test - Loss: 0.5896, Acc: 77.62%\n",
      "Client Avg - Loss: 0.1560, Acc: 94.08%\n",
      "Round 62/100, μ=0.0292, Clients: 10\n",
      "Global Test - Loss: 0.5557, Acc: 78.06%\n",
      "Client Avg - Loss: 0.1202, Acc: 96.27%\n",
      "Round 63/100, μ=0.0286, Clients: 10\n",
      "Global Test - Loss: 0.5242, Acc: 81.02%\n",
      "Client Avg - Loss: 0.1224, Acc: 96.44%\n",
      "Round 64/100, μ=0.0280, Clients: 10\n",
      "Global Test - Loss: 0.5850, Acc: 78.23%\n",
      "Client Avg - Loss: 0.1231, Acc: 96.21%\n",
      "Round 65/100, μ=0.0274, Clients: 10\n",
      "Global Test - Loss: 0.5537, Acc: 80.09%\n",
      "Client Avg - Loss: 0.1267, Acc: 96.29%\n",
      "Round 66/100, μ=0.0269, Clients: 10\n",
      "Global Test - Loss: 0.5747, Acc: 79.15%\n",
      "Client Avg - Loss: 0.1428, Acc: 95.03%\n",
      "Round 67/100, μ=0.0264, Clients: 10\n",
      "Global Test - Loss: 0.6187, Acc: 79.79%\n",
      "Client Avg - Loss: 0.1187, Acc: 96.65%\n",
      "Round 68/100, μ=0.0258, Clients: 10\n",
      "Global Test - Loss: 0.5473, Acc: 79.63%\n",
      "Client Avg - Loss: 0.1615, Acc: 94.63%\n",
      "Round 69/100, μ=0.0253, Clients: 10\n",
      "Global Test - Loss: 0.5555, Acc: 79.06%\n",
      "Client Avg - Loss: 0.1332, Acc: 96.06%\n",
      "Round 70/100, μ=0.0248, Clients: 10\n",
      "Global Test - Loss: 0.5112, Acc: 81.99%\n",
      "Client Avg - Loss: 0.1210, Acc: 96.31%\n",
      "Round 71/100, μ=0.0243, Clients: 10\n",
      "Global Test - Loss: 0.5598, Acc: 78.78%\n",
      "Client Avg - Loss: 0.1725, Acc: 93.87%\n",
      "Round 72/100, μ=0.0238, Clients: 10\n",
      "Global Test - Loss: 0.5372, Acc: 79.28%\n",
      "Client Avg - Loss: 0.1016, Acc: 97.11%\n",
      "Round 73/100, μ=0.0233, Clients: 10\n",
      "Global Test - Loss: 0.4981, Acc: 82.05%\n",
      "Client Avg - Loss: 0.1125, Acc: 96.75%\n",
      "Round 74/100, μ=0.0229, Clients: 10\n",
      "Global Test - Loss: 0.6136, Acc: 78.16%\n",
      "Client Avg - Loss: 0.1029, Acc: 96.96%\n",
      "Round 75/100, μ=0.0224, Clients: 10\n",
      "Global Test - Loss: 0.5214, Acc: 81.14%\n",
      "Client Avg - Loss: 0.0784, Acc: 97.94%\n",
      "Round 76/100, μ=0.0220, Clients: 10\n",
      "Global Test - Loss: 0.5748, Acc: 78.53%\n",
      "Client Avg - Loss: 0.1338, Acc: 95.01%\n",
      "Round 77/100, μ=0.0215, Clients: 10\n",
      "Global Test - Loss: 0.5792, Acc: 78.89%\n",
      "Client Avg - Loss: 0.1074, Acc: 96.91%\n",
      "Round 78/100, μ=0.0211, Clients: 10\n",
      "Global Test - Loss: 0.5645, Acc: 78.74%\n",
      "Client Avg - Loss: 0.0958, Acc: 97.16%\n",
      "Round 79/100, μ=0.0207, Clients: 10\n",
      "Global Test - Loss: 0.5841, Acc: 79.25%\n",
      "Client Avg - Loss: 0.1740, Acc: 93.95%\n",
      "Round 80/100, μ=0.0203, Clients: 10\n",
      "Global Test - Loss: 0.5130, Acc: 80.64%\n",
      "Client Avg - Loss: 0.1254, Acc: 96.06%\n",
      "Round 81/100, μ=0.0199, Clients: 10\n",
      "Global Test - Loss: 0.4825, Acc: 81.99%\n",
      "Client Avg - Loss: 0.0973, Acc: 97.00%\n",
      "Round 82/100, μ=0.0195, Clients: 10\n",
      "Global Test - Loss: 0.5829, Acc: 79.97%\n",
      "Client Avg - Loss: 0.1364, Acc: 94.58%\n",
      "Round 83/100, μ=0.0191, Clients: 10\n",
      "Global Test - Loss: 0.5358, Acc: 79.89%\n",
      "Client Avg - Loss: 0.1198, Acc: 96.20%\n",
      "Round 84/100, μ=0.0187, Clients: 10\n",
      "Global Test - Loss: 0.5315, Acc: 79.83%\n",
      "Client Avg - Loss: 0.0992, Acc: 97.02%\n",
      "Round 85/100, μ=0.0183, Clients: 10\n",
      "Global Test - Loss: 0.5332, Acc: 80.00%\n",
      "Client Avg - Loss: 0.1124, Acc: 96.24%\n",
      "Round 86/100, μ=0.0180, Clients: 10\n",
      "Global Test - Loss: 0.4658, Acc: 83.43%\n",
      "Client Avg - Loss: 0.0859, Acc: 97.64%\n",
      "Round 87/100, μ=0.0176, Clients: 10\n",
      "Global Test - Loss: 0.5499, Acc: 79.12%\n",
      "Client Avg - Loss: 0.1227, Acc: 96.47%\n",
      "Round 88/100, μ=0.0172, Clients: 10\n",
      "Global Test - Loss: 0.5770, Acc: 76.42%\n",
      "Client Avg - Loss: 0.1162, Acc: 95.90%\n",
      "Round 89/100, μ=0.0169, Clients: 10\n",
      "Global Test - Loss: 0.4822, Acc: 82.71%\n",
      "Client Avg - Loss: 0.0947, Acc: 96.97%\n",
      "Round 90/100, μ=0.0166, Clients: 10\n",
      "Global Test - Loss: 0.4921, Acc: 82.86%\n",
      "Client Avg - Loss: 0.1236, Acc: 95.74%\n",
      "Round 91/100, μ=0.0162, Clients: 10\n",
      "Global Test - Loss: 0.5133, Acc: 82.02%\n",
      "Client Avg - Loss: 0.1415, Acc: 94.83%\n",
      "Round 92/100, μ=0.0159, Clients: 10\n",
      "Global Test - Loss: 0.5214, Acc: 80.80%\n",
      "Client Avg - Loss: 0.1368, Acc: 95.18%\n",
      "Round 93/100, μ=0.0156, Clients: 10\n",
      "Global Test - Loss: 0.4803, Acc: 83.46%\n",
      "Client Avg - Loss: 0.0861, Acc: 97.50%\n",
      "Round 94/100, μ=0.0153, Clients: 10\n",
      "Global Test - Loss: 0.5340, Acc: 78.69%\n",
      "Client Avg - Loss: 0.1306, Acc: 95.24%\n",
      "Round 95/100, μ=0.0150, Clients: 10\n",
      "Global Test - Loss: 0.4906, Acc: 81.42%\n",
      "Client Avg - Loss: 0.1064, Acc: 96.28%\n",
      "Round 96/100, μ=0.0147, Clients: 10\n",
      "Global Test - Loss: 0.5649, Acc: 78.26%\n",
      "Client Avg - Loss: 0.1110, Acc: 95.97%\n",
      "Round 97/100, μ=0.0144, Clients: 10\n",
      "Global Test - Loss: 0.4948, Acc: 82.27%\n",
      "Client Avg - Loss: 0.1225, Acc: 95.93%\n",
      "Round 98/100, μ=0.0141, Clients: 10\n",
      "Global Test - Loss: 0.5667, Acc: 80.14%\n",
      "Client Avg - Loss: 0.1337, Acc: 94.98%\n",
      "Round 99/100, μ=0.0138, Clients: 10\n",
      "Global Test - Loss: 0.4951, Acc: 81.72%\n",
      "Client Avg - Loss: 0.1254, Acc: 95.72%\n",
      "Round 100/100, μ=0.0135, Clients: 10\n",
      "Global Test - Loss: 0.5126, Acc: 80.51%\n",
      "Client Avg - Loss: 0.0891, Acc: 97.23%\n",
      "Training complete! Results saved.\n"
     ]
    }
   ],
   "source": [
    "# FedProx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def load_femnist_data(num_clients=100, iid_degree=0.1):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    full_dataset = datasets.EMNIST(\n",
    "        root='./data',\n",
    "        split='byclass',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    \n",
    "    client_data = {i: {'x': [], 'y': []} for i in range(num_clients)}\n",
    "    targets = full_dataset.targets.numpy()\n",
    "\n",
    "    for class_idx in range(62):  \n",
    "        class_indices = np.where(targets == class_idx)[0]\n",
    "        np.random.shuffle(class_indices)\n",
    "\n",
    "        proportions = np.random.dirichlet(np.repeat(iid_degree, num_clients))\n",
    "        allocations = (proportions * len(class_indices)).astype(int)\n",
    "        allocations[-1] = len(class_indices) - np.sum(allocations[:-1])\n",
    "\n",
    "        start_idx = 0\n",
    "        for client_id in range(num_clients):\n",
    "            end_idx = start_idx + allocations[client_id]\n",
    "            client_indices = class_indices[start_idx:end_idx]\n",
    "\n",
    "            for idx in client_indices:\n",
    "                img, label = full_dataset[idx]\n",
    "                client_data[client_id]['x'].append(img)\n",
    "                client_data[client_id]['y'].append(label)\n",
    "\n",
    "            start_idx = end_idx\n",
    "\n",
    "    client_loaders = {}\n",
    "    for client_id, data in client_data.items():\n",
    "        if len(data['x']) == 0:\n",
    "            continue\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(\n",
    "            data['x'], data['y'], test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        train_dataset = CustomDataset(x_train, y_train)\n",
    "        test_dataset = CustomDataset(x_test, y_test)\n",
    "\n",
    "        client_loaders[client_id] = {\n",
    "            'train': DataLoader(train_dataset, batch_size=32, shuffle=True),\n",
    "            'test': DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "        }\n",
    "\n",
    "    return client_loaders\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "class FemnistCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FemnistCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
    "        self.fc1 = nn.Linear(7*7*64, 512)\n",
    "        self.fc2 = nn.Linear(512, 62)  # 62个类别\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 7*7*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class FedProxClient:\n",
    "    def __init__(self, client_id, train_loader, test_loader, device):\n",
    "        self.client_id = client_id\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        self.model = FemnistCNN().to(device)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def train(self, global_model, mu, local_epochs, lr=0.01):\n",
    "        self.model.load_state_dict(global_model.state_dict())\n",
    "        self.model.train()\n",
    "\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=lr)\n",
    "\n",
    "        train_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for epoch in range(local_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for data, targets in self.train_loader:\n",
    "                data, targets = data.to(self.device), targets.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = self.model(data)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                proximal_term = 0.0\n",
    "                for w, w_t in zip(self.model.parameters(), global_model.parameters()):\n",
    "                    proximal_term += (w - w_t).norm(2)\n",
    "\n",
    "                loss = loss + (mu / 2) * proximal_term\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            epoch_loss /= len(self.train_loader)\n",
    "            train_loss += epoch_loss\n",
    "\n",
    "        train_loss /= local_epochs\n",
    "        train_acc = 100. * correct / total\n",
    "\n",
    "        return copy.deepcopy(self.model.state_dict()), train_loss, train_acc\n",
    "\n",
    "    def test(self, model=None):\n",
    "        if model:\n",
    "            self.model.load_state_dict(model)\n",
    "        self.model.eval()\n",
    "\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, targets in self.test_loader:\n",
    "                data, targets = data.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(data)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        test_loss /= len(self.test_loader)\n",
    "        test_acc = 100. * correct / total\n",
    "\n",
    "        return test_loss, test_acc\n",
    "\n",
    "# ======================\n",
    "# FedProx server\n",
    "# ======================\n",
    "class FedProxServer:\n",
    "    def __init__(self, num_clients, device, mu=0.1, dynamic_mu=False):\n",
    "        self.global_model = FemnistCNN().to(device)\n",
    "        self.device = device\n",
    "        self.clients = []\n",
    "        self.mu = mu\n",
    "        self.dynamic_mu = dynamic_mu\n",
    "        self.num_clients = num_clients\n",
    "\n",
    "    def add_clients(self, client_loaders):\n",
    "        for client_id, loaders in client_loaders.items():\n",
    "            self.clients.append(FedProxClient(\n",
    "                client_id,\n",
    "                loaders['train'],\n",
    "                loaders['test'],\n",
    "                self.device\n",
    "            ))\n",
    "\n",
    "    def aggregate(self, client_updates):\n",
    "        global_dict = self.global_model.state_dict()\n",
    "\n",
    "        total_samples = sum([samples for _, samples, _ in client_updates])\n",
    "        averaged_params = {}\n",
    "\n",
    "        for key in global_dict.keys():\n",
    "            averaged_params[key] = torch.zeros_like(global_dict[key])\n",
    "\n",
    "        for model_state, samples, _ in client_updates:\n",
    "            for key in model_state.keys():\n",
    "                averaged_params[key] += model_state[key] * (samples / total_samples)\n",
    "\n",
    "        self.global_model.load_state_dict(averaged_params)\n",
    "        return averaged_params\n",
    "\n",
    "    def select_clients(self, fraction=0.1):\n",
    "        num_selected = max(int(self.num_clients * fraction), 1)\n",
    "        return np.random.choice(self.clients, num_selected, replace=False)\n",
    "\n",
    "    def adaptive_mu(self, round_idx, base_mu=0.1, decay_rate=0.98):\n",
    "        if self.dynamic_mu:\n",
    "            return base_mu * (decay_rate ** round_idx)\n",
    "        return self.mu\n",
    "\n",
    "    def evaluate_global_model(self, test_loader=None):\n",
    "        self.global_model.eval()\n",
    "\n",
    "        if test_loader:\n",
    "            return self._centralized_eval(test_loader)\n",
    "        else:\n",
    "            return self._federated_eval()\n",
    "\n",
    "    def _centralized_eval(self, test_loader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        test_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, targets in test_loader:\n",
    "                data, targets = data.to(self.device), targets.to(self.device)\n",
    "                outputs = self.global_model(data)\n",
    "                loss = F.cross_entropy(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_acc = 100. * correct / total\n",
    "        return test_loss, test_acc\n",
    "\n",
    "    def _federated_eval(self):\n",
    "        total_loss = 0.0\n",
    "        total_acc = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        for client in self.clients:\n",
    "            samples = len(client.test_loader.dataset)\n",
    "            loss, acc = client.test(self.global_model.state_dict())\n",
    "\n",
    "            total_loss += loss * samples\n",
    "            total_acc += acc * samples\n",
    "            total_samples += samples\n",
    "\n",
    "        avg_loss = total_loss / total_samples\n",
    "        avg_acc = total_acc / total_samples\n",
    "        return avg_loss, avg_acc\n",
    "\n",
    "# ======================\n",
    "# main function\n",
    "# ======================\n",
    "def main():\n",
    "    num_rounds = 100\n",
    "    num_clients = 100\n",
    "    client_fraction = 0.1\n",
    "    local_epochs = 5\n",
    "    base_mu = 0.1\n",
    "    dynamic_mu = True  \n",
    "\n",
    "    print(\"Loading EMNIST data...\")\n",
    "    client_loaders = load_femnist_data(num_clients=num_clients, iid_degree=0.1)\n",
    "\n",
    "    server = FedProxServer(\n",
    "        num_clients=num_clients,\n",
    "        device=device,\n",
    "        mu=base_mu,\n",
    "        dynamic_mu=dynamic_mu\n",
    "    )\n",
    "    server.add_clients(client_loaders)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    test_dataset = datasets.EMNIST(\n",
    "        root='./data',\n",
    "        split='byclass',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transform\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    history = {\n",
    "        'round': [],\n",
    "        'mu': [],\n",
    "        'global_loss': [],\n",
    "        'global_acc': [],\n",
    "        'client_losses': [],\n",
    "        'client_accs': []\n",
    "    }\n",
    "\n",
    "    print(\"Starting Federated Training...\")\n",
    "    for round_idx in range(num_rounds):\n",
    "        mu = server.adaptive_mu(round_idx, base_mu=base_mu)\n",
    "\n",
    "        selected_clients = server.select_clients(fraction=client_fraction)\n",
    "        print(f\"Round {round_idx+1}/{num_rounds}, μ={mu:.4f}, Clients: {len(selected_clients)}\")\n",
    "\n",
    "        client_updates = []\n",
    "        client_stats = {'loss': [], 'acc': []}\n",
    "\n",
    "        for client in selected_clients:\n",
    "            model_state, loss, acc = client.train(\n",
    "                global_model=server.global_model,\n",
    "                mu=mu,\n",
    "                local_epochs=local_epochs,\n",
    "                lr=0.01\n",
    "            )\n",
    "            samples = len(client.train_loader.dataset)\n",
    "            client_updates.append((model_state, samples, client.client_id))\n",
    "            client_stats['loss'].append(loss)\n",
    "            client_stats['acc'].append(acc)\n",
    "\n",
    "        server.aggregate(client_updates)\n",
    "\n",
    "        global_loss, global_acc = server.evaluate_global_model(test_loader=test_loader)\n",
    "\n",
    "        history['round'].append(round_idx)\n",
    "        history['mu'].append(mu)\n",
    "        history['global_loss'].append(global_loss)\n",
    "        history['global_acc'].append(global_acc)\n",
    "        history['client_losses'].append(client_stats['loss'])\n",
    "        history['client_accs'].append(client_stats['acc'])\n",
    "\n",
    "        print(f\"Global Test - Loss: {global_loss:.4f}, Acc: {global_acc:.2f}%\")\n",
    "        print(f\"Client Avg - Loss: {np.mean(client_stats['loss']):.4f}, Acc: {np.mean(client_stats['acc']):.2f}%\")\n",
    "\n",
    "    torch.save({\n",
    "        'model': server.global_model.state_dict(),\n",
    "        'history': history\n",
    "    }, 'fedprox_femnist_results.pth')\n",
    "    print(\"Training complete! Results saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[0] Loading EMNIST...\n",
      "[1] Dataset loaded. Total samples: 112800\n",
      "[2] Partitioning data...\n",
      "[3] Partition done in 0.01s\n",
      "[4] Initializing models...\n",
      "[5] Starting federated training...\n",
      "Round 1/100, Clients: 10\n",
      "Global Test - Loss: 3.8508, Acc: 2.13%\n",
      "Round 2/100, Clients: 10\n",
      "Global Test - Loss: 3.8487, Acc: 2.21%\n",
      "Round 3/100, Clients: 10\n",
      "Global Test - Loss: 3.8466, Acc: 2.26%\n",
      "Round 4/100, Clients: 10\n",
      "Global Test - Loss: 3.8445, Acc: 2.30%\n",
      "Round 5/100, Clients: 10\n",
      "Global Test - Loss: 3.8425, Acc: 2.35%\n",
      "Round 6/100, Clients: 10\n",
      "Global Test - Loss: 3.8405, Acc: 2.43%\n",
      "Round 7/100, Clients: 10\n",
      "Global Test - Loss: 3.8386, Acc: 2.52%\n",
      "Round 8/100, Clients: 10\n",
      "Global Test - Loss: 3.8366, Acc: 2.62%\n",
      "Round 9/100, Clients: 10\n",
      "Global Test - Loss: 3.8346, Acc: 2.88%\n",
      "Round 10/100, Clients: 10\n",
      "Global Test - Loss: 3.8327, Acc: 3.11%\n",
      "Round 11/100, Clients: 10\n",
      "Global Test - Loss: 3.8308, Acc: 3.36%\n",
      "Round 12/100, Clients: 10\n",
      "Global Test - Loss: 3.8289, Acc: 3.67%\n",
      "Round 13/100, Clients: 10\n",
      "Global Test - Loss: 3.8269, Acc: 4.04%\n",
      "Round 14/100, Clients: 10\n",
      "Global Test - Loss: 3.8249, Acc: 4.47%\n",
      "Round 15/100, Clients: 10\n",
      "Global Test - Loss: 3.8228, Acc: 4.88%\n",
      "Round 16/100, Clients: 10\n",
      "Global Test - Loss: 3.8206, Acc: 5.34%\n",
      "Round 17/100, Clients: 10\n",
      "Global Test - Loss: 3.8184, Acc: 5.78%\n",
      "Round 18/100, Clients: 10\n",
      "Global Test - Loss: 3.8160, Acc: 6.17%\n",
      "Round 19/100, Clients: 10\n",
      "Global Test - Loss: 3.8135, Acc: 6.59%\n",
      "Round 20/100, Clients: 10\n",
      "Global Test - Loss: 3.8110, Acc: 7.07%\n",
      "Round 21/100, Clients: 10\n",
      "Global Test - Loss: 3.8084, Acc: 7.44%\n",
      "Round 22/100, Clients: 10\n",
      "Global Test - Loss: 3.8056, Acc: 7.81%\n",
      "Round 23/100, Clients: 10\n",
      "Global Test - Loss: 3.8028, Acc: 8.25%\n",
      "Round 24/100, Clients: 10\n",
      "Global Test - Loss: 3.7999, Acc: 8.63%\n",
      "Round 25/100, Clients: 10\n",
      "Global Test - Loss: 3.7967, Acc: 9.04%\n",
      "Round 26/100, Clients: 10\n",
      "Global Test - Loss: 3.7935, Acc: 9.45%\n",
      "Round 27/100, Clients: 10\n",
      "Global Test - Loss: 3.7901, Acc: 9.77%\n",
      "Round 28/100, Clients: 10\n",
      "Global Test - Loss: 3.7865, Acc: 10.17%\n",
      "Round 29/100, Clients: 10\n",
      "Global Test - Loss: 3.7828, Acc: 10.59%\n",
      "Round 30/100, Clients: 10\n",
      "Global Test - Loss: 3.7789, Acc: 10.94%\n",
      "Round 31/100, Clients: 10\n",
      "Global Test - Loss: 3.7747, Acc: 11.23%\n",
      "Round 32/100, Clients: 10\n",
      "Global Test - Loss: 3.7703, Acc: 11.68%\n",
      "Round 33/100, Clients: 10\n",
      "Global Test - Loss: 3.7656, Acc: 12.09%\n",
      "Round 34/100, Clients: 10\n",
      "Global Test - Loss: 3.7606, Acc: 12.47%\n",
      "Round 35/100, Clients: 10\n",
      "Global Test - Loss: 3.7553, Acc: 12.77%\n",
      "Round 36/100, Clients: 10\n",
      "Global Test - Loss: 3.7497, Acc: 13.18%\n",
      "Round 37/100, Clients: 10\n",
      "Global Test - Loss: 3.7437, Acc: 13.66%\n",
      "Round 38/100, Clients: 10\n",
      "Global Test - Loss: 3.7372, Acc: 14.00%\n",
      "Round 39/100, Clients: 10\n",
      "Global Test - Loss: 3.7303, Acc: 14.43%\n",
      "Round 40/100, Clients: 10\n",
      "Global Test - Loss: 3.7230, Acc: 14.86%\n",
      "Round 41/100, Clients: 10\n",
      "Global Test - Loss: 3.7152, Acc: 15.35%\n",
      "Round 42/100, Clients: 10\n",
      "Global Test - Loss: 3.7069, Acc: 15.78%\n",
      "Round 43/100, Clients: 10\n",
      "Global Test - Loss: 3.6981, Acc: 16.29%\n",
      "Round 44/100, Clients: 10\n",
      "Global Test - Loss: 3.6885, Acc: 16.77%\n",
      "Round 45/100, Clients: 10\n",
      "Global Test - Loss: 3.6784, Acc: 17.53%\n",
      "Round 46/100, Clients: 10\n",
      "Global Test - Loss: 3.6673, Acc: 18.21%\n",
      "Round 47/100, Clients: 10\n",
      "Global Test - Loss: 3.6551, Acc: 19.00%\n",
      "Round 48/100, Clients: 10\n",
      "Global Test - Loss: 3.6419, Acc: 19.94%\n",
      "Round 49/100, Clients: 10\n",
      "Global Test - Loss: 3.6280, Acc: 20.76%\n",
      "Round 50/100, Clients: 10\n",
      "Global Test - Loss: 3.6128, Acc: 21.64%\n",
      "Round 51/100, Clients: 10\n",
      "Global Test - Loss: 3.5962, Acc: 22.42%\n",
      "Round 52/100, Clients: 10\n",
      "Global Test - Loss: 3.5784, Acc: 23.30%\n",
      "Round 53/100, Clients: 10\n",
      "Global Test - Loss: 3.5590, Acc: 24.11%\n",
      "Round 54/100, Clients: 10\n",
      "Global Test - Loss: 3.5382, Acc: 24.69%\n",
      "Round 55/100, Clients: 10\n",
      "Global Test - Loss: 3.5155, Acc: 25.30%\n",
      "Round 56/100, Clients: 10\n",
      "Global Test - Loss: 3.4910, Acc: 25.84%\n",
      "Round 57/100, Clients: 10\n",
      "Global Test - Loss: 3.4644, Acc: 26.49%\n",
      "Round 58/100, Clients: 10\n",
      "Global Test - Loss: 3.4354, Acc: 27.12%\n",
      "Round 59/100, Clients: 10\n",
      "Global Test - Loss: 3.4038, Acc: 27.78%\n",
      "Round 60/100, Clients: 10\n",
      "Global Test - Loss: 3.3701, Acc: 28.51%\n",
      "Round 61/100, Clients: 10\n",
      "Global Test - Loss: 3.3340, Acc: 29.29%\n",
      "Round 62/100, Clients: 10\n",
      "Global Test - Loss: 3.2946, Acc: 30.21%\n",
      "Round 63/100, Clients: 10\n",
      "Global Test - Loss: 3.2526, Acc: 30.98%\n",
      "Round 64/100, Clients: 10\n",
      "Global Test - Loss: 3.2076, Acc: 31.85%\n",
      "Round 65/100, Clients: 10\n",
      "Global Test - Loss: 3.1599, Acc: 32.78%\n",
      "Round 66/100, Clients: 10\n",
      "Global Test - Loss: 3.1088, Acc: 33.71%\n",
      "Round 67/100, Clients: 10\n",
      "Global Test - Loss: 3.0553, Acc: 34.54%\n",
      "Round 68/100, Clients: 10\n",
      "Global Test - Loss: 2.9992, Acc: 35.38%\n",
      "Round 69/100, Clients: 10\n",
      "Global Test - Loss: 2.9409, Acc: 36.18%\n",
      "Round 70/100, Clients: 10\n",
      "Global Test - Loss: 2.8813, Acc: 37.08%\n",
      "Round 71/100, Clients: 10\n",
      "Global Test - Loss: 2.8204, Acc: 37.94%\n",
      "Round 72/100, Clients: 10\n",
      "Global Test - Loss: 2.7576, Acc: 38.78%\n",
      "Round 73/100, Clients: 10\n",
      "Global Test - Loss: 2.6949, Acc: 39.56%\n",
      "Round 74/100, Clients: 10\n",
      "Global Test - Loss: 2.6320, Acc: 40.31%\n",
      "Round 75/100, Clients: 10\n",
      "Global Test - Loss: 2.5702, Acc: 41.16%\n",
      "Round 76/100, Clients: 10\n",
      "Global Test - Loss: 2.5102, Acc: 41.97%\n",
      "Round 77/100, Clients: 10\n",
      "Global Test - Loss: 2.4513, Acc: 42.90%\n",
      "Round 78/100, Clients: 10\n",
      "Global Test - Loss: 2.3941, Acc: 43.65%\n",
      "Round 79/100, Clients: 10\n",
      "Global Test - Loss: 2.3397, Acc: 44.28%\n",
      "Round 80/100, Clients: 10\n",
      "Global Test - Loss: 2.2864, Acc: 44.92%\n",
      "Round 81/100, Clients: 10\n",
      "Global Test - Loss: 2.2358, Acc: 45.69%\n",
      "Round 82/100, Clients: 10\n",
      "Global Test - Loss: 2.1886, Acc: 46.31%\n",
      "Round 83/100, Clients: 10\n",
      "Global Test - Loss: 2.1444, Acc: 46.98%\n",
      "Round 84/100, Clients: 10\n",
      "Global Test - Loss: 2.1018, Acc: 47.61%\n",
      "Round 85/100, Clients: 10\n",
      "Global Test - Loss: 2.0622, Acc: 48.25%\n",
      "Round 86/100, Clients: 10\n",
      "Global Test - Loss: 2.0249, Acc: 48.82%\n",
      "Round 87/100, Clients: 10\n",
      "Global Test - Loss: 1.9897, Acc: 49.12%\n",
      "Round 88/100, Clients: 10\n",
      "Global Test - Loss: 1.9565, Acc: 49.72%\n",
      "Round 89/100, Clients: 10\n",
      "Global Test - Loss: 1.9253, Acc: 50.22%\n",
      "Round 90/100, Clients: 10\n",
      "Global Test - Loss: 1.8957, Acc: 50.59%\n",
      "Round 91/100, Clients: 10\n",
      "Global Test - Loss: 1.8671, Acc: 51.23%\n",
      "Round 92/100, Clients: 10\n",
      "Global Test - Loss: 1.8412, Acc: 51.54%\n",
      "Round 93/100, Clients: 10\n",
      "Global Test - Loss: 1.8162, Acc: 52.03%\n",
      "Round 94/100, Clients: 10\n",
      "Global Test - Loss: 1.7926, Acc: 52.35%\n",
      "Round 95/100, Clients: 10\n",
      "Global Test - Loss: 1.7702, Acc: 52.78%\n",
      "Round 96/100, Clients: 10\n",
      "Global Test - Loss: 1.7493, Acc: 53.20%\n",
      "Round 97/100, Clients: 10\n",
      "Global Test - Loss: 1.7287, Acc: 53.67%\n",
      "Round 98/100, Clients: 10\n",
      "Global Test - Loss: 1.7091, Acc: 53.96%\n",
      "Round 99/100, Clients: 10\n",
      "Global Test - Loss: 1.6907, Acc: 54.37%\n",
      "Round 100/100, Clients: 10\n",
      "Global Test - Loss: 1.6726, Acc: 54.72%\n",
      "[6] Done. Total time: 2173.10s\n"
     ]
    }
   ],
   "source": [
    "# FedAVG\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Model Definition\n",
    "# -----------------------------\n",
    "class EMNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*5*5, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 47)  # EMNIST Balanced has 47 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.conv(x))\n",
    "\n",
    "# -----------------------------\n",
    "# 2. EMNIST Partitioning (Non-IID)\n",
    "# -----------------------------\n",
    "def partition_data(dataset, num_clients=100):\n",
    "    labels = dataset.targets.numpy() if torch.is_tensor(dataset.targets) else np.array(dataset.targets)\n",
    "    idx_by_class = [np.where(labels == i)[0] for i in range(47)]\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "    for c in range(47):\n",
    "        np.random.shuffle(idx_by_class[c])\n",
    "        parts = np.array_split(idx_by_class[c], num_clients)\n",
    "        for i in range(num_clients):\n",
    "            client_indices[i].extend(parts[i])\n",
    "    return [Subset(dataset, inds) for inds in client_indices]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Client Class (FedAvg)\n",
    "# -----------------------------\n",
    "class Client:\n",
    "    def __init__(self, model, data, lr, local_epochs, device):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.data = data\n",
    "        self.lr = lr\n",
    "        self.local_epochs = local_epochs\n",
    "        self.device = device\n",
    "\n",
    "    def train(self, global_model):\n",
    "        self.model.load_state_dict(global_model.state_dict())\n",
    "        self.model.train()\n",
    "\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=self.lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loader = DataLoader(self.data, batch_size=32, shuffle=True)\n",
    "\n",
    "        for epoch in range(self.local_epochs):\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        return copy.deepcopy(self.model.state_dict())\n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        loader = DataLoader(self.data, batch_size=64, shuffle=False)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "                total_loss += loss.item() * x.size(0)\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += x.size(0)\n",
    "        return total_loss / total, correct / total\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Server Class (FedAvg)\n",
    "# -----------------------------\n",
    "class Server:\n",
    "    def __init__(self, model, num_clients):\n",
    "        self.global_model = model\n",
    "        self.clients = []\n",
    "        self.num_clients = num_clients\n",
    "\n",
    "    def add_clients(self, client_list):\n",
    "        self.clients = client_list\n",
    "\n",
    "    def aggregate(self, client_states):\n",
    "        avg_state = copy.deepcopy(self.global_model.state_dict())\n",
    "        for k in avg_state:\n",
    "            avg_state[k] = sum(client[k] for client in client_states) / len(client_states)\n",
    "        self.global_model.load_state_dict(avg_state)\n",
    "\n",
    "    def federated_train(self, rounds):\n",
    "        for r in range(rounds):\n",
    "            round_start = time.time()\n",
    "            selected = random.sample(self.clients, k=10)\n",
    "            client_states = []\n",
    "\n",
    "            print(f\"Round {r+1}/{rounds}, Clients: {len(selected)}\")\n",
    "\n",
    "            for client in selected:\n",
    "                state_dict = client.train(self.global_model)\n",
    "                client_states.append(state_dict)\n",
    "\n",
    "            self.aggregate(client_states)\n",
    "\n",
    "            # 全部客户端用于评估\n",
    "            global_losses, global_accs = [], []\n",
    "            for client in self.clients:\n",
    "                client.model.load_state_dict(self.global_model.state_dict())\n",
    "                loss, acc = client.evaluate()\n",
    "                global_losses.append(loss)\n",
    "                global_accs.append(acc)\n",
    "\n",
    "            avg_loss = np.mean(global_losses)\n",
    "            avg_acc = np.mean(global_accs) * 100\n",
    "\n",
    "            print(f\"Global Test - Loss: {avg_loss:.4f}, Acc: {avg_acc:.2f}%\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Main Execution\n",
    "# -----------------------------\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    print(\"[0] Loading EMNIST...\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    emnist_train = datasets.EMNIST(root=\"./data\", split=\"balanced\", train=True, download=True, transform=transform)\n",
    "    print(f\"[1] Dataset loaded. Total samples: {len(emnist_train)}\")\n",
    "\n",
    "    print(\"[2] Partitioning data...\")\n",
    "    partition_start = time.time()\n",
    "    client_data = partition_data(emnist_train, num_clients=100)\n",
    "    print(f\"[3] Partition done in {time.time() - partition_start:.2f}s\")\n",
    "\n",
    "    print(\"[4] Initializing models...\")\n",
    "    global_model = EMNIST_CNN().to(device)\n",
    "    server = Server(global_model, num_clients=100)\n",
    "    clients = [Client(global_model, data, lr=0.001, local_epochs=2, device=device) for data in client_data]\n",
    "    server.add_clients(clients)\n",
    "\n",
    "    print(\"[5] Starting federated training...\")\n",
    "    server.federated_train(rounds=100)\n",
    "\n",
    "    print(f\"[6] Done. Total time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[0] Loading EMNIST...\n",
      "[1] Dataset loaded. Total samples: 112800\n",
      "[2] Partitioning data...\n",
      "[3] Partition done in 0.01s\n",
      "[4] Initializing models...\n",
      "[5] Starting federated training...\n",
      "Round 1/100, Clients: 10\n",
      "Global Test - Loss: 3.8496, Acc: 2.36%\n",
      "Round 2/100, Clients: 10\n",
      "Global Test - Loss: 3.8472, Acc: 2.67%\n",
      "Round 3/100, Clients: 10\n",
      "Global Test - Loss: 3.8450, Acc: 3.01%\n",
      "Round 4/100, Clients: 10\n",
      "Global Test - Loss: 3.8428, Acc: 3.36%\n",
      "Round 5/100, Clients: 10\n",
      "Global Test - Loss: 3.8407, Acc: 3.77%\n",
      "Round 6/100, Clients: 10\n",
      "Global Test - Loss: 3.8387, Acc: 4.24%\n",
      "Round 7/100, Clients: 10\n",
      "Global Test - Loss: 3.8366, Acc: 4.68%\n",
      "Round 8/100, Clients: 10\n",
      "Global Test - Loss: 3.8345, Acc: 5.09%\n",
      "Round 9/100, Clients: 10\n",
      "Global Test - Loss: 3.8324, Acc: 5.47%\n",
      "Round 10/100, Clients: 10\n",
      "Global Test - Loss: 3.8303, Acc: 5.83%\n",
      "Round 11/100, Clients: 10\n",
      "Global Test - Loss: 3.8281, Acc: 6.22%\n",
      "Round 12/100, Clients: 10\n",
      "Global Test - Loss: 3.8259, Acc: 6.61%\n",
      "Round 13/100, Clients: 10\n",
      "Global Test - Loss: 3.8236, Acc: 6.94%\n",
      "Round 14/100, Clients: 10\n",
      "Global Test - Loss: 3.8212, Acc: 7.44%\n",
      "Round 15/100, Clients: 10\n",
      "Global Test - Loss: 3.8187, Acc: 7.82%\n",
      "Round 16/100, Clients: 10\n",
      "Global Test - Loss: 3.8161, Acc: 8.31%\n",
      "Round 17/100, Clients: 10\n",
      "Global Test - Loss: 3.8134, Acc: 8.75%\n",
      "Round 18/100, Clients: 10\n",
      "Global Test - Loss: 3.8105, Acc: 9.22%\n",
      "Round 19/100, Clients: 10\n",
      "Global Test - Loss: 3.8075, Acc: 9.65%\n",
      "Round 20/100, Clients: 10\n",
      "Global Test - Loss: 3.8043, Acc: 10.18%\n",
      "Round 21/100, Clients: 10\n",
      "Global Test - Loss: 3.8010, Acc: 10.59%\n",
      "Round 22/100, Clients: 10\n",
      "Global Test - Loss: 3.7975, Acc: 11.14%\n",
      "Round 23/100, Clients: 10\n",
      "Global Test - Loss: 3.7938, Acc: 11.56%\n",
      "Round 24/100, Clients: 10\n",
      "Global Test - Loss: 3.7899, Acc: 12.00%\n",
      "Round 25/100, Clients: 10\n",
      "Global Test - Loss: 3.7859, Acc: 12.32%\n",
      "Round 26/100, Clients: 10\n",
      "Global Test - Loss: 3.7816, Acc: 12.81%\n",
      "Round 27/100, Clients: 10\n",
      "Global Test - Loss: 3.7771, Acc: 13.17%\n",
      "Round 28/100, Clients: 10\n",
      "Global Test - Loss: 3.7723, Acc: 13.55%\n",
      "Round 29/100, Clients: 10\n",
      "Global Test - Loss: 3.7672, Acc: 13.97%\n",
      "Round 30/100, Clients: 10\n",
      "Global Test - Loss: 3.7619, Acc: 14.43%\n",
      "Round 31/100, Clients: 10\n",
      "Global Test - Loss: 3.7562, Acc: 14.77%\n",
      "Round 32/100, Clients: 10\n",
      "Global Test - Loss: 3.7502, Acc: 15.12%\n",
      "Round 33/100, Clients: 10\n",
      "Global Test - Loss: 3.7437, Acc: 15.54%\n",
      "Round 34/100, Clients: 10\n",
      "Global Test - Loss: 3.7369, Acc: 15.90%\n",
      "Round 35/100, Clients: 10\n",
      "Global Test - Loss: 3.7296, Acc: 16.22%\n",
      "Round 36/100, Clients: 10\n",
      "Global Test - Loss: 3.7219, Acc: 16.65%\n",
      "Round 37/100, Clients: 10\n",
      "Global Test - Loss: 3.7137, Acc: 16.95%\n",
      "Round 38/100, Clients: 10\n",
      "Global Test - Loss: 3.7050, Acc: 17.25%\n",
      "Round 39/100, Clients: 10\n",
      "Global Test - Loss: 3.6957, Acc: 17.52%\n",
      "Round 40/100, Clients: 10\n",
      "Global Test - Loss: 3.6856, Acc: 17.97%\n",
      "Round 41/100, Clients: 10\n",
      "Global Test - Loss: 3.6749, Acc: 18.38%\n",
      "Round 42/100, Clients: 10\n",
      "Global Test - Loss: 3.6635, Acc: 18.88%\n",
      "Round 43/100, Clients: 10\n",
      "Global Test - Loss: 3.6512, Acc: 19.22%\n",
      "Round 44/100, Clients: 10\n",
      "Global Test - Loss: 3.6381, Acc: 19.65%\n",
      "Round 45/100, Clients: 10\n",
      "Global Test - Loss: 3.6239, Acc: 20.11%\n",
      "Round 46/100, Clients: 10\n",
      "Global Test - Loss: 3.6086, Acc: 20.65%\n",
      "Round 47/100, Clients: 10\n",
      "Global Test - Loss: 3.5922, Acc: 21.05%\n",
      "Round 48/100, Clients: 10\n",
      "Global Test - Loss: 3.5743, Acc: 21.66%\n",
      "Round 49/100, Clients: 10\n",
      "Global Test - Loss: 3.5551, Acc: 22.41%\n",
      "Round 50/100, Clients: 10\n",
      "Global Test - Loss: 3.5344, Acc: 23.19%\n",
      "Round 51/100, Clients: 10\n",
      "Global Test - Loss: 3.5121, Acc: 24.09%\n",
      "Round 52/100, Clients: 10\n",
      "Global Test - Loss: 3.4880, Acc: 24.98%\n",
      "Round 53/100, Clients: 10\n",
      "Global Test - Loss: 3.4618, Acc: 25.65%\n",
      "Round 54/100, Clients: 10\n",
      "Global Test - Loss: 3.4335, Acc: 26.71%\n",
      "Round 55/100, Clients: 10\n",
      "Global Test - Loss: 3.4025, Acc: 27.61%\n",
      "Round 56/100, Clients: 10\n",
      "Global Test - Loss: 3.3691, Acc: 28.69%\n",
      "Round 57/100, Clients: 10\n",
      "Global Test - Loss: 3.3330, Acc: 29.87%\n",
      "Round 58/100, Clients: 10\n",
      "Global Test - Loss: 3.2936, Acc: 31.05%\n",
      "Round 59/100, Clients: 10\n",
      "Global Test - Loss: 3.2514, Acc: 32.26%\n",
      "Round 60/100, Clients: 10\n",
      "Global Test - Loss: 3.2058, Acc: 33.32%\n",
      "Round 61/100, Clients: 10\n",
      "Global Test - Loss: 3.1574, Acc: 34.38%\n",
      "Round 62/100, Clients: 10\n",
      "Global Test - Loss: 3.1057, Acc: 35.31%\n",
      "Round 63/100, Clients: 10\n",
      "Global Test - Loss: 3.0504, Acc: 36.48%\n",
      "Round 64/100, Clients: 10\n",
      "Global Test - Loss: 2.9919, Acc: 37.43%\n",
      "Round 65/100, Clients: 10\n",
      "Global Test - Loss: 2.9307, Acc: 38.30%\n",
      "Round 66/100, Clients: 10\n",
      "Global Test - Loss: 2.8668, Acc: 39.10%\n",
      "Round 67/100, Clients: 10\n",
      "Global Test - Loss: 2.8018, Acc: 39.98%\n",
      "Round 68/100, Clients: 10\n",
      "Global Test - Loss: 2.7348, Acc: 40.94%\n",
      "Round 69/100, Clients: 10\n",
      "Global Test - Loss: 2.6670, Acc: 41.67%\n",
      "Round 70/100, Clients: 10\n",
      "Global Test - Loss: 2.5994, Acc: 42.75%\n",
      "Round 71/100, Clients: 10\n",
      "Global Test - Loss: 2.5319, Acc: 43.56%\n",
      "Round 72/100, Clients: 10\n",
      "Global Test - Loss: 2.4658, Acc: 44.46%\n",
      "Round 73/100, Clients: 10\n",
      "Global Test - Loss: 2.4010, Acc: 45.14%\n",
      "Round 74/100, Clients: 10\n",
      "Global Test - Loss: 2.3374, Acc: 45.97%\n",
      "Round 75/100, Clients: 10\n",
      "Global Test - Loss: 2.2767, Acc: 46.91%\n",
      "Round 76/100, Clients: 10\n",
      "Global Test - Loss: 2.2189, Acc: 47.62%\n",
      "Round 77/100, Clients: 10\n",
      "Global Test - Loss: 2.1645, Acc: 48.33%\n",
      "Round 78/100, Clients: 10\n",
      "Global Test - Loss: 2.1130, Acc: 48.94%\n",
      "Round 79/100, Clients: 10\n",
      "Global Test - Loss: 2.0642, Acc: 49.66%\n",
      "Round 80/100, Clients: 10\n",
      "Global Test - Loss: 2.0185, Acc: 50.28%\n",
      "Round 81/100, Clients: 10\n",
      "Global Test - Loss: 1.9761, Acc: 50.65%\n",
      "Round 82/100, Clients: 10\n",
      "Global Test - Loss: 1.9365, Acc: 51.26%\n",
      "Round 83/100, Clients: 10\n",
      "Global Test - Loss: 1.8992, Acc: 51.81%\n",
      "Round 84/100, Clients: 10\n",
      "Global Test - Loss: 1.8647, Acc: 52.23%\n",
      "Round 85/100, Clients: 10\n",
      "Global Test - Loss: 1.8327, Acc: 52.69%\n",
      "Round 86/100, Clients: 10\n",
      "Global Test - Loss: 1.8029, Acc: 53.15%\n",
      "Round 87/100, Clients: 10\n",
      "Global Test - Loss: 1.7752, Acc: 53.53%\n",
      "Round 88/100, Clients: 10\n",
      "Global Test - Loss: 1.7492, Acc: 54.11%\n",
      "Round 89/100, Clients: 10\n",
      "Global Test - Loss: 1.7243, Acc: 54.41%\n",
      "Round 90/100, Clients: 10\n",
      "Global Test - Loss: 1.7015, Acc: 54.78%\n",
      "Round 91/100, Clients: 10\n",
      "Global Test - Loss: 1.6800, Acc: 55.15%\n",
      "Round 92/100, Clients: 10\n",
      "Global Test - Loss: 1.6598, Acc: 55.57%\n",
      "Round 93/100, Clients: 10\n",
      "Global Test - Loss: 1.6401, Acc: 55.77%\n",
      "Round 94/100, Clients: 10\n",
      "Global Test - Loss: 1.6220, Acc: 56.12%\n",
      "Round 95/100, Clients: 10\n",
      "Global Test - Loss: 1.6047, Acc: 56.48%\n",
      "Round 96/100, Clients: 10\n",
      "Global Test - Loss: 1.5887, Acc: 56.83%\n",
      "Round 97/100, Clients: 10\n",
      "Global Test - Loss: 1.5726, Acc: 57.04%\n",
      "Round 98/100, Clients: 10\n",
      "Global Test - Loss: 1.5576, Acc: 57.35%\n",
      "Round 99/100, Clients: 10\n",
      "Global Test - Loss: 1.5434, Acc: 57.60%\n",
      "Round 100/100, Clients: 10\n",
      "Global Test - Loss: 1.5299, Acc: 57.89%\n",
      "[6] Done. Total time: 2737.32s\n"
     ]
    }
   ],
   "source": [
    "# SCAFFOLD\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Model Definition\n",
    "# -----------------------------\n",
    "class EMNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*5*5, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 47)  # EMNIST Balanced has 47 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.conv(x))\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Partitioning (Non-IID)\n",
    "# -----------------------------\n",
    "def partition_data(dataset, num_clients=100):\n",
    "    labels = dataset.targets.numpy() if torch.is_tensor(dataset.targets) else np.array(dataset.targets)\n",
    "    idx_by_class = [np.where(labels == i)[0] for i in range(47)]\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "    for c in range(47):\n",
    "        np.random.shuffle(idx_by_class[c])\n",
    "        parts = np.array_split(idx_by_class[c], num_clients)\n",
    "        for i in range(num_clients):\n",
    "            client_indices[i].extend(parts[i])\n",
    "    return [Subset(dataset, inds) for inds in client_indices]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Client Class (SCAFFOLD)\n",
    "# -----------------------------\n",
    "class Client:\n",
    "    def __init__(self, model, data, lr, local_epochs, device):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.data = data\n",
    "        self.lr = lr\n",
    "        self.local_epochs = local_epochs\n",
    "        self.device = device\n",
    "        self.ci = {k: torch.zeros_like(v) for k, v in self.model.state_dict().items()}\n",
    "\n",
    "    def train(self, global_model, global_control):\n",
    "        self.model.load_state_dict(global_model.state_dict())\n",
    "        self.model.train()\n",
    "\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=self.lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loader = DataLoader(self.data, batch_size=32, shuffle=True)\n",
    "\n",
    "        for epoch in range(self.local_epochs):\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "\n",
    "                # SCAFFOLD correction term\n",
    "                control = torch.tensor(0.0, device=self.device)\n",
    "\n",
    "                model_state = self.model.state_dict()\n",
    "                global_state = global_model.state_dict()\n",
    "\n",
    "                for name in model_state:\n",
    "                    p = model_state[name]\n",
    "                    w_t = global_state[name]\n",
    "                    c = global_control[name]\n",
    "                    ci = self.ci[name]\n",
    "                    control += ((p - w_t) * (c - ci)).sum()\n",
    "\n",
    "                loss += 0.5 * control\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Update local control variates\n",
    "        delta_ci = {}\n",
    "        with torch.no_grad():\n",
    "            for k in self.model.state_dict().keys():\n",
    "                delta = global_control[k] - self.ci[k] + \\\n",
    "                        (self.model.state_dict()[k] - global_model.state_dict()[k]) / (self.local_epochs * self.lr)\n",
    "                delta_ci[k] = delta\n",
    "                self.ci[k] += delta\n",
    "\n",
    "        return copy.deepcopy(self.model.state_dict()), delta_ci\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        loader = DataLoader(self.data, batch_size=64, shuffle=False)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "                total_loss += loss.item() * x.size(0)\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += x.size(0)\n",
    "        return total_loss / total, correct / total\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Server Class (SCAFFOLD)\n",
    "# -----------------------------\n",
    "class Server:\n",
    "    def __init__(self, model, num_clients):\n",
    "        self.global_model = model\n",
    "        self.clients = []\n",
    "        self.num_clients = num_clients\n",
    "        self.global_control = {k: torch.zeros_like(v) for k, v in self.global_model.state_dict().items()}\n",
    "\n",
    "    def add_clients(self, client_list):\n",
    "        self.clients = client_list\n",
    "\n",
    "    def aggregate(self, client_states):\n",
    "        avg_state = copy.deepcopy(self.global_model.state_dict())\n",
    "        for k in avg_state:\n",
    "            avg_state[k] = sum(client[k] for client in client_states) / len(client_states)\n",
    "        self.global_model.load_state_dict(avg_state)\n",
    "\n",
    "    def update_control(self, delta_controls):\n",
    "        for k in self.global_control:\n",
    "            self.global_control[k] += sum(delta[k] for delta in delta_controls) / len(delta_controls)\n",
    "\n",
    "    def federated_train(self, rounds):\n",
    "        for r in range(rounds):\n",
    "            selected = random.sample(self.clients, k=10)\n",
    "            client_states, delta_controls = [], []\n",
    "\n",
    "            print(f\"Round {r+1}/{rounds}, Clients: {len(selected)}\")\n",
    "\n",
    "            for client in selected:\n",
    "                state_dict, delta_ci = client.train(self.global_model, self.global_control)\n",
    "                client_states.append(state_dict)\n",
    "                delta_controls.append(delta_ci)\n",
    "\n",
    "            self.aggregate(client_states)\n",
    "            self.update_control(delta_controls)\n",
    "\n",
    "            # Evaluate\n",
    "            global_losses, global_accs = [], []\n",
    "            for client in self.clients:\n",
    "                client.model.load_state_dict(self.global_model.state_dict())\n",
    "                loss, acc = client.evaluate()\n",
    "                global_losses.append(loss)\n",
    "                global_accs.append(acc)\n",
    "\n",
    "            avg_loss = np.mean(global_losses)\n",
    "            avg_acc = np.mean(global_accs) * 100\n",
    "\n",
    "            print(f\"Global Test - Loss: {avg_loss:.4f}, Acc: {avg_acc:.2f}%\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Main Execution\n",
    "# -----------------------------\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    print(\"[0] Loading EMNIST...\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    emnist_train = datasets.EMNIST(root=\"./data\", split=\"balanced\", train=True, download=True, transform=transform)\n",
    "    print(f\"[1] Dataset loaded. Total samples: {len(emnist_train)}\")\n",
    "\n",
    "    print(\"[2] Partitioning data...\")\n",
    "    partition_start = time.time()\n",
    "    client_data = partition_data(emnist_train, num_clients=100)\n",
    "    print(f\"[3] Partition done in {time.time() - partition_start:.2f}s\")\n",
    "\n",
    "    print(\"[4] Initializing models...\")\n",
    "    global_model = EMNIST_CNN().to(device)\n",
    "    server = Server(global_model, num_clients=100)\n",
    "    clients = [Client(global_model, data, lr=0.001, local_epochs=2, device=device) for data in client_data]\n",
    "    server.add_clients(clients)\n",
    "\n",
    "    print(\"[5] Starting federated training...\")\n",
    "    server.federated_train(rounds=100)\n",
    "\n",
    "    print(f\"[6] Done. Total time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[0] Loading EMNIST...\n",
      "[1] Dataset loaded. Total samples: 112800\n",
      "[2] Partitioning data...\n",
      "[3] Partition done in 0.01s\n",
      "[4] Initializing models...\n",
      "[5] Starting federated training...\n",
      "Round 1/100, Clients: 10\n",
      "Global Test - Loss: 3.8537, Acc: 2.74%\n",
      "Round 2/100, Clients: 10\n",
      "Global Test - Loss: 3.8537, Acc: 2.75%\n",
      "Round 3/100, Clients: 10\n",
      "Global Test - Loss: 3.8537, Acc: 2.77%\n",
      "Round 4/100, Clients: 10\n",
      "Global Test - Loss: 3.8536, Acc: 2.79%\n",
      "Round 5/100, Clients: 10\n",
      "Global Test - Loss: 3.8536, Acc: 2.80%\n",
      "Round 6/100, Clients: 10\n",
      "Global Test - Loss: 3.8536, Acc: 2.81%\n",
      "Round 7/100, Clients: 10\n",
      "Global Test - Loss: 3.8535, Acc: 2.82%\n",
      "Round 8/100, Clients: 10\n",
      "Global Test - Loss: 3.8535, Acc: 2.84%\n",
      "Round 9/100, Clients: 10\n",
      "Global Test - Loss: 3.8535, Acc: 2.86%\n",
      "Round 10/100, Clients: 10\n",
      "Global Test - Loss: 3.8534, Acc: 2.88%\n",
      "Round 11/100, Clients: 10\n",
      "Global Test - Loss: 3.8534, Acc: 2.89%\n",
      "Round 12/100, Clients: 10\n",
      "Global Test - Loss: 3.8534, Acc: 2.91%\n",
      "Round 13/100, Clients: 10\n",
      "Global Test - Loss: 3.8533, Acc: 2.92%\n",
      "Round 14/100, Clients: 10\n",
      "Global Test - Loss: 3.8533, Acc: 2.94%\n",
      "Round 15/100, Clients: 10\n",
      "Global Test - Loss: 3.8533, Acc: 2.95%\n",
      "Round 16/100, Clients: 10\n",
      "Global Test - Loss: 3.8532, Acc: 2.97%\n",
      "Round 17/100, Clients: 10\n",
      "Global Test - Loss: 3.8532, Acc: 3.00%\n",
      "Round 18/100, Clients: 10\n",
      "Global Test - Loss: 3.8532, Acc: 3.01%\n",
      "Round 19/100, Clients: 10\n",
      "Global Test - Loss: 3.8531, Acc: 3.02%\n",
      "Round 20/100, Clients: 10\n",
      "Global Test - Loss: 3.8531, Acc: 3.04%\n",
      "Round 21/100, Clients: 10\n",
      "Global Test - Loss: 3.8531, Acc: 3.04%\n",
      "Round 22/100, Clients: 10\n",
      "Global Test - Loss: 3.8530, Acc: 3.05%\n",
      "Round 23/100, Clients: 10\n",
      "Global Test - Loss: 3.8530, Acc: 3.07%\n",
      "Round 24/100, Clients: 10\n",
      "Global Test - Loss: 3.8530, Acc: 3.09%\n",
      "Round 25/100, Clients: 10\n",
      "Global Test - Loss: 3.8529, Acc: 3.11%\n",
      "Round 26/100, Clients: 10\n",
      "Global Test - Loss: 3.8529, Acc: 3.12%\n",
      "Round 27/100, Clients: 10\n",
      "Global Test - Loss: 3.8529, Acc: 3.14%\n",
      "Round 28/100, Clients: 10\n",
      "Global Test - Loss: 3.8529, Acc: 3.15%\n",
      "Round 29/100, Clients: 10\n",
      "Global Test - Loss: 3.8528, Acc: 3.17%\n",
      "Round 30/100, Clients: 10\n",
      "Global Test - Loss: 3.8528, Acc: 3.18%\n",
      "Round 31/100, Clients: 10\n",
      "Global Test - Loss: 3.8528, Acc: 3.20%\n",
      "Round 32/100, Clients: 10\n",
      "Global Test - Loss: 3.8527, Acc: 3.21%\n",
      "Round 33/100, Clients: 10\n",
      "Global Test - Loss: 3.8527, Acc: 3.23%\n",
      "Round 34/100, Clients: 10\n",
      "Global Test - Loss: 3.8527, Acc: 3.25%\n",
      "Round 35/100, Clients: 10\n",
      "Global Test - Loss: 3.8527, Acc: 3.26%\n",
      "Round 36/100, Clients: 10\n",
      "Global Test - Loss: 3.8526, Acc: 3.28%\n",
      "Round 37/100, Clients: 10\n",
      "Global Test - Loss: 3.8526, Acc: 3.29%\n",
      "Round 38/100, Clients: 10\n",
      "Global Test - Loss: 3.8526, Acc: 3.31%\n",
      "Round 39/100, Clients: 10\n",
      "Global Test - Loss: 3.8526, Acc: 3.32%\n",
      "Round 40/100, Clients: 10\n",
      "Global Test - Loss: 3.8525, Acc: 3.33%\n",
      "Round 41/100, Clients: 10\n",
      "Global Test - Loss: 3.8525, Acc: 3.34%\n",
      "Round 42/100, Clients: 10\n",
      "Global Test - Loss: 3.8525, Acc: 3.35%\n",
      "Round 43/100, Clients: 10\n",
      "Global Test - Loss: 3.8525, Acc: 3.37%\n",
      "Round 44/100, Clients: 10\n",
      "Global Test - Loss: 3.8524, Acc: 3.39%\n",
      "Round 45/100, Clients: 10\n",
      "Global Test - Loss: 3.8524, Acc: 3.41%\n",
      "Round 46/100, Clients: 10\n",
      "Global Test - Loss: 3.8524, Acc: 3.42%\n",
      "Round 47/100, Clients: 10\n",
      "Global Test - Loss: 3.8524, Acc: 3.43%\n",
      "Round 48/100, Clients: 10\n",
      "Global Test - Loss: 3.8523, Acc: 3.44%\n",
      "Round 49/100, Clients: 10\n",
      "Global Test - Loss: 3.8523, Acc: 3.46%\n",
      "Round 50/100, Clients: 10\n",
      "Global Test - Loss: 3.8523, Acc: 3.47%\n",
      "Round 51/100, Clients: 10\n",
      "Global Test - Loss: 3.8523, Acc: 3.49%\n",
      "Round 52/100, Clients: 10\n",
      "Global Test - Loss: 3.8522, Acc: 3.50%\n",
      "Round 53/100, Clients: 10\n",
      "Global Test - Loss: 3.8522, Acc: 3.51%\n",
      "Round 54/100, Clients: 10\n",
      "Global Test - Loss: 3.8522, Acc: 3.52%\n",
      "Round 55/100, Clients: 10\n",
      "Global Test - Loss: 3.8522, Acc: 3.54%\n",
      "Round 56/100, Clients: 10\n",
      "Global Test - Loss: 3.8522, Acc: 3.55%\n",
      "Round 57/100, Clients: 10\n",
      "Global Test - Loss: 3.8521, Acc: 3.57%\n",
      "Round 58/100, Clients: 10\n",
      "Global Test - Loss: 3.8521, Acc: 3.59%\n",
      "Round 59/100, Clients: 10\n",
      "Global Test - Loss: 3.8521, Acc: 3.61%\n",
      "Round 60/100, Clients: 10\n",
      "Global Test - Loss: 3.8521, Acc: 3.63%\n",
      "Round 61/100, Clients: 10\n",
      "Global Test - Loss: 3.8520, Acc: 3.65%\n",
      "Round 62/100, Clients: 10\n",
      "Global Test - Loss: 3.8520, Acc: 3.66%\n",
      "Round 63/100, Clients: 10\n",
      "Global Test - Loss: 3.8520, Acc: 3.67%\n",
      "Round 64/100, Clients: 10\n",
      "Global Test - Loss: 3.8520, Acc: 3.68%\n",
      "Round 65/100, Clients: 10\n",
      "Global Test - Loss: 3.8520, Acc: 3.68%\n",
      "Round 66/100, Clients: 10\n",
      "Global Test - Loss: 3.8519, Acc: 3.70%\n",
      "Round 67/100, Clients: 10\n",
      "Global Test - Loss: 3.8519, Acc: 3.72%\n",
      "Round 68/100, Clients: 10\n",
      "Global Test - Loss: 3.8519, Acc: 3.73%\n",
      "Round 69/100, Clients: 10\n",
      "Global Test - Loss: 3.8519, Acc: 3.74%\n",
      "Round 70/100, Clients: 10\n",
      "Global Test - Loss: 3.8519, Acc: 3.76%\n",
      "Round 71/100, Clients: 10\n",
      "Global Test - Loss: 3.8518, Acc: 3.76%\n",
      "Round 72/100, Clients: 10\n",
      "Global Test - Loss: 3.8518, Acc: 3.78%\n",
      "Round 73/100, Clients: 10\n",
      "Global Test - Loss: 3.8518, Acc: 3.80%\n",
      "Round 74/100, Clients: 10\n",
      "Global Test - Loss: 3.8518, Acc: 3.82%\n",
      "Round 75/100, Clients: 10\n",
      "Global Test - Loss: 3.8518, Acc: 3.83%\n",
      "Round 76/100, Clients: 10\n",
      "Global Test - Loss: 3.8517, Acc: 3.85%\n",
      "Round 77/100, Clients: 10\n",
      "Global Test - Loss: 3.8517, Acc: 3.86%\n",
      "Round 78/100, Clients: 10\n",
      "Global Test - Loss: 3.8517, Acc: 3.87%\n",
      "Round 79/100, Clients: 10\n",
      "Global Test - Loss: 3.8517, Acc: 3.89%\n",
      "Round 80/100, Clients: 10\n",
      "Global Test - Loss: 3.8517, Acc: 3.89%\n",
      "Round 81/100, Clients: 10\n",
      "Global Test - Loss: 3.8517, Acc: 3.90%\n",
      "Round 82/100, Clients: 10\n",
      "Global Test - Loss: 3.8516, Acc: 3.92%\n",
      "Round 83/100, Clients: 10\n",
      "Global Test - Loss: 3.8516, Acc: 3.93%\n",
      "Round 84/100, Clients: 10\n",
      "Global Test - Loss: 3.8516, Acc: 3.94%\n",
      "Round 85/100, Clients: 10\n",
      "Global Test - Loss: 3.8516, Acc: 3.96%\n",
      "Round 86/100, Clients: 10\n",
      "Global Test - Loss: 3.8516, Acc: 3.98%\n",
      "Round 87/100, Clients: 10\n",
      "Global Test - Loss: 3.8515, Acc: 3.99%\n",
      "Round 88/100, Clients: 10\n",
      "Global Test - Loss: 3.8515, Acc: 4.02%\n",
      "Round 89/100, Clients: 10\n",
      "Global Test - Loss: 3.8515, Acc: 4.03%\n",
      "Round 90/100, Clients: 10\n",
      "Global Test - Loss: 3.8515, Acc: 4.04%\n",
      "Round 91/100, Clients: 10\n",
      "Global Test - Loss: 3.8515, Acc: 4.05%\n",
      "Round 92/100, Clients: 10\n",
      "Global Test - Loss: 3.8515, Acc: 4.07%\n",
      "Round 93/100, Clients: 10\n",
      "Global Test - Loss: 3.8514, Acc: 4.09%\n",
      "Round 94/100, Clients: 10\n",
      "Global Test - Loss: 3.8514, Acc: 4.10%\n",
      "Round 95/100, Clients: 10\n",
      "Global Test - Loss: 3.8514, Acc: 4.10%\n",
      "Round 96/100, Clients: 10\n",
      "Global Test - Loss: 3.8514, Acc: 4.10%\n",
      "Round 97/100, Clients: 10\n",
      "Global Test - Loss: 3.8514, Acc: 4.12%\n",
      "Round 98/100, Clients: 10\n",
      "Global Test - Loss: 3.8514, Acc: 4.12%\n",
      "Round 99/100, Clients: 10\n",
      "Global Test - Loss: 3.8513, Acc: 4.13%\n",
      "Round 100/100, Clients: 10\n",
      "Global Test - Loss: 3.8513, Acc: 4.14%\n",
      "[6] Done. Total time: 1909.17s\n"
     ]
    }
   ],
   "source": [
    "# FedICT\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Model Definition\n",
    "# -----------------------------\n",
    "class EMNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*5*5, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 47)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.conv(x))\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Partitioning (Non-IID)\n",
    "# -----------------------------\n",
    "def partition_data(dataset, num_clients=100):\n",
    "    labels = dataset.targets.numpy() if torch.is_tensor(dataset.targets) else np.array(dataset.targets)\n",
    "    idx_by_class = [np.where(labels == i)[0] for i in range(47)]\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "    for c in range(47):\n",
    "        np.random.shuffle(idx_by_class[c])\n",
    "        parts = np.array_split(idx_by_class[c], num_clients)\n",
    "        for i in range(num_clients):\n",
    "            client_indices[i].extend(parts[i])\n",
    "    return [Subset(dataset, inds) for inds in client_indices]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Client Class (FedICT)\n",
    "# -----------------------------\n",
    "class Client:\n",
    "    def __init__(self, model, data, lr, local_epochs, device):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.data = data\n",
    "        self.lr = lr\n",
    "        self.local_epochs = local_epochs\n",
    "        self.device = device\n",
    "\n",
    "    def local_train(self):\n",
    "        self.model.train()\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=self.lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loader = DataLoader(self.data, batch_size=32, shuffle=True)\n",
    "\n",
    "        for epoch in range(self.local_epochs):\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        return copy.deepcopy(self.model.state_dict())\n",
    "\n",
    "    def get_logits(self):\n",
    "        self.model.eval()\n",
    "        loader = DataLoader(self.data, batch_size=64, shuffle=False)\n",
    "        all_logits, all_targets = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x = x.to(self.device)\n",
    "                logits = self.model(x)\n",
    "                all_logits.append(logits.cpu())\n",
    "                all_targets.append(y)\n",
    "\n",
    "        all_logits = torch.cat(all_logits, dim=0)\n",
    "        all_targets = torch.cat(all_targets, dim=0)\n",
    "        return all_logits, all_targets\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        loader = DataLoader(self.data, batch_size=64, shuffle=False)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "                total_loss += loss.item() * x.size(0)\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += x.size(0)\n",
    "        return total_loss / total, correct / total\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Server Class (FedICT)\n",
    "# -----------------------------\n",
    "class Server:\n",
    "    def __init__(self, model, num_clients):\n",
    "        self.global_model = model\n",
    "        self.clients = []\n",
    "        self.num_clients = num_clients\n",
    "\n",
    "    def add_clients(self, client_list):\n",
    "        self.clients = client_list\n",
    "\n",
    "    def federated_train(self, rounds):\n",
    "        for r in range(rounds):\n",
    "            selected = random.sample(self.clients, k=10)\n",
    "            client_states = []\n",
    "            all_logits, all_targets, all_images = [], [], []\n",
    "\n",
    "            print(f\"Round {r+1}/{rounds}, Clients: {len(selected)}\")\n",
    "\n",
    "            # Local training and get logits\n",
    "            for client in selected:\n",
    "                state_dict = client.local_train()\n",
    "                client_states.append(state_dict)\n",
    "\n",
    "                client.model.load_state_dict(state_dict)\n",
    "                logits, targets = client.get_logits()\n",
    "                all_logits.append(logits)\n",
    "                all_targets.append(targets)\n",
    "\n",
    "                # 收集原始图片\n",
    "                for x, _ in DataLoader(client.data, batch_size=64, shuffle=False):\n",
    "                    all_images.append(x)\n",
    "\n",
    "            # Aggregate pseudo labels (soft distillation)\n",
    "            concat_logits = torch.cat(all_logits, dim=0)\n",
    "            pseudo_labels = concat_logits.softmax(dim=1)\n",
    "\n",
    "            images_tensor = torch.cat(all_images, dim=0)\n",
    "\n",
    "            # Create loader for distillation\n",
    "            loader = DataLoader(torch.utils.data.TensorDataset(images_tensor, pseudo_labels), batch_size=64, shuffle=True)\n",
    "\n",
    "            # Train global model using images + soft labels\n",
    "            self.global_model.train()\n",
    "            optimizer = optim.SGD(self.global_model.parameters(), lr=0.001)\n",
    "\n",
    "            for x, soft_y in loader:\n",
    "                x = x.to(self.global_model.fc[-1].weight.device)\n",
    "                soft_y = soft_y.to(self.global_model.fc[-1].weight.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = self.global_model(x)\n",
    "                loss = nn.KLDivLoss(reduction=\"batchmean\")(output.log_softmax(dim=1), soft_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Evaluate\n",
    "            global_losses, global_accs = [], []\n",
    "            for client in self.clients:\n",
    "                client.model.load_state_dict(self.global_model.state_dict())\n",
    "                loss, acc = client.evaluate()\n",
    "                global_losses.append(loss)\n",
    "                global_accs.append(acc)\n",
    "\n",
    "            avg_loss = np.mean(global_losses)\n",
    "            avg_acc = np.mean(global_accs) * 100\n",
    "\n",
    "            print(f\"Global Test - Loss: {avg_loss:.4f}, Acc: {avg_acc:.2f}%\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Main Execution\n",
    "# -----------------------------\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    print(\"[0] Loading EMNIST...\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    emnist_train = datasets.EMNIST(root=\"./data\", split=\"balanced\", train=True, download=True, transform=transform)\n",
    "    print(f\"[1] Dataset loaded. Total samples: {len(emnist_train)}\")\n",
    "\n",
    "    print(\"[2] Partitioning data...\")\n",
    "    partition_start = time.time()\n",
    "    client_data = partition_data(emnist_train, num_clients=100)\n",
    "    print(f\"[3] Partition done in {time.time() - partition_start:.2f}s\")\n",
    "\n",
    "    print(\"[4] Initializing models...\")\n",
    "    global_model = EMNIST_CNN().to(device)\n",
    "    server = Server(global_model, num_clients=100)\n",
    "    clients = [Client(global_model, data, lr=0.001, local_epochs=2, device=device) for data in client_data]\n",
    "    server.add_clients(clients)\n",
    "\n",
    "    print(\"[5] Starting federated training...\")\n",
    "    server.federated_train(rounds=100)\n",
    "\n",
    "    print(f\"[6] Done. Total time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[0] Loading EMNIST...\n",
      "[1] Dataset loaded. Total samples: 112800\n",
      "[2] Partitioning data...\n",
      "[3] Partition done in 0.01s\n",
      "[4] Initializing models...\n",
      "[5] Starting federated training...\n",
      "Round 1/100, Clients: 10\n",
      "Global Test - Loss: 3.8527, Acc: 2.01%\n",
      "Round 2/100, Clients: 10\n",
      "Global Test - Loss: 3.8515, Acc: 2.03%\n",
      "Round 3/100, Clients: 10\n",
      "Global Test - Loss: 3.8503, Acc: 2.06%\n",
      "Round 4/100, Clients: 10\n",
      "Global Test - Loss: 3.8492, Acc: 2.09%\n",
      "Round 5/100, Clients: 10\n",
      "Global Test - Loss: 3.8482, Acc: 2.14%\n",
      "Round 6/100, Clients: 10\n",
      "Global Test - Loss: 3.8472, Acc: 2.20%\n",
      "Round 7/100, Clients: 10\n",
      "Global Test - Loss: 3.8463, Acc: 2.30%\n",
      "Round 8/100, Clients: 10\n",
      "Global Test - Loss: 3.8454, Acc: 2.46%\n",
      "Round 9/100, Clients: 10\n",
      "Global Test - Loss: 3.8445, Acc: 2.64%\n",
      "Round 10/100, Clients: 10\n",
      "Global Test - Loss: 3.8436, Acc: 2.88%\n",
      "Round 11/100, Clients: 10\n",
      "Global Test - Loss: 3.8426, Acc: 3.11%\n",
      "Round 12/100, Clients: 10\n",
      "Global Test - Loss: 3.8417, Acc: 3.36%\n",
      "Round 13/100, Clients: 10\n",
      "Global Test - Loss: 3.8408, Acc: 3.63%\n",
      "Round 14/100, Clients: 10\n",
      "Global Test - Loss: 3.8398, Acc: 3.89%\n",
      "Round 15/100, Clients: 10\n",
      "Global Test - Loss: 3.8389, Acc: 4.16%\n",
      "Round 16/100, Clients: 10\n",
      "Global Test - Loss: 3.8379, Acc: 4.45%\n",
      "Round 17/100, Clients: 10\n",
      "Global Test - Loss: 3.8369, Acc: 4.73%\n",
      "Round 18/100, Clients: 10\n",
      "Global Test - Loss: 3.8359, Acc: 5.01%\n",
      "Round 19/100, Clients: 10\n",
      "Global Test - Loss: 3.8348, Acc: 5.22%\n",
      "Round 20/100, Clients: 10\n",
      "Global Test - Loss: 3.8337, Acc: 5.49%\n",
      "Round 21/100, Clients: 10\n",
      "Global Test - Loss: 3.8326, Acc: 5.71%\n",
      "Round 22/100, Clients: 10\n",
      "Global Test - Loss: 3.8314, Acc: 5.93%\n",
      "Round 23/100, Clients: 10\n",
      "Global Test - Loss: 3.8302, Acc: 6.12%\n",
      "Round 24/100, Clients: 10\n",
      "Global Test - Loss: 3.8289, Acc: 6.37%\n",
      "Round 25/100, Clients: 10\n",
      "Global Test - Loss: 3.8276, Acc: 6.66%\n",
      "Round 26/100, Clients: 10\n",
      "Global Test - Loss: 3.8262, Acc: 6.84%\n",
      "Round 27/100, Clients: 10\n",
      "Global Test - Loss: 3.8248, Acc: 7.08%\n",
      "Round 28/100, Clients: 10\n",
      "Global Test - Loss: 3.8234, Acc: 7.34%\n",
      "Round 29/100, Clients: 10\n",
      "Global Test - Loss: 3.8219, Acc: 7.59%\n",
      "Round 30/100, Clients: 10\n",
      "Global Test - Loss: 3.8203, Acc: 7.84%\n",
      "Round 31/100, Clients: 10\n",
      "Global Test - Loss: 3.8186, Acc: 8.11%\n",
      "Round 32/100, Clients: 10\n",
      "Global Test - Loss: 3.8169, Acc: 8.35%\n",
      "Round 33/100, Clients: 10\n",
      "Global Test - Loss: 3.8151, Acc: 8.60%\n",
      "Round 34/100, Clients: 10\n",
      "Global Test - Loss: 3.8132, Acc: 8.89%\n",
      "Round 35/100, Clients: 10\n",
      "Global Test - Loss: 3.8113, Acc: 9.24%\n",
      "Round 36/100, Clients: 10\n",
      "Global Test - Loss: 3.8092, Acc: 9.49%\n",
      "Round 37/100, Clients: 10\n",
      "Global Test - Loss: 3.8071, Acc: 9.74%\n",
      "Round 38/100, Clients: 10\n",
      "Global Test - Loss: 3.8048, Acc: 10.04%\n",
      "Round 39/100, Clients: 10\n",
      "Global Test - Loss: 3.8024, Acc: 10.42%\n",
      "Round 40/100, Clients: 10\n",
      "Global Test - Loss: 3.8000, Acc: 10.80%\n",
      "Round 41/100, Clients: 10\n",
      "Global Test - Loss: 3.7973, Acc: 11.18%\n",
      "Round 42/100, Clients: 10\n",
      "Global Test - Loss: 3.7945, Acc: 11.62%\n",
      "Round 43/100, Clients: 10\n",
      "Global Test - Loss: 3.7916, Acc: 12.05%\n",
      "Round 44/100, Clients: 10\n",
      "Global Test - Loss: 3.7885, Acc: 12.48%\n",
      "Round 45/100, Clients: 10\n",
      "Global Test - Loss: 3.7852, Acc: 12.87%\n",
      "Round 46/100, Clients: 10\n",
      "Global Test - Loss: 3.7818, Acc: 13.27%\n",
      "Round 47/100, Clients: 10\n",
      "Global Test - Loss: 3.7781, Acc: 13.65%\n",
      "Round 48/100, Clients: 10\n",
      "Global Test - Loss: 3.7743, Acc: 13.98%\n",
      "Round 49/100, Clients: 10\n",
      "Global Test - Loss: 3.7702, Acc: 14.29%\n",
      "Round 50/100, Clients: 10\n",
      "Global Test - Loss: 3.7659, Acc: 14.59%\n",
      "Round 51/100, Clients: 10\n",
      "Global Test - Loss: 3.7613, Acc: 14.98%\n",
      "Round 52/100, Clients: 10\n",
      "Global Test - Loss: 3.7565, Acc: 15.27%\n",
      "Round 53/100, Clients: 10\n",
      "Global Test - Loss: 3.7513, Acc: 15.55%\n",
      "Round 54/100, Clients: 10\n",
      "Global Test - Loss: 3.7459, Acc: 15.91%\n",
      "Round 55/100, Clients: 10\n",
      "Global Test - Loss: 3.7401, Acc: 16.19%\n",
      "Round 56/100, Clients: 10\n",
      "Global Test - Loss: 3.7340, Acc: 16.54%\n",
      "Round 57/100, Clients: 10\n",
      "Global Test - Loss: 3.7276, Acc: 16.92%\n",
      "Round 58/100, Clients: 10\n",
      "Global Test - Loss: 3.7206, Acc: 17.32%\n",
      "Round 59/100, Clients: 10\n",
      "Global Test - Loss: 3.7132, Acc: 17.67%\n",
      "Round 60/100, Clients: 10\n",
      "Global Test - Loss: 3.7053, Acc: 18.12%\n",
      "Round 61/100, Clients: 10\n",
      "Global Test - Loss: 3.6969, Acc: 18.54%\n",
      "Round 62/100, Clients: 10\n",
      "Global Test - Loss: 3.6879, Acc: 18.96%\n",
      "Round 63/100, Clients: 10\n",
      "Global Test - Loss: 3.6783, Acc: 19.48%\n",
      "Round 64/100, Clients: 10\n",
      "Global Test - Loss: 3.6678, Acc: 19.93%\n",
      "Round 65/100, Clients: 10\n",
      "Global Test - Loss: 3.6567, Acc: 20.45%\n",
      "Round 66/100, Clients: 10\n",
      "Global Test - Loss: 3.6448, Acc: 20.95%\n",
      "Round 67/100, Clients: 10\n",
      "Global Test - Loss: 3.6321, Acc: 21.61%\n",
      "Round 68/100, Clients: 10\n",
      "Global Test - Loss: 3.6184, Acc: 22.11%\n",
      "Round 69/100, Clients: 10\n",
      "Global Test - Loss: 3.6036, Acc: 22.77%\n",
      "Round 70/100, Clients: 10\n",
      "Global Test - Loss: 3.5878, Acc: 23.43%\n",
      "Round 71/100, Clients: 10\n",
      "Global Test - Loss: 3.5705, Acc: 24.02%\n",
      "Round 72/100, Clients: 10\n",
      "Global Test - Loss: 3.5520, Acc: 24.65%\n",
      "Round 73/100, Clients: 10\n",
      "Global Test - Loss: 3.5320, Acc: 25.23%\n",
      "Round 74/100, Clients: 10\n",
      "Global Test - Loss: 3.5102, Acc: 25.82%\n",
      "Round 75/100, Clients: 10\n",
      "Global Test - Loss: 3.4865, Acc: 26.50%\n",
      "Round 76/100, Clients: 10\n",
      "Global Test - Loss: 3.4612, Acc: 27.21%\n",
      "Round 77/100, Clients: 10\n",
      "Global Test - Loss: 3.4339, Acc: 27.86%\n",
      "Round 78/100, Clients: 10\n",
      "Global Test - Loss: 3.4043, Acc: 28.53%\n",
      "Round 79/100, Clients: 10\n",
      "Global Test - Loss: 3.3724, Acc: 29.28%\n",
      "Round 80/100, Clients: 10\n",
      "Global Test - Loss: 3.3378, Acc: 30.00%\n",
      "Round 81/100, Clients: 10\n",
      "Global Test - Loss: 3.3008, Acc: 30.88%\n",
      "Round 82/100, Clients: 10\n",
      "Global Test - Loss: 3.2603, Acc: 31.61%\n",
      "Round 83/100, Clients: 10\n",
      "Global Test - Loss: 3.2167, Acc: 32.59%\n",
      "Round 84/100, Clients: 10\n",
      "Global Test - Loss: 3.1705, Acc: 33.39%\n",
      "Round 85/100, Clients: 10\n",
      "Global Test - Loss: 3.1209, Acc: 34.16%\n",
      "Round 86/100, Clients: 10\n",
      "Global Test - Loss: 3.0687, Acc: 34.98%\n",
      "Round 87/100, Clients: 10\n",
      "Global Test - Loss: 3.0139, Acc: 35.96%\n",
      "Round 88/100, Clients: 10\n",
      "Global Test - Loss: 2.9566, Acc: 36.67%\n",
      "Round 89/100, Clients: 10\n",
      "Global Test - Loss: 2.8964, Acc: 37.41%\n",
      "Round 90/100, Clients: 10\n",
      "Global Test - Loss: 2.8348, Acc: 38.26%\n",
      "Round 91/100, Clients: 10\n",
      "Global Test - Loss: 2.7719, Acc: 39.16%\n",
      "Round 92/100, Clients: 10\n",
      "Global Test - Loss: 2.7077, Acc: 39.79%\n",
      "Round 93/100, Clients: 10\n",
      "Global Test - Loss: 2.6433, Acc: 40.88%\n",
      "Round 94/100, Clients: 10\n",
      "Global Test - Loss: 2.5787, Acc: 41.61%\n",
      "Round 95/100, Clients: 10\n",
      "Global Test - Loss: 2.5150, Acc: 42.59%\n",
      "Round 96/100, Clients: 10\n",
      "Global Test - Loss: 2.4518, Acc: 43.54%\n",
      "Round 97/100, Clients: 10\n",
      "Global Test - Loss: 2.3912, Acc: 44.23%\n",
      "Round 98/100, Clients: 10\n",
      "Global Test - Loss: 2.3320, Acc: 45.08%\n",
      "Round 99/100, Clients: 10\n",
      "Global Test - Loss: 2.2750, Acc: 45.77%\n",
      "Round 100/100, Clients: 10\n",
      "Global Test - Loss: 2.2203, Acc: 46.42%\n",
      "[6] Done. Total time: 1697.59s\n"
     ]
    }
   ],
   "source": [
    "# FedDyn\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Model Definition\n",
    "# -----------------------------\n",
    "class EMNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*5*5, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 47)  # EMNIST Balanced has 47 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.conv(x))\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Partitioning (Non-IID)\n",
    "# -----------------------------\n",
    "def partition_data(dataset, num_clients=100):\n",
    "    labels = dataset.targets.numpy() if torch.is_tensor(dataset.targets) else np.array(dataset.targets)\n",
    "    idx_by_class = [np.where(labels == i)[0] for i in range(47)]\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "    for c in range(47):\n",
    "        np.random.shuffle(idx_by_class[c])\n",
    "        parts = np.array_split(idx_by_class[c], num_clients)\n",
    "        for i in range(num_clients):\n",
    "            client_indices[i].extend(parts[i])\n",
    "    return [Subset(dataset, inds) for inds in client_indices]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Client Class (FedDyn)\n",
    "# -----------------------------\n",
    "class Client:\n",
    "    def __init__(self, model, data, lr, local_epochs, device):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.data = data\n",
    "        self.lr = lr\n",
    "        self.local_epochs = local_epochs\n",
    "        self.device = device\n",
    "        # Dynamic correction vector (tracker)\n",
    "        self.dyn_vector = {k: torch.zeros_like(v) for k, v in self.model.state_dict().items()}\n",
    "\n",
    "    def train(self, global_model):\n",
    "        self.model.load_state_dict(global_model.state_dict())\n",
    "        self.model.train()\n",
    "\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=self.lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loader = DataLoader(self.data, batch_size=32, shuffle=True)\n",
    "\n",
    "        for epoch in range(self.local_epochs):\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "\n",
    "                # FedDyn correction term\n",
    "                correction = 0.0\n",
    "                local_state = self.model.state_dict()\n",
    "                for name in local_state:\n",
    "                    p = local_state[name]\n",
    "                    dyn = self.dyn_vector[name]\n",
    "                    correction += (p * dyn).sum()\n",
    "\n",
    "                loss += correction\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Update dynamic correction vector\n",
    "        with torch.no_grad():\n",
    "            for k in self.model.state_dict().keys():\n",
    "                delta = global_model.state_dict()[k] - self.model.state_dict()[k]\n",
    "                self.dyn_vector[k] -= delta / (self.lr * self.local_epochs)\n",
    "\n",
    "        return copy.deepcopy(self.model.state_dict())\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        loader = DataLoader(self.data, batch_size=64, shuffle=False)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "                total_loss += loss.item() * x.size(0)\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += x.size(0)\n",
    "        return total_loss / total, correct / total\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Server Class (FedDyn)\n",
    "# -----------------------------\n",
    "class Server:\n",
    "    def __init__(self, model, num_clients):\n",
    "        self.global_model = model\n",
    "        self.clients = []\n",
    "        self.num_clients = num_clients\n",
    "\n",
    "    def add_clients(self, client_list):\n",
    "        self.clients = client_list\n",
    "\n",
    "    def aggregate(self, client_states):\n",
    "        avg_state = copy.deepcopy(self.global_model.state_dict())\n",
    "        for k in avg_state:\n",
    "            avg_state[k] = sum(client[k] for client in client_states) / len(client_states)\n",
    "        self.global_model.load_state_dict(avg_state)\n",
    "\n",
    "    def federated_train(self, rounds):\n",
    "        for r in range(rounds):\n",
    "            selected = random.sample(self.clients, k=10)\n",
    "            client_states = []\n",
    "\n",
    "            print(f\"Round {r+1}/{rounds}, Clients: {len(selected)}\")\n",
    "\n",
    "            for client in selected:\n",
    "                state_dict = client.train(self.global_model)\n",
    "                client_states.append(state_dict)\n",
    "\n",
    "            self.aggregate(client_states)\n",
    "\n",
    "            # Evaluate\n",
    "            global_losses, global_accs = [], []\n",
    "            for client in self.clients:\n",
    "                client.model.load_state_dict(self.global_model.state_dict())\n",
    "                loss, acc = client.evaluate()\n",
    "                global_losses.append(loss)\n",
    "                global_accs.append(acc)\n",
    "\n",
    "            avg_loss = np.mean(global_losses)\n",
    "            avg_acc = np.mean(global_accs) * 100\n",
    "\n",
    "            print(f\"Global Test - Loss: {avg_loss:.4f}, Acc: {avg_acc:.2f}%\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Main Execution\n",
    "# -----------------------------\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    print(\"[0] Loading EMNIST...\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    emnist_train = datasets.EMNIST(root=\"./data\", split=\"balanced\", train=True, download=True, transform=transform)\n",
    "    print(f\"[1] Dataset loaded. Total samples: {len(emnist_train)}\")\n",
    "\n",
    "    print(\"[2] Partitioning data...\")\n",
    "    partition_start = time.time()\n",
    "    client_data = partition_data(emnist_train, num_clients=100)\n",
    "    print(f\"[3] Partition done in {time.time() - partition_start:.2f}s\")\n",
    "\n",
    "    print(\"[4] Initializing models...\")\n",
    "    global_model = EMNIST_CNN().to(device)\n",
    "    server = Server(global_model, num_clients=100)\n",
    "    clients = [Client(global_model, data, lr=0.001, local_epochs=2, device=device) for data in client_data]\n",
    "    server.add_clients(clients)\n",
    "\n",
    "    print(\"[5] Starting federated training...\")\n",
    "    server.federated_train(rounds=100)\n",
    "\n",
    "    print(f\"[6] Done. Total time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[0] Loading EMNIST...\n",
      "[1] Dataset loaded. Total samples: 112800\n",
      "[2] Partitioning data...\n",
      "[3] Partition done in 0.02s\n",
      "[4] Initializing models...\n",
      "[5] Starting federated training...\n",
      "Round 1/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 3.8506, Acc: 2.76%\n",
      "Round 2/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 3.8491, Acc: 2.96%\n",
      "Round 3/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 3.8477, Acc: 3.18%\n",
      "Round 4/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 3.8464, Acc: 3.47%\n",
      "Round 5/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 3.8452, Acc: 3.77%\n",
      "Round 6/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 3.8441, Acc: 4.00%\n",
      "Round 7/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 3.8430, Acc: 4.25%\n",
      "Round 8/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 3.8420, Acc: 4.43%\n",
      "Round 9/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 3.8409, Acc: 4.59%\n",
      "Round 10/100, μ=0.1000, Clients: 10\n",
      "Global Test - Loss: 3.8399, Acc: 4.67%\n",
      "Round 11/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 3.8389, Acc: 4.77%\n",
      "Round 12/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 3.8379, Acc: 4.88%\n",
      "Round 13/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 3.8369, Acc: 4.99%\n",
      "Round 14/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 3.8359, Acc: 5.07%\n",
      "Round 15/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 3.8349, Acc: 5.14%\n",
      "Round 16/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 3.8339, Acc: 5.12%\n",
      "Round 17/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 3.8329, Acc: 5.13%\n",
      "Round 18/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 3.8318, Acc: 5.12%\n",
      "Round 19/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 3.8307, Acc: 5.17%\n",
      "Round 20/100, μ=0.0950, Clients: 10\n",
      "Global Test - Loss: 3.8296, Acc: 5.17%\n",
      "Round 21/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 3.8284, Acc: 5.27%\n",
      "Round 22/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 3.8273, Acc: 5.34%\n",
      "Round 23/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 3.8261, Acc: 5.36%\n",
      "Round 24/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 3.8248, Acc: 5.47%\n",
      "Round 25/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 3.8235, Acc: 5.52%\n",
      "Round 26/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 3.8222, Acc: 5.67%\n",
      "Round 27/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 3.8208, Acc: 5.80%\n",
      "Round 28/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 3.8194, Acc: 5.86%\n",
      "Round 29/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 3.8180, Acc: 5.92%\n",
      "Round 30/100, μ=0.0902, Clients: 10\n",
      "Global Test - Loss: 3.8165, Acc: 6.07%\n",
      "Round 31/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 3.8149, Acc: 6.19%\n",
      "Round 32/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 3.8133, Acc: 6.32%\n",
      "Round 33/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 3.8116, Acc: 6.49%\n",
      "Round 34/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 3.8099, Acc: 6.61%\n",
      "Round 35/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 3.8081, Acc: 6.77%\n",
      "Round 36/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 3.8063, Acc: 6.87%\n",
      "Round 37/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 3.8044, Acc: 7.08%\n",
      "Round 38/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 3.8024, Acc: 7.28%\n",
      "Round 39/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 3.8004, Acc: 7.42%\n",
      "Round 40/100, μ=0.0857, Clients: 10\n",
      "Global Test - Loss: 3.7983, Acc: 7.61%\n",
      "Round 41/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 3.7961, Acc: 7.72%\n",
      "Round 42/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 3.7938, Acc: 7.88%\n",
      "Round 43/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 3.7915, Acc: 8.03%\n",
      "Round 44/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 3.7891, Acc: 8.18%\n",
      "Round 45/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 3.7866, Acc: 8.37%\n",
      "Round 46/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 3.7840, Acc: 8.49%\n",
      "Round 47/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 3.7813, Acc: 8.68%\n",
      "Round 48/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 3.7785, Acc: 8.95%\n",
      "Round 49/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 3.7756, Acc: 9.17%\n",
      "Round 50/100, μ=0.0815, Clients: 10\n",
      "Global Test - Loss: 3.7727, Acc: 9.32%\n",
      "Round 51/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 3.7697, Acc: 9.59%\n",
      "Round 52/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 3.7665, Acc: 9.96%\n",
      "Round 53/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 3.7633, Acc: 10.19%\n",
      "Round 54/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 3.7599, Acc: 10.50%\n",
      "Round 55/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 3.7563, Acc: 10.86%\n",
      "Round 56/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 3.7526, Acc: 11.20%\n",
      "Round 57/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 3.7488, Acc: 11.66%\n",
      "Round 58/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 3.7449, Acc: 11.88%\n",
      "Round 59/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 3.7408, Acc: 12.43%\n",
      "Round 60/100, μ=0.0774, Clients: 10\n",
      "Global Test - Loss: 3.7367, Acc: 12.83%\n",
      "Round 61/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 3.7323, Acc: 13.35%\n",
      "Round 62/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 3.7278, Acc: 13.76%\n",
      "Round 63/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 3.7232, Acc: 14.27%\n",
      "Round 64/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 3.7184, Acc: 14.79%\n",
      "Round 65/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 3.7134, Acc: 15.36%\n",
      "Round 66/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 3.7084, Acc: 15.86%\n",
      "Round 67/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 3.7030, Acc: 16.30%\n",
      "Round 68/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 3.6975, Acc: 16.78%\n",
      "Round 69/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 3.6919, Acc: 17.36%\n",
      "Round 70/100, μ=0.0735, Clients: 10\n",
      "Global Test - Loss: 3.6860, Acc: 17.79%\n",
      "Round 71/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 3.6800, Acc: 18.24%\n",
      "Round 72/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 3.6737, Acc: 18.84%\n",
      "Round 73/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 3.6672, Acc: 19.29%\n",
      "Round 74/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 3.6606, Acc: 19.71%\n",
      "Round 75/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 3.6535, Acc: 20.22%\n",
      "Round 76/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 3.6464, Acc: 20.89%\n",
      "Round 77/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 3.6391, Acc: 21.43%\n",
      "Round 78/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 3.6317, Acc: 22.03%\n",
      "Round 79/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 3.6238, Acc: 22.62%\n",
      "Round 80/100, μ=0.0698, Clients: 10\n",
      "Global Test - Loss: 3.6157, Acc: 23.10%\n",
      "Round 81/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 3.6073, Acc: 23.70%\n",
      "Round 82/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 3.5986, Acc: 24.18%\n",
      "Round 83/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 3.5896, Acc: 24.81%\n",
      "Round 84/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 3.5804, Acc: 25.32%\n",
      "Round 85/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 3.5710, Acc: 25.85%\n",
      "Round 86/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 3.5612, Acc: 26.36%\n",
      "Round 87/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 3.5511, Acc: 26.86%\n",
      "Round 88/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 3.5408, Acc: 27.34%\n",
      "Round 89/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 3.5305, Acc: 27.77%\n",
      "Round 90/100, μ=0.0663, Clients: 10\n",
      "Global Test - Loss: 3.5196, Acc: 28.32%\n",
      "Round 91/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 3.5085, Acc: 28.84%\n",
      "Round 92/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 3.4970, Acc: 29.19%\n",
      "Round 93/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 3.4849, Acc: 29.61%\n",
      "Round 94/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 3.4727, Acc: 30.07%\n",
      "Round 95/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 3.4602, Acc: 30.50%\n",
      "Round 96/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 3.4468, Acc: 30.94%\n",
      "Round 97/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 3.4336, Acc: 31.43%\n",
      "Round 98/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 3.4200, Acc: 31.88%\n",
      "Round 99/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 3.4060, Acc: 32.31%\n",
      "Round 100/100, μ=0.0630, Clients: 10\n",
      "Global Test - Loss: 3.3922, Acc: 32.91%\n",
      "[6] Done. Total time: 1693.47s\n"
     ]
    }
   ],
   "source": [
    "# FedSC-MTL\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Model Definition\n",
    "# -----------------------------\n",
    "class EMNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc1 = nn.Linear(64*5*5, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 47)\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        feat = self.relu(self.fc1(x))\n",
    "        out = self.fc2(feat)\n",
    "        if return_features:\n",
    "            return out, feat\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Partitioning (Non-IID)\n",
    "# -----------------------------\n",
    "def partition_data(dataset, num_clients=100):\n",
    "    labels = dataset.targets.numpy() if torch.is_tensor(dataset.targets) else np.array(dataset.targets)\n",
    "    idx_by_class = [np.where(labels == i)[0] for i in range(47)]\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "    for c in range(47):\n",
    "        np.random.shuffle(idx_by_class[c])\n",
    "        parts = np.array_split(idx_by_class[c], num_clients)\n",
    "        for i in range(num_clients):\n",
    "            client_indices[i].extend(parts[i])\n",
    "    return [Subset(dataset, inds) for inds in client_indices]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Client Class (FedSC-MTL)\n",
    "# -----------------------------\n",
    "class Client:\n",
    "    def __init__(self, model, data, lr, local_epochs, device):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.data = data\n",
    "        self.lr = lr\n",
    "        self.local_epochs = local_epochs\n",
    "        self.device = device\n",
    "        self.ci = {k: torch.zeros_like(v) for k, v in self.model.state_dict().items()}\n",
    "\n",
    "    def train(self, global_model, cg, mu):\n",
    "        self.model.load_state_dict(global_model.state_dict())\n",
    "        self.model.train()\n",
    "\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=self.lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loader = DataLoader(self.data, batch_size=32, shuffle=True)\n",
    "\n",
    "        for epoch in range(self.local_epochs):\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                output, feat = self.model(x, return_features=True)\n",
    "                loss_cls = criterion(output, y)\n",
    "\n",
    "                # 特征蒸馏损失（这里以零向量作为参考特征示例，你可根据实际替换）\n",
    "                fref = torch.zeros_like(feat).to(self.device)\n",
    "                distill_loss = nn.MSELoss()(feat, fref)\n",
    "\n",
    "                # 控制变量修正项\n",
    "                grad_correction = 0.0\n",
    "                model_state = self.model.state_dict()\n",
    "                global_state = global_model.state_dict()\n",
    "\n",
    "                for name in model_state:\n",
    "                    p = model_state[name]\n",
    "                    w_t = global_state[name]\n",
    "                    c_global = cg[name]\n",
    "                    ci_local = self.ci[name]\n",
    "                    grad_correction += ((p - w_t) * (-ci_local + c_global + mu * (p - w_t))).sum()\n",
    "\n",
    "                # 合并总损失\n",
    "                total_loss = loss_cls + distill_loss + 0.5 * grad_correction\n",
    "\n",
    "                total_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # 更新 local control ci\n",
    "        with torch.no_grad():\n",
    "            for k in self.model.state_dict().keys():\n",
    "                self.ci[k] = self.ci[k] - cg[k] + (global_model.state_dict()[k] - self.model.state_dict()[k]) / self.lr\n",
    "\n",
    "        return copy.deepcopy(self.model.state_dict()), self.ci\n",
    "\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        loader = DataLoader(self.data, batch_size=64, shuffle=False)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                output = self.model(x)\n",
    "                loss = criterion(output, y)\n",
    "                total_loss += loss.item() * x.size(0)\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += x.size(0)\n",
    "        return total_loss / total, correct / total\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Server Class (FedSC-MTL)\n",
    "# -----------------------------\n",
    "class Server:\n",
    "    def __init__(self, model, num_clients):\n",
    "        self.global_model = model\n",
    "        self.clients = []\n",
    "        self.num_clients = num_clients\n",
    "        self.cg = {k: torch.zeros_like(v) for k, v in self.global_model.state_dict().items()}\n",
    "\n",
    "    def add_clients(self, client_list):\n",
    "        self.clients = client_list\n",
    "\n",
    "    def aggregate(self, client_states):\n",
    "        avg_state = copy.deepcopy(self.global_model.state_dict())\n",
    "        for k in avg_state:\n",
    "            avg_state[k] = sum(client[k] for client in client_states) / len(client_states)\n",
    "        self.global_model.load_state_dict(avg_state)\n",
    "\n",
    "    def update_cg(self, ci_list):\n",
    "        for k in self.cg:\n",
    "            self.cg[k] = sum(ci[k] for ci in ci_list) / len(ci_list)\n",
    "\n",
    "    def federated_train(self, rounds, mu_scheduler):\n",
    "        for r in range(rounds):\n",
    "            selected = random.sample(self.clients, k=10)\n",
    "            mu = mu_scheduler(r)\n",
    "            client_states, ci_list = [], []\n",
    "\n",
    "            print(f\"Round {r+1}/{rounds}, μ={mu:.4f}, Clients: {len(selected)}\")\n",
    "\n",
    "            for client in selected:\n",
    "                state_dict, ci = client.train(self.global_model, self.cg, mu)\n",
    "                client_states.append(state_dict)\n",
    "                ci_list.append(ci)\n",
    "\n",
    "            self.aggregate(client_states)\n",
    "            self.update_cg(ci_list)\n",
    "\n",
    "            # Evaluate\n",
    "            global_losses, global_accs = [], []\n",
    "            for client in self.clients:\n",
    "                client.model.load_state_dict(self.global_model.state_dict())\n",
    "                loss, acc = client.evaluate()\n",
    "                global_losses.append(loss)\n",
    "                global_accs.append(acc)\n",
    "\n",
    "            avg_loss = np.mean(global_losses)\n",
    "            avg_acc = np.mean(global_accs) * 100\n",
    "\n",
    "            print(f\"Global Test - Loss: {avg_loss:.4f}, Acc: {avg_acc:.2f}%\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Main Execution\n",
    "# -----------------------------\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    print(\"[0] Loading EMNIST...\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    emnist_train = datasets.EMNIST(root=\"./data\", split=\"balanced\", train=True, download=True, transform=transform)\n",
    "    print(f\"[1] Dataset loaded. Total samples: {len(emnist_train)}\")\n",
    "\n",
    "    print(\"[2] Partitioning data...\")\n",
    "    partition_start = time.time()\n",
    "    client_data = partition_data(emnist_train, num_clients=100)\n",
    "    print(f\"[3] Partition done in {time.time() - partition_start:.2f}s\")\n",
    "\n",
    "    print(\"[4] Initializing models...\")\n",
    "    global_model = EMNIST_CNN().to(device)\n",
    "    server = Server(global_model, num_clients=100)\n",
    "    clients = [Client(global_model, data, lr=0.001, local_epochs=2, device=device) for data in client_data]\n",
    "    server.add_clients(clients)\n",
    "\n",
    "    def mu_schedule(round_idx):\n",
    "        return 0.1 * (0.95 ** (round_idx // 10))  # 每10轮衰减\n",
    "\n",
    "    print(\"[5] Starting federated training...\")\n",
    "    server.federated_train(rounds=100, mu_scheduler=mu_schedule)\n",
    "\n",
    "    print(f\"[6] Done. Total time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fedavg_acc = [\n",
    "    2.13, 2.21, 2.26, 2.30, 2.35, 2.43, 2.52, 2.62, 2.88, 3.11,\n",
    "    3.36, 3.67, 4.04, 4.47, 4.88, 5.34, 5.78, 6.17, 6.59, 7.07,\n",
    "    7.44, 7.81, 8.25, 8.63, 9.04, 9.45, 9.77, 10.17, 10.59, 10.94,\n",
    "    11.23, 11.68, 12.09, 12.47, 12.77, 13.18, 13.66, 14.00, 14.43, 14.86,\n",
    "    15.35, 15.78, 16.29, 16.77, 17.53, 18.21, 19.00, 19.94, 20.76, 21.64,\n",
    "    22.42, 23.30, 24.11, 24.69, 25.30, 25.84, 26.49, 27.12, 27.78, 28.51,\n",
    "    29.29, 30.21, 30.98, 31.85, 32.78, 33.71, 34.54, 35.38, 36.18, 37.08,\n",
    "    37.94, 38.78, 39.56, 40.31, 41.16, 41.97, 42.90, 43.65, 44.28, 44.92,\n",
    "    45.69, 46.31, 46.98, 47.61, 48.25, 48.82, 49.12, 49.72, 50.22, 50.59,\n",
    "    51.23, 51.54, 52.03, 52.35, 52.78, 53.20, 53.67, 53.96, 54.37, 54.72\n",
    "]\n",
    "\n",
    "# FedProx 数据\n",
    "fedprox_acc = [\n",
    "    31.85, 54.45, 62.32, 67.97, 70.49, 70.99, 73.22, 72.15, 76.26, 73.61,\n",
    "    77.51, 76.57, 75.95, 78.97, 76.91, 73.10, 76.06, 73.35, 74.65, 76.14,\n",
    "    76.11, 79.10, 78.80, 76.41, 78.75, 79.40, 80.33, 76.76, 74.21, 80.59,\n",
    "    76.69, 77.77, 78.54, 80.96, 79.63, 80.49, 79.15, 79.07, 80.40, 78.11,\n",
    "    79.10, 78.35, 77.39, 80.07, 78.94, 75.18, 80.98, 79.13, 76.94, 77.81,\n",
    "    80.60, 79.46, 80.78, 79.37, 79.69, 77.15, 77.21, 81.55, 80.01, 80.83,\n",
    "    77.62, 78.06, 81.02, 78.23, 80.09, 79.15, 79.79, 79.63, 79.06, 81.99,\n",
    "    78.78, 79.28, 82.05, 78.16, 81.14, 78.53, 78.89, 78.74, 79.25, 80.64,\n",
    "    81.99, 79.97, 79.89, 79.83, 80.00, 83.43, 79.12, 76.42, 82.71, 82.86,\n",
    "    82.02, 80.80, 83.46, 78.69, 81.42, 78.26, 82.27, 80.14, 81.72, 80.51\n",
    "]\n",
    "\n",
    "# SCAFFOLD 数据\n",
    "scaffold_acc = [\n",
    "    2.36, 2.67, 3.01, 3.36, 3.77, 4.24, 4.68, 5.09, 5.47, 5.83,\n",
    "    6.22, 6.61, 6.94, 7.44, 7.82, 8.31, 8.75, 9.22, 9.65, 10.18,\n",
    "    10.59, 11.14, 11.56, 12.00, 12.32, 12.81, 13.17, 13.55, 13.97, 14.43,\n",
    "    14.77, 15.12, 15.54, 15.90, 16.22, 16.65, 16.95, 17.25, 17.52, 17.97,\n",
    "    18.38, 18.88, 19.22, 19.65, 20.11, 20.65, 21.05, 21.66, 22.41, 23.19,\n",
    "    24.09, 24.98, 25.65, 26.71, 27.61, 28.69, 29.87, 31.05, 32.26, 33.32,\n",
    "    34.38, 35.31, 36.48, 37.43, 38.30, 39.10, 39.98, 40.94, 41.67, 42.75,\n",
    "    43.56, 44.46, 45.14, 45.97, 46.91, 47.62, 48.33, 48.94, 49.66, 50.28,\n",
    "    50.65, 51.26, 51.81, 52.23, 52.69, 53.15, 53.53, 54.11, 54.41, 54.78,\n",
    "    55.15, 55.57, 55.77, 56.12, 56.48, 56.83, 57.04, 57.35, 57.60, 57.89\n",
    "]\n",
    "\n",
    "fedict_acc = [\n",
    "    2.74, 2.75, 2.77, 2.79, 2.80, 2.81, 2.82, 2.84, 2.86, 2.88,\n",
    "    2.89, 2.91, 2.92, 2.94, 2.95, 2.97, 3.00, 3.01, 3.02, 3.04,\n",
    "    3.04, 3.05, 3.07, 3.09, 3.11, 3.12, 3.14, 3.15, 3.17, 3.18,\n",
    "    3.20, 3.21, 3.23, 3.25, 3.26, 3.28, 3.29, 3.31, 3.32, 3.33,\n",
    "    3.34, 3.35, 3.35, 3.37, 3.39, 3.41, 3.42, 3.43, 3.44, 3.46,\n",
    "    3.47, 3.49, 3.50, 3.51, 3.52, 3.54, 3.55, 3.57, 3.59, 3.61,\n",
    "    3.63, 3.65, 3.66, 3.67, 3.68, 3.68, 3.70, 3.72, 3.73, 3.74,\n",
    "    3.76, 3.76, 3.78, 3.80, 3.82, 3.83, 3.85, 3.86, 3.87, 3.89,\n",
    "    3.89, 3.90, 3.92, 3.93, 3.94, 3.96, 3.98, 3.99, 4.02, 4.03,\n",
    "    4.04, 4.05, 4.07, 4.09, 4.10, 4.10, 4.12, 4.12, 4.13, 4.14\n",
    "]\n",
    "\n",
    "feddyn_acc = [\n",
    "    2.01, 2.03, 2.06, 2.09, 2.14, 2.20, 2.30, 2.46, 2.64, 2.88,\n",
    "    3.11, 3.36, 3.63, 3.89, 4.16, 4.45, 4.73, 5.01, 5.22, 5.49,\n",
    "    5.71, 5.93, 6.12, 6.37, 6.66, 6.84, 7.08, 7.34, 7.59, 7.84,\n",
    "    8.11, 8.35, 8.60, 8.89, 9.24, 9.49, 9.74, 10.04, 10.42, 10.80,\n",
    "    11.18, 11.62, 12.05, 12.48, 12.87, 13.27, 13.65, 13.98, 14.29, 14.59,\n",
    "    14.98, 15.27, 15.55, 15.91, 16.19, 16.54, 16.92, 17.32, 17.67, 18.12,\n",
    "    18.54, 18.96, 19.48, 19.93, 20.45, 20.95, 21.61, 22.11, 22.77, 23.43,\n",
    "    24.02, 24.65, 25.23, 25.82, 26.50, 27.21, 27.86, 28.53, 29.28, 30.00,\n",
    "    30.88, 31.61, 32.59, 33.39, 34.16, 34.98, 35.96, 36.67, 37.41, 38.26,\n",
    "    39.16, 39.79, 40.88, 41.61, 42.59, 43.54, 44.23, 45.08, 45.77, 46.42\n",
    "]\n",
    "\n",
    "fedsc_mtl_acc = [\n",
    "    2.76, 2.96, 3.18, 3.47, 3.77, 4.00, 4.25, 4.43, 4.59, 4.67,\n",
    "    4.77, 4.88, 4.99, 5.07, 5.14, 5.12, 5.13, 5.12, 5.17, 5.17,\n",
    "    5.27, 5.34, 5.36, 5.47, 5.52, 5.67, 5.80, 5.86, 5.92, 6.07,\n",
    "    6.19, 6.32, 6.49, 6.61, 6.77, 6.87, 7.08, 7.28, 7.42, 7.61,\n",
    "    7.72, 7.88, 8.03, 8.18, 8.37, 8.49, 8.68, 8.95, 9.17, 9.32,\n",
    "    9.59, 9.96, 10.19, 10.50, 10.86, 11.20, 11.66, 11.88, 12.43, 12.83,\n",
    "    13.35, 13.76, 14.27, 14.79, 15.36, 15.86, 16.30, 16.78, 17.36, 17.79,\n",
    "    18.24, 18.84, 19.29, 19.71, 20.22, 20.89, 21.43, 22.03, 22.62, 23.10,\n",
    "    23.70, 24.18, 24.81, 25.32, 25.85, 26.36, 26.86, 27.34, 27.77, 28.32,\n",
    "    28.84, 29.19, 29.61, 30.07, 30.50, 30.94, 31.43, 31.88, 32.31, 32.91\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "rounds = list(range(1, 101))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(rounds, fedavg_acc, label='FedAvg')\n",
    "plt.plot(rounds, fedprox_acc, label='FedProx')\n",
    "plt.plot(rounds, scaffold_acc, label='SCAFFOLD')\n",
    "plt.plot(rounds, fedict_acc, label='FedICT')\n",
    "plt.plot(rounds, feddyn_acc, label='FedDyn')\n",
    "plt.plot(rounds, fedsc_mtl_acc, label='FedSC-MTL')\n",
    "\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.title('Test Accuracy vs. Round (EMNIST)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedAvg      : 89 rounds\n",
      "FedProx     : 2 rounds\n",
      "SCAFFOLD    : 80 rounds\n",
      "FedICT      : 100 rounds\n",
      "FedDyn      : 100 rounds\n",
      "FedSC-MTL   : 100 rounds\n"
     ]
    }
   ],
   "source": [
    "def find_convergence_round(acc_list, target_acc=50.0):\n",
    "    for i, acc in enumerate(acc_list):\n",
    "        if acc >= target_acc:\n",
    "            return i + 1  \n",
    "    return len(acc_list)\n",
    "\n",
    "target_acc = 50.0\n",
    "\n",
    "rounds_fedavg = find_convergence_round(fedavg_acc, target_acc)\n",
    "rounds_fedprox = find_convergence_round(fedprox_acc, target_acc)\n",
    "rounds_scaffold = find_convergence_round(scaffold_acc, target_acc)\n",
    "rounds_fedict = find_convergence_round(fedict_acc, target_acc)\n",
    "rounds_feddyn = find_convergence_round(feddyn_acc, target_acc)\n",
    "rounds_fedscmtl = find_convergence_round(fedsc_mtl_acc, target_acc)\n",
    "\n",
    "print(f\"FedAvg      : {rounds_fedavg} rounds\")\n",
    "print(f\"FedProx     : {rounds_fedprox} rounds\")\n",
    "print(f\"SCAFFOLD    : {rounds_scaffold} rounds\")\n",
    "print(f\"FedICT      : {rounds_fedict} rounds\")\n",
    "print(f\"FedDyn      : {rounds_feddyn} rounds\")\n",
    "print(f\"FedSC-MTL   : {rounds_fedscmtl} rounds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
